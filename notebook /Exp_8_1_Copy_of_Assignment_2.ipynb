{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp 8 1 Copy of Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f0ayvowQNK3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Referred Material\n",
        "\n",
        "**-Loading and transforming data **\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "\n",
        "-**Intro to pytorch **\n",
        "\n",
        "https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
        "\n",
        "\n",
        "-**Image preprocessing over view: **\n",
        "\n",
        "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258\n",
        " \n",
        " (*Try this*) https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        " \n",
        " (*Try this*) https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
        " \n",
        " -**List of things to try w.r.t pre-processing**\n",
        " \n",
        "\n",
        "*   Square images + batch size 10  (**Done**)\n",
        "*   Square images + bw + batch size 100 (**Done**)\n",
        "*   Square images + batch size 100  (**Done**)\n",
        "*   Random flips and rotation  (**Done**)\n",
        "*   Five crop images + batch size 100  (**Done**)\n",
        "*   Other transformation techniques  (**Done**)\n",
        "*   Without normalization  (**Done**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MCpt-zcyo_xc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m29L6L_EYtQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Mounting the google drive for loading Dataset sand saving other files"
      ]
    },
    {
      "metadata": {
        "id": "kiT0P1Zh0T4O",
        "colab_type": "code",
        "outputId": "dac2b5f0-c3f3-4d5a-9ac1-b9a082dbe03c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJz_lmGZDF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Installing and loading necessary modules"
      ]
    },
    {
      "metadata": {
        "id": "L5xPhzElgxSe",
        "colab_type": "code",
        "outputId": "8edd96aa-4a25-4545-a39a-7c1e797332dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random;\n",
        "import math;\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from IPython.display import clear_output, display\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 8.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "01YPIMAwKWEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "031939f6-2e63-49b7-98a6-3adbccee6213"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMN54-l0Y2Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading Dataset to pandas dataframe and splitting it into train, test and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "jpn74UIA1LG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "c0cd94d8-c2d6-404b-a7ca-ba2dbf804a15"
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/train_cars.csv', 'r') as f:\n",
        "#   print(f.read())  \n",
        "\n",
        "file_dir = \"/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/\"\n",
        "img_dir = file_dir + \"train/\"\n",
        "sq_img_dir = file_dir + \"train_sq/\"\n",
        "file_name = file_dir + \"train_cars.csv\"\n",
        "sep_datasets = file_dir + \"sep datasets/\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_entire_dataset = pd.read_csv(file_name)\n",
        "\n",
        "print(df_entire_dataset.columns)\n",
        "unique_car_type = df_entire_dataset.target.unique()\n",
        "\n",
        "print(unique_car_type)\n",
        "\n",
        "unique_car_type_dict = {}\n",
        "df_entire_dataset[\"num_target\"] = df_entire_dataset[\"target\"]\n",
        "for index, per_car_type in enumerate(unique_car_type):\n",
        "  df_entire_dataset[\"num_target\"] = df_entire_dataset[\"num_target\"].replace(per_car_type, index)\n",
        "\n",
        "# print(df_entire_dataset)\n",
        "train_valid, test = train_test_split(df_entire_dataset, test_size=0.05, random_state =10, stratify=df_entire_dataset[\"num_target\"])\n",
        "train, valid = train_test_split(train_valid, test_size=0.05, random_state=10, stratify=train_valid[\"num_target\"])\n",
        "\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)\n",
        "test.reset_index(inplace = True, drop=True)\n",
        "\n",
        "train_data_file = sep_datasets + \"train_dataset.csv\"\n",
        "train.to_csv(train_data_file)\n",
        "valid_data_file = sep_datasets + \"valid_dataset.csv\"\n",
        "valid.to_csv(valid_data_file)\n",
        "test_data_file = sep_datasets + \"test_dataset.csv\"\n",
        "test.to_csv(test_data_file)\n",
        "\n",
        "\n",
        "print(df_entire_dataset.groupby(\"target\").size())\n",
        "# print(train.groupby(\"target\").size())\n",
        "# print(valid.groupby(\"target\").size())\n",
        "# print(test.groupby(\"target\").size())\n",
        "print(train.size)\n",
        "print(valid.size)\n",
        "print(test.size)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['image_name', 'target'], dtype='object')\n",
            "['sedan' 'truck' 'dedicated agricultural vehicle' 'jeep' 'crane truck'\n",
            " 'prime mover' 'cement mixer' 'hatchback' 'minivan' 'pickup' 'van'\n",
            " 'light truck' 'bus' 'tanker' 'minibus']\n",
            "target\n",
            "bus                                 53\n",
            "cement mixer                        17\n",
            "crane truck                         16\n",
            "dedicated agricultural vehicle       5\n",
            "hatchback                         3080\n",
            "jeep                               865\n",
            "light truck                        164\n",
            "minibus                             25\n",
            "minivan                            586\n",
            "pickup                             435\n",
            "prime mover                         44\n",
            "sedan                             5783\n",
            "tanker                               3\n",
            "truck                              179\n",
            "van                                362\n",
            "dtype: int64\n",
            "31452\n",
            "1656\n",
            "1743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKm-1x3KZLsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Class to load and transform the dataset"
      ]
    },
    {
      "metadata": {
        "id": "LRWlulvT6gB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#referred from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CarTypeDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, pd_dataframe, root_dir, transform=None, sq_image = False, image_channel = \"RGB\", find_edges = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pd_dataframe (dataframe): Pandas dataframe with the respectve data\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.cartype_frame = pd_dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.sq_image = sq_image\n",
        "        self.image_channel = image_channel\n",
        "        self.find_edges = find_edges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cartype_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir + self.cartype_frame.iloc[idx, 0]\n",
        "        # read the image which returns numerical transformation of image plot using plt.imshow\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        actual_image = image \n",
        "        \n",
        "        if self.find_edges: \n",
        "          image = cv2.Canny(image,10,100, L2gradient= True)\n",
        "          \n",
        "        \n",
        "        pil_image = Image.fromarray(image)\n",
        "        \n",
        "        if self.sq_image: \n",
        "          pil_image = CarTypeDataset.make_square(pil_image)\n",
        "        \n",
        "#         if self.image_channel:\n",
        "        pil_image = pil_image.convert(self.image_channel)\n",
        "\n",
        "        image = pil_image\n",
        "        num_car_type = self.cartype_frame.iloc[idx, 2]\n",
        "        car_type = self.cartype_frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': num_car_type}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def make_square(im, min_size=80, fill_color=(0, 0, 0, 0)):\n",
        "        x, y = im.size\n",
        "        min_size = x if x > y else y \n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        val_x = int((size - x) / 2)\n",
        "        val_y = int((size - y) / 2)\n",
        "\n",
        "        new_im.paste(im, (val_x, val_y))\n",
        "        return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_dCHX5hXP-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Calculating Mean and Standard Deviation across all the train images data\n",
        "\n",
        "(Outputs are commented below the print statements)"
      ]
    },
    {
      "metadata": {
        "id": "37RiX6XnU9Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# composed = transforms.Compose([\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "\n",
        "# car_type_train = CarTypeDataset(pd_dataframe=train,\n",
        "#                                     root_dir=img_dir,\n",
        "#                                     transform = composed)\n",
        "\n",
        "\n",
        "# tensor_mean_list = []\n",
        "# tensor_std_list = []\n",
        "\n",
        "# for index in range(0,len(car_type_train)):\n",
        "# #   print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "#   this_car_type = car_type_train[index]\n",
        "#   this_mean = this_car_type[\"image\"].mean(1).mean(1)\n",
        "#   this_std = this_car_type[\"image\"].std(1).std(1)\n",
        "#   if index % 1000 == 0:\n",
        "#     print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "    \n",
        "#     print(this_mean)\n",
        "#     print(this_std)\n",
        "#   tensor_mean_list.append(this_mean)\n",
        "#   tensor_std_list.append(this_std)\n",
        "  \n",
        "# tensor_mean_tuple = tuple(tensor_mean_list)\n",
        "# tensor_std_tuple = tuple(tensor_std_list)\n",
        "\n",
        "# # print(tensor_mean_tuple)\n",
        "\n",
        "# image_means = torch.stack(tensor_mean_tuple)\n",
        "# print(image_means.mean(0))\n",
        "# # tensor([0.4961, 0.5154, 0.5685])\n",
        "\n",
        "# image_std = torch.stack(tensor_std_tuple)\n",
        "# print(image_std.mean(0))\n",
        "# # tensor([0.0538, 0.0556, 0.0510])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSqClVOB3MBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Edge Dectection Sample Code\n",
        "(The sample outputs are included in the report)"
      ]
    },
    {
      "metadata": {
        "id": "B3yhsGxR3JIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# from random import * \n",
        "\n",
        "# def plot_edges(car_type):\n",
        "\n",
        "#   car_type_df = train.loc[train['target'] == car_type]\n",
        "#   car_img = car_type_df.iloc[randint(0,len(car_type_df))]\n",
        "#   image = car_img[\"image_name\"]\n",
        "#   img_name = img_dir + image\n",
        "#   io_image  = io.imread(img_name)\n",
        "#   print(type(io_image))\n",
        "\n",
        "#   edges_1 = cv2.Canny(io_image,10,100, L2gradient= True)\n",
        "\n",
        "#   plt.subplot(121),plt.imshow(edges_1)\n",
        "#   plt.title('Edge Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "#   plt.subplot(122)\n",
        "#   plt.imshow(io_image)\n",
        "#   plt.title('Oriignal Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# plot_edges(\"sedan\")\n",
        "# plot_edges(\"truck\")\n",
        "# plot_edges(\"jeep\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB3dw_BUK1or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_extra_char = \"8\"\n",
        "\n",
        "num_epochs = 300;\n",
        "batch_size = 10;\n",
        "learning_rate = 0.001;\n",
        "find_edges = False\n",
        "kernel_size = (10,10)\n",
        "neuron_count = 32\n",
        "\n",
        "sq_image = False\n",
        "acc_score = 0\n",
        "\n",
        "# model_extra_char = input(\"Enter that extra character to apply to the best model name\")\n",
        "model_save_path = file_dir + \"model_file_experiment_\" + str(model_extra_char) +\".model\"\n",
        "losses_save_path = file_dir + \"losses/losses_file_experiment_\" + str(model_extra_char) +\".csv\"\n",
        "\n",
        "resize_height = 72\n",
        "resize_width = 30\n",
        "rotation_degree= 10\n",
        "#           transforms.RandomRotation(rotation_degree),\n",
        "if find_edges:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.ToTensor()\n",
        "\n",
        "      ])\n",
        "else:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4961, 0.5154, 0.5685), (0.0538, 0.0556, 0.0510))\n",
        "      ])\n",
        "\n",
        "\n",
        "car_type_train_norm = CarTypeDataset(pd_dataframe=train,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform, \n",
        "                                    sq_image = sq_image, \n",
        "                                    find_edges = find_edges)\n",
        "\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(car_type_train_norm,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzPN8EchhjzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "          \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.MaxPool2d(2))\n",
        "  \n",
        "        self.layer_hd = nn.Sequential(\n",
        "            nn.Conv2d(neuron_count, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.fcS = nn.Linear(1344, neuron_count)\n",
        "        self.fc_c = nn.Linear(neuron_count, neuron_count)      \n",
        "        self.fcL = nn.Linear(neuron_count, 15)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)     #1 \n",
        "        out = self.layer_hd(out) #2\n",
        "        \n",
        "        \n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fcS(out)  #First   \n",
        "        out = self.fcL(out)  #Last\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uGZHD17hmVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#instance of the Conv Net\n",
        "cnn = CNN();\n",
        "cnn.to(device)\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16kZUe0Axb30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_score(acc_score, cnn, data_transform):\n",
        "  car_type_valid_norm = CarTypeDataset(pd_dataframe=valid,\n",
        "                                      root_dir=img_dir,\n",
        "                                      transform = data_transform,\n",
        "                                       sq_image = sq_image, \n",
        "                                      find_edges = find_edges\n",
        "                                      )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(car_type_valid_norm,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=8)\n",
        "  cnn.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, this_loader in enumerate(valid_loader):\n",
        "      images = Variable(this_loader[\"image\"].to(device))\n",
        "\n",
        "      outputs = cnn(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += this_loader[\"label\"].size(0)\n",
        "      correct += (predicted == this_loader[\"label\"].to(device)).sum()\n",
        "    \n",
        "  this_acc_score = (100 * correct / total)\n",
        "  if this_acc_score > acc_score:\n",
        "    acc_score = this_acc_score\n",
        "    torch.save(cnn, model_save_path)\n",
        "    print(\"Saved the model to \" + model_save_path)\n",
        "  print('Test Accuracy of the model on the %i test images: %.4f %%' % (len(car_type_valid_norm), (100 * correct / total)) )\n",
        "  return acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGVb6d9-IvXm",
        "colab_type": "code",
        "outputId": "fbe6ac51-8ba3-455f-d491-ca1a20b69dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3142
        }
      },
      "cell_type": "code",
      "source": [
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      acc_score =  valid_score(acc_score, cnn, data_transform)\n",
        "      \n",
        "    for i, this_loader in enumerate(dataset_loader):\n",
        "        images = Variable(this_loader[\"image\"].to(device))\n",
        "        labels = Variable(this_loader[\"label\"].to(device))\n",
        "        \n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.data.item());\n",
        "        with open(losses_save_path, 'wb') as fp:\n",
        "          pickle.dump(losses, fp)\n",
        "        \n",
        "        if (i+1) % 500 == 0:\n",
        "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
        "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data.item()))\n",
        "          \n",
        "    "
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1/300, Iter : 500/1048,  Loss: 0.9339\n",
            "Epoch : 1/300, Iter : 1000/1048,  Loss: 1.3548\n",
            "Epoch : 2/300, Iter : 500/1048,  Loss: 1.0902\n",
            "Epoch : 2/300, Iter : 1000/1048,  Loss: 1.2924\n",
            "Epoch : 3/300, Iter : 500/1048,  Loss: 1.9098\n",
            "Epoch : 3/300, Iter : 1000/1048,  Loss: 1.2080\n",
            "Epoch : 4/300, Iter : 500/1048,  Loss: 1.1955\n",
            "Epoch : 4/300, Iter : 1000/1048,  Loss: 1.0648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_8.model\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 5/300, Iter : 500/1048,  Loss: 0.9428\n",
            "Epoch : 5/300, Iter : 1000/1048,  Loss: 0.9657\n",
            "Epoch : 6/300, Iter : 500/1048,  Loss: 0.7440\n",
            "Epoch : 6/300, Iter : 1000/1048,  Loss: 1.0226\n",
            "Epoch : 7/300, Iter : 500/1048,  Loss: 1.0018\n",
            "Epoch : 7/300, Iter : 1000/1048,  Loss: 1.2709\n",
            "Epoch : 8/300, Iter : 500/1048,  Loss: 0.8708\n",
            "Epoch : 8/300, Iter : 1000/1048,  Loss: 0.3554\n",
            "Epoch : 9/300, Iter : 500/1048,  Loss: 0.9289\n",
            "Epoch : 9/300, Iter : 1000/1048,  Loss: 1.0462\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_8.model\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 10/300, Iter : 500/1048,  Loss: 0.9961\n",
            "Epoch : 10/300, Iter : 1000/1048,  Loss: 0.6705\n",
            "Epoch : 11/300, Iter : 500/1048,  Loss: 0.9526\n",
            "Epoch : 11/300, Iter : 1000/1048,  Loss: 0.8873\n",
            "Epoch : 12/300, Iter : 500/1048,  Loss: 1.3046\n",
            "Epoch : 12/300, Iter : 1000/1048,  Loss: 0.7393\n",
            "Epoch : 13/300, Iter : 500/1048,  Loss: 0.8230\n",
            "Epoch : 13/300, Iter : 1000/1048,  Loss: 0.6462\n",
            "Epoch : 14/300, Iter : 500/1048,  Loss: 0.3985\n",
            "Epoch : 14/300, Iter : 1000/1048,  Loss: 0.6808\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 15/300, Iter : 500/1048,  Loss: 1.8206\n",
            "Epoch : 15/300, Iter : 1000/1048,  Loss: 0.6421\n",
            "Epoch : 16/300, Iter : 500/1048,  Loss: 1.1083\n",
            "Epoch : 16/300, Iter : 1000/1048,  Loss: 0.7316\n",
            "Epoch : 17/300, Iter : 500/1048,  Loss: 1.0815\n",
            "Epoch : 17/300, Iter : 1000/1048,  Loss: 0.7571\n",
            "Epoch : 18/300, Iter : 500/1048,  Loss: 0.5709\n",
            "Epoch : 18/300, Iter : 1000/1048,  Loss: 0.3053\n",
            "Epoch : 19/300, Iter : 500/1048,  Loss: 0.7104\n",
            "Epoch : 19/300, Iter : 1000/1048,  Loss: 0.2227\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_8.model\n",
            "Test Accuracy of the model on the 552 test images: 68.0000 %\n",
            "Epoch : 20/300, Iter : 500/1048,  Loss: 0.6411\n",
            "Epoch : 20/300, Iter : 1000/1048,  Loss: 0.4518\n",
            "Epoch : 21/300, Iter : 500/1048,  Loss: 0.8277\n",
            "Epoch : 21/300, Iter : 1000/1048,  Loss: 0.9499\n",
            "Epoch : 22/300, Iter : 500/1048,  Loss: 0.8720\n",
            "Epoch : 22/300, Iter : 1000/1048,  Loss: 1.1283\n",
            "Epoch : 23/300, Iter : 500/1048,  Loss: 0.5530\n",
            "Epoch : 23/300, Iter : 1000/1048,  Loss: 2.3476\n",
            "Epoch : 24/300, Iter : 500/1048,  Loss: 0.4570\n",
            "Epoch : 24/300, Iter : 1000/1048,  Loss: 0.6523\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 25/300, Iter : 500/1048,  Loss: 0.5304\n",
            "Epoch : 25/300, Iter : 1000/1048,  Loss: 2.1698\n",
            "Epoch : 26/300, Iter : 500/1048,  Loss: 0.4956\n",
            "Epoch : 26/300, Iter : 1000/1048,  Loss: 0.8104\n",
            "Epoch : 27/300, Iter : 500/1048,  Loss: 0.6034\n",
            "Epoch : 27/300, Iter : 1000/1048,  Loss: 1.3215\n",
            "Epoch : 28/300, Iter : 500/1048,  Loss: 0.4643\n",
            "Epoch : 28/300, Iter : 1000/1048,  Loss: 0.9888\n",
            "Epoch : 29/300, Iter : 500/1048,  Loss: 0.2765\n",
            "Epoch : 29/300, Iter : 1000/1048,  Loss: 0.9409\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 30/300, Iter : 500/1048,  Loss: 1.0246\n",
            "Epoch : 30/300, Iter : 1000/1048,  Loss: 0.4348\n",
            "Epoch : 31/300, Iter : 500/1048,  Loss: 0.7216\n",
            "Epoch : 31/300, Iter : 1000/1048,  Loss: 0.5107\n",
            "Epoch : 32/300, Iter : 500/1048,  Loss: 0.8177\n",
            "Epoch : 32/300, Iter : 1000/1048,  Loss: 1.1007\n",
            "Epoch : 33/300, Iter : 500/1048,  Loss: 0.8819\n",
            "Epoch : 33/300, Iter : 1000/1048,  Loss: 0.5486\n",
            "Epoch : 34/300, Iter : 500/1048,  Loss: 0.5631\n",
            "Epoch : 34/300, Iter : 1000/1048,  Loss: 0.9044\n",
            "Test Accuracy of the model on the 552 test images: 68.0000 %\n",
            "Epoch : 35/300, Iter : 500/1048,  Loss: 0.5093\n",
            "Epoch : 35/300, Iter : 1000/1048,  Loss: 0.8805\n",
            "Epoch : 36/300, Iter : 500/1048,  Loss: 1.1189\n",
            "Epoch : 36/300, Iter : 1000/1048,  Loss: 0.4025\n",
            "Epoch : 37/300, Iter : 500/1048,  Loss: 0.4215\n",
            "Epoch : 37/300, Iter : 1000/1048,  Loss: 0.5045\n",
            "Epoch : 38/300, Iter : 500/1048,  Loss: 0.7490\n",
            "Epoch : 38/300, Iter : 1000/1048,  Loss: 1.8540\n",
            "Epoch : 39/300, Iter : 500/1048,  Loss: 1.3142\n",
            "Epoch : 39/300, Iter : 1000/1048,  Loss: 0.5461\n",
            "Test Accuracy of the model on the 552 test images: 68.0000 %\n",
            "Epoch : 40/300, Iter : 500/1048,  Loss: 0.9096\n",
            "Epoch : 40/300, Iter : 1000/1048,  Loss: 0.4531\n",
            "Epoch : 41/300, Iter : 500/1048,  Loss: 1.1593\n",
            "Epoch : 41/300, Iter : 1000/1048,  Loss: 0.5261\n",
            "Epoch : 42/300, Iter : 500/1048,  Loss: 0.2393\n",
            "Epoch : 42/300, Iter : 1000/1048,  Loss: 0.7927\n",
            "Epoch : 43/300, Iter : 500/1048,  Loss: 0.7847\n",
            "Epoch : 43/300, Iter : 1000/1048,  Loss: 0.7584\n",
            "Epoch : 44/300, Iter : 500/1048,  Loss: 0.7323\n",
            "Epoch : 44/300, Iter : 1000/1048,  Loss: 0.6023\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 45/300, Iter : 500/1048,  Loss: 0.2669\n",
            "Epoch : 45/300, Iter : 1000/1048,  Loss: 0.3208\n",
            "Epoch : 46/300, Iter : 500/1048,  Loss: 0.5852\n",
            "Epoch : 46/300, Iter : 1000/1048,  Loss: 0.1863\n",
            "Epoch : 47/300, Iter : 500/1048,  Loss: 1.0889\n",
            "Epoch : 47/300, Iter : 1000/1048,  Loss: 0.6399\n",
            "Epoch : 48/300, Iter : 500/1048,  Loss: 0.6960\n",
            "Epoch : 48/300, Iter : 1000/1048,  Loss: 0.4489\n",
            "Epoch : 49/300, Iter : 500/1048,  Loss: 0.3858\n",
            "Epoch : 49/300, Iter : 1000/1048,  Loss: 0.3784\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 50/300, Iter : 500/1048,  Loss: 0.3000\n",
            "Epoch : 50/300, Iter : 1000/1048,  Loss: 0.5733\n",
            "Epoch : 51/300, Iter : 500/1048,  Loss: 0.5166\n",
            "Epoch : 51/300, Iter : 1000/1048,  Loss: 0.8491\n",
            "Epoch : 52/300, Iter : 500/1048,  Loss: 0.3560\n",
            "Epoch : 52/300, Iter : 1000/1048,  Loss: 0.5729\n",
            "Epoch : 53/300, Iter : 500/1048,  Loss: 0.3400\n",
            "Epoch : 53/300, Iter : 1000/1048,  Loss: 0.4108\n",
            "Epoch : 54/300, Iter : 500/1048,  Loss: 0.5058\n",
            "Epoch : 54/300, Iter : 1000/1048,  Loss: 0.7472\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 55/300, Iter : 500/1048,  Loss: 0.4584\n",
            "Epoch : 55/300, Iter : 1000/1048,  Loss: 0.6033\n",
            "Epoch : 56/300, Iter : 500/1048,  Loss: 0.8456\n",
            "Epoch : 56/300, Iter : 1000/1048,  Loss: 0.2799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-c2fe57a3644f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mvalid_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DSVlzWTMvgZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_save_path = file_dir + \"model_file_\" + str(find_edges) + \"_1.model\"\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\"_1.model\"\n",
        "torch.save(cnn, model_save_path)\n",
        "print(\"Saved the model to \" + model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUm4UsnDxt_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "car_type_test = CarTypeDataset(pd_dataframe=test,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform,\n",
        "                                     sq_image = sq_image, \n",
        "                                    find_edges = find_edges\n",
        "                                    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(car_type_test,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, this_loader in enumerate(test_loader):\n",
        "    images = Variable(this_loader[\"image\"])\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += this_loader[\"label\"].size(0)\n",
        "    correct += (predicted == this_loader[\"label\"]).sum()\n",
        "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usEoTQQA0j-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "b50f8250-74aa-4191-8f05-9424fd34366d"
      },
      "cell_type": "code",
      "source": [
        "print(len(losses))\n",
        "# losses_in_epochs = losses[0::60]\n",
        "losses_in_epochs = losses\n",
        "# plt.xkcd();\n",
        "plt.rcdefaults()\n",
        "plt.figure();\n",
        "plt.title(\"Experiment \" + str(model_extra_char))\n",
        "plt.xlabel('Iterations #');\n",
        "plt.ylabel('Loss');\n",
        "plt.plot(losses_in_epochs);\n",
        "plt.show();"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8614f70b70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}