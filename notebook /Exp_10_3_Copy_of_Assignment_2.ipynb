{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp 10 3 Copy of Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f0ayvowQNK3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Referred Material\n",
        "\n",
        "**-Loading and transforming data **\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "\n",
        "-**Intro to pytorch **\n",
        "\n",
        "https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
        "\n",
        "\n",
        "-**Image preprocessing over view: **\n",
        "\n",
        "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258\n",
        " \n",
        " (*Try this*) https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        " \n",
        " (*Try this*) https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
        " \n",
        " -**List of things to try w.r.t pre-processing**\n",
        " \n",
        "\n",
        "*   Square images + batch size 10  (**Done**)\n",
        "*   Square images + bw + batch size 100 (**Done**)\n",
        "*   Square images + batch size 100  (**Done**)\n",
        "*   Random flips and rotation  (**Done**)\n",
        "*   Five crop images + batch size 100  (**Done**)\n",
        "*   Other transformation techniques  (**Done**)\n",
        "*   Without normalization  (**Done**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m29L6L_EYtQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Mounting the google drive for loading Dataset sand saving other files"
      ]
    },
    {
      "metadata": {
        "id": "kiT0P1Zh0T4O",
        "colab_type": "code",
        "outputId": "4a98f7b8-807d-4c87-c08e-7aa33210dfce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJz_lmGZDF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Installing and loading necessary modules"
      ]
    },
    {
      "metadata": {
        "id": "L5xPhzElgxSe",
        "colab_type": "code",
        "outputId": "de1b98ad-e695-4708-d664-f52f9a04bf6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random;\n",
        "import math;\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from IPython.display import clear_output, display\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 30.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wf4vVlA6IgOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05003896-e0f5-4cc4-b78c-d99dc033cf80"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMN54-l0Y2Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading Dataset to pandas dataframe and splitting it into train, test and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "jpn74UIA1LG-",
        "colab_type": "code",
        "outputId": "28739473-433f-4d58-c1d3-a9bac14cbff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/train_cars.csv', 'r') as f:\n",
        "#   print(f.read())  \n",
        "\n",
        "file_dir = \"/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/\"\n",
        "img_dir = file_dir + \"train/\"\n",
        "sq_img_dir = file_dir + \"train_sq/\"\n",
        "file_name = file_dir + \"train_cars.csv\"\n",
        "sep_datasets = file_dir + \"sep datasets/\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_entire_dataset = pd.read_csv(file_name)\n",
        "\n",
        "print(df_entire_dataset.columns)\n",
        "unique_car_type = df_entire_dataset.target.unique()\n",
        "\n",
        "print(unique_car_type)\n",
        "\n",
        "unique_car_type_dict = {}\n",
        "df_entire_dataset[\"num_target\"] = df_entire_dataset[\"target\"]\n",
        "for index, per_car_type in enumerate(unique_car_type):\n",
        "  df_entire_dataset[\"num_target\"] = df_entire_dataset[\"num_target\"].replace(per_car_type, index)\n",
        "\n",
        "# print(df_entire_dataset)\n",
        "train_valid, test = train_test_split(df_entire_dataset, test_size=0.05, random_state =10, stratify=df_entire_dataset[\"num_target\"])\n",
        "train, valid = train_test_split(train_valid, test_size=0.05, random_state=10, stratify=train_valid[\"num_target\"])\n",
        "\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)\n",
        "test.reset_index(inplace = True, drop=True)\n",
        "\n",
        "train_data_file = sep_datasets + \"train_dataset.csv\"\n",
        "train.to_csv(train_data_file)\n",
        "valid_data_file = sep_datasets + \"valid_dataset.csv\"\n",
        "valid.to_csv(valid_data_file)\n",
        "test_data_file = sep_datasets + \"test_dataset.csv\"\n",
        "test.to_csv(test_data_file)\n",
        "\n",
        "\n",
        "print(df_entire_dataset.groupby(\"target\").size())\n",
        "# print(train.groupby(\"target\").size())\n",
        "# print(valid.groupby(\"target\").size())\n",
        "# print(test.groupby(\"target\").size())\n",
        "print(train.size)\n",
        "print(valid.size)\n",
        "print(test.size)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['image_name', 'target'], dtype='object')\n",
            "['sedan' 'truck' 'dedicated agricultural vehicle' 'jeep' 'crane truck'\n",
            " 'prime mover' 'cement mixer' 'hatchback' 'minivan' 'pickup' 'van'\n",
            " 'light truck' 'bus' 'tanker' 'minibus']\n",
            "target\n",
            "bus                                 53\n",
            "cement mixer                        17\n",
            "crane truck                         16\n",
            "dedicated agricultural vehicle       5\n",
            "hatchback                         3080\n",
            "jeep                               865\n",
            "light truck                        164\n",
            "minibus                             25\n",
            "minivan                            586\n",
            "pickup                             435\n",
            "prime mover                         44\n",
            "sedan                             5783\n",
            "tanker                               3\n",
            "truck                              179\n",
            "van                                362\n",
            "dtype: int64\n",
            "31452\n",
            "1656\n",
            "1743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKm-1x3KZLsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Class to load and transform the dataset"
      ]
    },
    {
      "metadata": {
        "id": "LRWlulvT6gB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#referred from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CarTypeDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, pd_dataframe, root_dir, transform=None, sq_image = False, image_channel = \"RGB\", find_edges = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pd_dataframe (dataframe): Pandas dataframe with the respectve data\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.cartype_frame = pd_dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.sq_image = sq_image\n",
        "        self.image_channel = image_channel\n",
        "        self.find_edges = find_edges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cartype_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir + self.cartype_frame.iloc[idx, 0]\n",
        "        # read the image which returns numerical transformation of image plot using plt.imshow\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        actual_image = image \n",
        "        \n",
        "        if self.find_edges: \n",
        "          image = cv2.Canny(image,10,100, L2gradient= True)\n",
        "          \n",
        "        \n",
        "        pil_image = Image.fromarray(image)\n",
        "        \n",
        "        if self.sq_image: \n",
        "          pil_image = CarTypeDataset.make_square(pil_image)\n",
        "        \n",
        "#         if self.image_channel:\n",
        "        pil_image = pil_image.convert(self.image_channel)\n",
        "\n",
        "        image = pil_image\n",
        "        num_car_type = self.cartype_frame.iloc[idx, 2]\n",
        "        car_type = self.cartype_frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': num_car_type}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def make_square(im, min_size=80, fill_color=(0, 0, 0, 0)):\n",
        "        x, y = im.size\n",
        "        min_size = x if x > y else y \n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        val_x = int((size - x) / 2)\n",
        "        val_y = int((size - y) / 2)\n",
        "\n",
        "        new_im.paste(im, (val_x, val_y))\n",
        "        return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_dCHX5hXP-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Calculating Mean and Standard Deviation across all the train images data\n",
        "\n",
        "(Outputs are commented below the print statements)"
      ]
    },
    {
      "metadata": {
        "id": "37RiX6XnU9Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# composed = transforms.Compose([\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "\n",
        "# car_type_train = CarTypeDataset(pd_dataframe=train,\n",
        "#                                     root_dir=img_dir,\n",
        "#                                     transform = composed)\n",
        "\n",
        "\n",
        "# tensor_mean_list = []\n",
        "# tensor_std_list = []\n",
        "\n",
        "# for index in range(0,len(car_type_train)):\n",
        "# #   print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "#   this_car_type = car_type_train[index]\n",
        "#   this_mean = this_car_type[\"image\"].mean(1).mean(1)\n",
        "#   this_std = this_car_type[\"image\"].std(1).std(1)\n",
        "#   if index % 1000 == 0:\n",
        "#     print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "    \n",
        "#     print(this_mean)\n",
        "#     print(this_std)\n",
        "#   tensor_mean_list.append(this_mean)\n",
        "#   tensor_std_list.append(this_std)\n",
        "  \n",
        "# tensor_mean_tuple = tuple(tensor_mean_list)\n",
        "# tensor_std_tuple = tuple(tensor_std_list)\n",
        "\n",
        "# # print(tensor_mean_tuple)\n",
        "\n",
        "# image_means = torch.stack(tensor_mean_tuple)\n",
        "# print(image_means.mean(0))\n",
        "# # tensor([0.4961, 0.5154, 0.5685])\n",
        "\n",
        "# image_std = torch.stack(tensor_std_tuple)\n",
        "# print(image_std.mean(0))\n",
        "# # tensor([0.0538, 0.0556, 0.0510])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSqClVOB3MBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Edge Dectection Sample Code\n",
        "(The sample outputs are included in the report)"
      ]
    },
    {
      "metadata": {
        "id": "B3yhsGxR3JIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# from random import * \n",
        "\n",
        "# def plot_edges(car_type):\n",
        "\n",
        "#   car_type_df = train.loc[train['target'] == car_type]\n",
        "#   car_img = car_type_df.iloc[randint(0,len(car_type_df))]\n",
        "#   image = car_img[\"image_name\"]\n",
        "#   img_name = img_dir + image\n",
        "#   io_image  = io.imread(img_name)\n",
        "#   print(type(io_image))\n",
        "\n",
        "#   edges_1 = cv2.Canny(io_image,10,100, L2gradient= True)\n",
        "\n",
        "#   plt.subplot(121),plt.imshow(edges_1)\n",
        "#   plt.title('Edge Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "#   plt.subplot(122)\n",
        "#   plt.imshow(io_image)\n",
        "#   plt.title('Oriignal Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# plot_edges(\"sedan\")\n",
        "# plot_edges(\"truck\")\n",
        "# plot_edges(\"jeep\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB3dw_BUK1or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_extra_char = \"10\"\n",
        "num_epochs = 300;\n",
        "batch_size = 1;\n",
        "learning_rate = 0.001;\n",
        "find_edges = False\n",
        "in_kernel_size = (10,10)\n",
        "hd_kernel_size = (3,3)\n",
        "neuron_count = 64\n",
        "max_neuron_count = int(neuron_count/4)\n",
        "cnv_count = 10\n",
        "full_count = 5\n",
        "\n",
        "sq_image = False\n",
        "acc_score = 0\n",
        "\n",
        "# model_extra_char = input(\"Enter that extra character to apply to the best model name\")\n",
        "model_save_path = file_dir + \"model_file_experiment_\"  + str(model_extra_char) +\".model\"\n",
        "losses_save_path = file_dir + \"losses/losses_file_experiment_\" + str(model_extra_char) +\".csv\"\n",
        "\n",
        "resize_height = 72\n",
        "resize_width = 30\n",
        "rotation_degree= 10\n",
        "\n",
        "if find_edges:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor()\n",
        "\n",
        "      ])\n",
        "else:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4961, 0.5154, 0.5685), (0.0538, 0.0556, 0.0510))\n",
        "      ])\n",
        "\n",
        "\n",
        "car_type_train_norm = CarTypeDataset(pd_dataframe=train,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform, \n",
        "                                    sq_image = sq_image, \n",
        "                                    find_edges = find_edges)\n",
        "\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(car_type_train_norm,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzPN8EchhjzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "          \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, neuron_count, kernel_size=in_kernel_size, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.MaxPool2d(max_neuron_count))\n",
        "  \n",
        "        self.layer_hd = nn.Sequential(\n",
        "            nn.Conv2d(neuron_count, neuron_count, kernel_size=hd_kernel_size, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(max_neuron_count))\n",
        "\n",
        "        self.fcS = nn.Linear(64, neuron_count)\n",
        "        self.fc_c = nn.Linear(neuron_count, neuron_count)      \n",
        "        self.fcL = nn.Linear(neuron_count, 15)\n",
        "        \n",
        "    def forward(self, x, cnv_count= 1, full_count = 2):\n",
        "        out = self.layer1(x)     #1 \n",
        "        \n",
        "        for i in range(cnv_count-1):\n",
        "          out = self.layer_hd(out) #2\n",
        "        \n",
        "        out = out.view(out.size(0), -1)\n",
        "    \n",
        "        out = self.fcS(out)  #First\n",
        "        for i in range(full_count-2):\n",
        "          out = self.fc_c(out) #1  \n",
        "        out = self.fcL(out)  #Last\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uGZHD17hmVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#instance of the Conv Net\n",
        "cnn = CNN();\n",
        "cnn.to(device)\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16kZUe0Axb30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_score(acc_score, cnn, data_transform):\n",
        "  car_type_valid_norm = CarTypeDataset(pd_dataframe=valid,\n",
        "                                      root_dir=img_dir,\n",
        "                                      transform = data_transform,\n",
        "                                       sq_image = sq_image, \n",
        "                                      find_edges = find_edges\n",
        "                                      )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(car_type_valid_norm,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=8)\n",
        "  cnn.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, this_loader in enumerate(valid_loader):\n",
        "      images = Variable(this_loader[\"image\"].to(device))\n",
        "\n",
        "      outputs = cnn(images, cnv_count, full_count)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += this_loader[\"label\"].size(0)\n",
        "      correct += (predicted == this_loader[\"label\"].to(device)).sum()\n",
        "    \n",
        "  this_acc_score = (100 * correct / total)\n",
        "  if this_acc_score > acc_score:\n",
        "    acc_score = this_acc_score\n",
        "    torch.save(cnn, model_save_path)\n",
        "    print(\"Saved the model to \" + model_save_path)\n",
        "  print('Test Accuracy of the model on the %i test images: %.4f %%' % (len(car_type_valid_norm), (100 * correct / total)) )\n",
        "  return acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGVb6d9-IvXm",
        "colab_type": "code",
        "outputId": "27800d55-1559-489c-a043-d389743f6f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1357
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Size Data loader\")\n",
        "print(len(dataset_loader))\n",
        "data_loader_len = len(dataset_loader)\n",
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      acc_score =  valid_score(acc_score, cnn, data_transform)\n",
        "      \n",
        "    for i, this_loader in enumerate(dataset_loader):\n",
        "        images = Variable(this_loader[\"image\"]).to(device)\n",
        "        labels = Variable(this_loader[\"label\"]).to(device)\n",
        "        \n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images, cnv_count, full_count)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.data.item());\n",
        "        \n",
        "        with open(losses_save_path, 'wb') as fp:\n",
        "          pickle.dump(losses, fp)\n",
        "        \n",
        "        if (i+1) % int(data_loader_len/3) == 0:\n",
        "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
        "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data.item()))\n",
        "          \n",
        "    "
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Data loader\n",
            "10484\n",
            "Epoch : 1/300, Iter : 3494/10484,  Loss: 0.7528\n",
            "Epoch : 1/300, Iter : 6988/10484,  Loss: 0.7701\n",
            "Epoch : 1/300, Iter : 10482/10484,  Loss: 0.7363\n",
            "Epoch : 2/300, Iter : 3494/10484,  Loss: 1.2585\n",
            "Epoch : 2/300, Iter : 6988/10484,  Loss: 0.6575\n",
            "Epoch : 2/300, Iter : 10482/10484,  Loss: 7.6675\n",
            "Epoch : 3/300, Iter : 3494/10484,  Loss: 5.3659\n",
            "Epoch : 3/300, Iter : 6988/10484,  Loss: 2.5362\n",
            "Epoch : 3/300, Iter : 10482/10484,  Loss: 0.7685\n",
            "Epoch : 4/300, Iter : 3494/10484,  Loss: 0.7051\n",
            "Epoch : 4/300, Iter : 6988/10484,  Loss: 0.7589\n",
            "Epoch : 4/300, Iter : 10482/10484,  Loss: 0.6749\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_7.model\n",
            "Test Accuracy of the model on the 552 test images: 49.0000 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : 5/300, Iter : 3494/10484,  Loss: 2.6630\n",
            "Epoch : 5/300, Iter : 6988/10484,  Loss: 0.6763\n",
            "Epoch : 5/300, Iter : 10482/10484,  Loss: 0.6665\n",
            "Epoch : 6/300, Iter : 3494/10484,  Loss: 0.7449\n",
            "Epoch : 6/300, Iter : 6988/10484,  Loss: 0.6207\n",
            "Epoch : 6/300, Iter : 10482/10484,  Loss: 1.3116\n",
            "Epoch : 7/300, Iter : 3494/10484,  Loss: 0.7432\n",
            "Epoch : 7/300, Iter : 6988/10484,  Loss: 0.8454\n",
            "Epoch : 7/300, Iter : 10482/10484,  Loss: 1.3348\n",
            "Epoch : 8/300, Iter : 3494/10484,  Loss: 3.0206\n",
            "Epoch : 8/300, Iter : 6988/10484,  Loss: 3.9492\n",
            "Epoch : 8/300, Iter : 10482/10484,  Loss: 2.5528\n",
            "Epoch : 9/300, Iter : 3494/10484,  Loss: 3.8897\n",
            "Epoch : 9/300, Iter : 6988/10484,  Loss: 0.7291\n",
            "Epoch : 9/300, Iter : 10482/10484,  Loss: 0.6122\n",
            "Test Accuracy of the model on the 552 test images: 49.0000 %\n",
            "Epoch : 10/300, Iter : 3494/10484,  Loss: 1.2915\n",
            "Epoch : 10/300, Iter : 6988/10484,  Loss: 3.4336\n",
            "Epoch : 10/300, Iter : 10482/10484,  Loss: 0.6767\n",
            "Epoch : 11/300, Iter : 3494/10484,  Loss: 0.6346\n",
            "Epoch : 11/300, Iter : 6988/10484,  Loss: 0.6962\n",
            "Epoch : 11/300, Iter : 10482/10484,  Loss: 0.6507\n",
            "Epoch : 12/300, Iter : 3494/10484,  Loss: 1.3618\n",
            "Epoch : 12/300, Iter : 6988/10484,  Loss: 2.6503\n",
            "Epoch : 12/300, Iter : 10482/10484,  Loss: 3.0867\n",
            "Epoch : 13/300, Iter : 3494/10484,  Loss: 0.6882\n",
            "Epoch : 13/300, Iter : 6988/10484,  Loss: 3.3791\n",
            "Epoch : 13/300, Iter : 10482/10484,  Loss: 3.3025\n",
            "Epoch : 14/300, Iter : 3494/10484,  Loss: 0.6337\n",
            "Epoch : 14/300, Iter : 6988/10484,  Loss: 0.7284\n",
            "Epoch : 14/300, Iter : 10482/10484,  Loss: 0.6547\n",
            "Test Accuracy of the model on the 552 test images: 49.0000 %\n",
            "Epoch : 15/300, Iter : 3494/10484,  Loss: 1.2730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-cd2b174fe221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnv_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DSVlzWTMvgZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_save_path = file_dir + \"model_file_\" + str(find_edges) + \"_1.model\"\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(2) +\"_1.model\"\n",
        "torch.save(cnn, model_save_path)\n",
        "print(\"Saved the model to \" + model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUm4UsnDxt_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "car_type_test = CarTypeDataset(pd_dataframe=test,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform,\n",
        "                                     sq_image = sq_image, \n",
        "                                    find_edges = find_edges\n",
        "                                    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(car_type_test,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, this_loader in enumerate(test_loader):\n",
        "    images = Variable(this_loader[\"image\"])\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += this_loader[\"label\"].size(0)\n",
        "    correct += (predicted == this_loader[\"label\"]).sum()\n",
        "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usEoTQQA0j-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "9b691e4a-8ce1-419c-bb6b-f646b116392b"
      },
      "cell_type": "code",
      "source": [
        "print(len(losses))\n",
        "# losses_in_epochs = losses[0::60]\n",
        "losses_in_epochs = losses\n",
        "# plt.xkcd();\n",
        "plt.rcdefaults()\n",
        "plt.figure();\n",
        "plt.title(\"Experiment \" + str(model_extra_char))\n",
        "plt.xlabel('Iterations #');\n",
        "plt.ylabel('Loss');\n",
        "plt.plot(losses_in_epochs);\n",
        "plt.show();"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAHHCAYAAABN+wdFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f399f22eb38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}