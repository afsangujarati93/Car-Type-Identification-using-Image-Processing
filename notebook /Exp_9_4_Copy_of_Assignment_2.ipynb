{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp 9 4 Copy of Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f0ayvowQNK3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Referred Material\n",
        "\n",
        "**-Loading and transforming data **\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "\n",
        "-**Intro to pytorch **\n",
        "\n",
        "https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
        "\n",
        "\n",
        "-**Image preprocessing over view: **\n",
        "\n",
        "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258\n",
        " \n",
        " (*Try this*) https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        " \n",
        " (*Try this*) https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
        " \n",
        " -**List of things to try w.r.t pre-processing**\n",
        " \n",
        "\n",
        "*   Square images + batch size 10  (**Done**)\n",
        "*   Square images + bw + batch size 100 (**Done**)\n",
        "*   Square images + batch size 100  (**Done**)\n",
        "*   Random flips and rotation  (**Done**)\n",
        "*   Five crop images + batch size 100  (**Done**)\n",
        "*   Other transformation techniques  (**Done**)\n",
        "*   Without normalization  (**Done**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m29L6L_EYtQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Mounting the google drive for loading Dataset sand saving other files"
      ]
    },
    {
      "metadata": {
        "id": "kiT0P1Zh0T4O",
        "colab_type": "code",
        "outputId": "a3f35cf5-da78-46b9-b52d-f16880901f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJz_lmGZDF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Installing and loading necessary modules"
      ]
    },
    {
      "metadata": {
        "id": "L5xPhzElgxSe",
        "colab_type": "code",
        "outputId": "83beb8ad-fa3c-41b8-859a-58014a65c890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random;\n",
        "import math;\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from IPython.display import clear_output, display\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 24.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQHizK52OvDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c79bc3ab-325e-4f7d-d98b-5808e385b7a9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMN54-l0Y2Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading Dataset to pandas dataframe and splitting it into train, test and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "jpn74UIA1LG-",
        "colab_type": "code",
        "outputId": "508b27d9-d472-4eeb-b264-c29b041e97d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/train_cars.csv', 'r') as f:\n",
        "#   print(f.read())  \n",
        "\n",
        "file_dir = \"/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/\"\n",
        "img_dir = file_dir + \"train/\"\n",
        "sq_img_dir = file_dir + \"train_sq/\"\n",
        "file_name = file_dir + \"train_cars.csv\"\n",
        "sep_datasets = file_dir + \"sep datasets/\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_entire_dataset = pd.read_csv(file_name)\n",
        "\n",
        "print(df_entire_dataset.columns)\n",
        "unique_car_type = df_entire_dataset.target.unique()\n",
        "\n",
        "print(unique_car_type)\n",
        "\n",
        "unique_car_type_dict = {}\n",
        "df_entire_dataset[\"num_target\"] = df_entire_dataset[\"target\"]\n",
        "for index, per_car_type in enumerate(unique_car_type):\n",
        "  df_entire_dataset[\"num_target\"] = df_entire_dataset[\"num_target\"].replace(per_car_type, index)\n",
        "\n",
        "# print(df_entire_dataset)\n",
        "train_valid, test = train_test_split(df_entire_dataset, test_size=0.05, random_state =10, stratify=df_entire_dataset[\"num_target\"])\n",
        "train, valid = train_test_split(train_valid, test_size=0.05, random_state=10, stratify=train_valid[\"num_target\"])\n",
        "\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)\n",
        "test.reset_index(inplace = True, drop=True)\n",
        "\n",
        "train_data_file = sep_datasets + \"train_dataset.csv\"\n",
        "train.to_csv(train_data_file)\n",
        "valid_data_file = sep_datasets + \"valid_dataset.csv\"\n",
        "valid.to_csv(valid_data_file)\n",
        "test_data_file = sep_datasets + \"test_dataset.csv\"\n",
        "test.to_csv(test_data_file)\n",
        "\n",
        "\n",
        "print(df_entire_dataset.groupby(\"target\").size())\n",
        "# print(train.groupby(\"target\").size())\n",
        "# print(valid.groupby(\"target\").size())\n",
        "# print(test.groupby(\"target\").size())\n",
        "print(train.size)\n",
        "print(valid.size)\n",
        "print(test.size)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['image_name', 'target'], dtype='object')\n",
            "['sedan' 'truck' 'dedicated agricultural vehicle' 'jeep' 'crane truck'\n",
            " 'prime mover' 'cement mixer' 'hatchback' 'minivan' 'pickup' 'van'\n",
            " 'light truck' 'bus' 'tanker' 'minibus']\n",
            "target\n",
            "bus                                 53\n",
            "cement mixer                        17\n",
            "crane truck                         16\n",
            "dedicated agricultural vehicle       5\n",
            "hatchback                         3080\n",
            "jeep                               865\n",
            "light truck                        164\n",
            "minibus                             25\n",
            "minivan                            586\n",
            "pickup                             435\n",
            "prime mover                         44\n",
            "sedan                             5783\n",
            "tanker                               3\n",
            "truck                              179\n",
            "van                                362\n",
            "dtype: int64\n",
            "31452\n",
            "1656\n",
            "1743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKm-1x3KZLsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Class to load and transform the dataset"
      ]
    },
    {
      "metadata": {
        "id": "LRWlulvT6gB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#referred from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CarTypeDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, pd_dataframe, root_dir, transform=None, sq_image = False, image_channel = \"RGB\", find_edges = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pd_dataframe (dataframe): Pandas dataframe with the respectve data\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.cartype_frame = pd_dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.sq_image = sq_image\n",
        "        self.image_channel = image_channel\n",
        "        self.find_edges = find_edges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cartype_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir + self.cartype_frame.iloc[idx, 0]\n",
        "        # read the image which returns numerical transformation of image plot using plt.imshow\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        actual_image = image \n",
        "        \n",
        "        if self.find_edges: \n",
        "          image = cv2.Canny(image,10,100, L2gradient= True)\n",
        "          \n",
        "        \n",
        "        pil_image = Image.fromarray(image)\n",
        "        \n",
        "        if self.sq_image: \n",
        "          pil_image = CarTypeDataset.make_square(pil_image)\n",
        "        \n",
        "#         if self.image_channel:\n",
        "        pil_image = pil_image.convert(self.image_channel)\n",
        "\n",
        "        image = pil_image\n",
        "        num_car_type = self.cartype_frame.iloc[idx, 2]\n",
        "        car_type = self.cartype_frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': num_car_type}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def make_square(im, min_size=80, fill_color=(0, 0, 0, 0)):\n",
        "        x, y = im.size\n",
        "        min_size = x if x > y else y \n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        val_x = int((size - x) / 2)\n",
        "        val_y = int((size - y) / 2)\n",
        "\n",
        "        new_im.paste(im, (val_x, val_y))\n",
        "        return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_dCHX5hXP-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Calculating Mean and Standard Deviation across all the train images data\n",
        "\n",
        "(Outputs are commented below the print statements)"
      ]
    },
    {
      "metadata": {
        "id": "37RiX6XnU9Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# composed = transforms.Compose([\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "\n",
        "# car_type_train = CarTypeDataset(pd_dataframe=train,\n",
        "#                                     root_dir=img_dir,\n",
        "#                                     transform = composed)\n",
        "\n",
        "\n",
        "# tensor_mean_list = []\n",
        "# tensor_std_list = []\n",
        "\n",
        "# for index in range(0,len(car_type_train)):\n",
        "# #   print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "#   this_car_type = car_type_train[index]\n",
        "#   this_mean = this_car_type[\"image\"].mean(1).mean(1)\n",
        "#   this_std = this_car_type[\"image\"].std(1).std(1)\n",
        "#   if index % 1000 == 0:\n",
        "#     print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "    \n",
        "#     print(this_mean)\n",
        "#     print(this_std)\n",
        "#   tensor_mean_list.append(this_mean)\n",
        "#   tensor_std_list.append(this_std)\n",
        "  \n",
        "# tensor_mean_tuple = tuple(tensor_mean_list)\n",
        "# tensor_std_tuple = tuple(tensor_std_list)\n",
        "\n",
        "# # print(tensor_mean_tuple)\n",
        "\n",
        "# image_means = torch.stack(tensor_mean_tuple)\n",
        "# print(image_means.mean(0))\n",
        "# # tensor([0.4961, 0.5154, 0.5685])\n",
        "\n",
        "# image_std = torch.stack(tensor_std_tuple)\n",
        "# print(image_std.mean(0))\n",
        "# # tensor([0.0538, 0.0556, 0.0510])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSqClVOB3MBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Edge Dectection Sample Code\n",
        "(The sample outputs are included in the report)"
      ]
    },
    {
      "metadata": {
        "id": "B3yhsGxR3JIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# from random import * \n",
        "\n",
        "# def plot_edges(car_type):\n",
        "\n",
        "#   car_type_df = train.loc[train['target'] == car_type]\n",
        "#   car_img = car_type_df.iloc[randint(0,len(car_type_df))]\n",
        "#   image = car_img[\"image_name\"]\n",
        "#   img_name = img_dir + image\n",
        "#   io_image  = io.imread(img_name)\n",
        "#   print(type(io_image))\n",
        "\n",
        "#   edges_1 = cv2.Canny(io_image,10,100, L2gradient= True)\n",
        "\n",
        "#   plt.subplot(121),plt.imshow(edges_1)\n",
        "#   plt.title('Edge Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "#   plt.subplot(122)\n",
        "#   plt.imshow(io_image)\n",
        "#   plt.title('Oriignal Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# plot_edges(\"sedan\")\n",
        "# plot_edges(\"truck\")\n",
        "# plot_edges(\"jeep\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB3dw_BUK1or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_extra_char = input(\"Enter experiment Number ..\")\n",
        "model_extra_char = \"9\"\n",
        "\n",
        "num_epochs = 300;\n",
        "batch_size = 30;\n",
        "learning_rate = 0.001;\n",
        "find_edges = True\n",
        "in_kernel_size = (15,15)\n",
        "hd_kernel_size = (3,3)\n",
        "neuron_count = 16\n",
        "cnv_count = 10\n",
        "full_count = 5\n",
        "\n",
        "sq_image = False\n",
        "acc_score = 0\n",
        "\n",
        "\n",
        "# model_extra_char = input(\"Enter that extra character to apply to the best model name\")\n",
        "model_save_path = file_dir + \"model_file_experiment_\"  + str(model_extra_char) +\".model\"\n",
        "losses_save_path = file_dir + \"losses/losses_file_experiment_\" + str(model_extra_char) +\".csv\"\n",
        "\n",
        "resize_height = 72\n",
        "resize_width = 30\n",
        "rotation_degree= 10\n",
        "#           transforms.RandomRotation(rotation_degree),\n",
        "if find_edges:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "\n",
        "          transforms.ToTensor()\n",
        "\n",
        "      ])\n",
        "else:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4961, 0.5154, 0.5685), (0.0538, 0.0556, 0.0510))\n",
        "      ])\n",
        "\n",
        "\n",
        "car_type_train_norm = CarTypeDataset(pd_dataframe=train,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform, \n",
        "                                    sq_image = sq_image, \n",
        "                                    find_edges = find_edges)\n",
        "\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(car_type_train_norm,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzPN8EchhjzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "          \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, neuron_count, kernel_size=in_kernel_size, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.MaxPool2d(2))\n",
        "  \n",
        "        self.layer_hd = nn.Sequential(\n",
        "            nn.Conv2d(neuron_count, neuron_count, kernel_size=hd_kernel_size, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.fcS = nn.Linear(64, neuron_count)\n",
        "        self.fc_c = nn.Linear(neuron_count, neuron_count)      \n",
        "        self.fcL = nn.Linear(neuron_count, 15)\n",
        "        \n",
        "    def forward(self, x, cnv_count= 1, full_count = 2):\n",
        "        out = self.layer1(x)     #1 \n",
        "        \n",
        "        for i in range(cnv_count-1):\n",
        "          out = self.layer_hd(out) #2\n",
        "#         out = self.layer_hd(out) #3\n",
        "#         out = self.layer_hd(out) #4\n",
        "#         out = self.layer_hd(out) #5\n",
        "#         out = self.layer_hd(out) #6\n",
        "#         out = self.layer_hd(out) #7\n",
        "#         out = self.layer_hd(out) #8\n",
        "#         out = self.layer_hd(out) #9\n",
        "#         out = self.layer_hd(out) #10  \n",
        "        \n",
        "        out = out.view(out.size(0), -1)\n",
        "    \n",
        "        out = self.fcS(out)  #First\n",
        "        for i in range(full_count-2):\n",
        "          out = self.fc_c(out) #1\n",
        "#         out = self.fc_c(out) #2\n",
        "#         out = self.fc_c(out) #3\n",
        "#         out = self.fc_c(out) #4\n",
        "#         out = self.fc_c(out) #5\n",
        "#         out = self.fc_c(out) #6        \n",
        "        out = self.fcL(out)  #Last\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uGZHD17hmVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#instance of the Conv Net\n",
        "cnn = CNN();\n",
        "cnn.to(device)\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16kZUe0Axb30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_score(acc_score, cnn, data_transform):\n",
        "  car_type_valid_norm = CarTypeDataset(pd_dataframe=valid,\n",
        "                                      root_dir=img_dir,\n",
        "                                      transform = data_transform,\n",
        "                                       sq_image = sq_image, \n",
        "                                      find_edges = find_edges\n",
        "                                      )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(car_type_valid_norm,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=8)\n",
        "  cnn.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, this_loader in enumerate(valid_loader):\n",
        "      images = Variable(this_loader[\"image\"]).to(device)\n",
        "      outputs = cnn(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += this_loader[\"label\"].size(0)\n",
        "      correct += (predicted == this_loader[\"label\"].to(device)).sum()\n",
        "    \n",
        "  this_acc_score = (100 * correct / total)\n",
        "  if this_acc_score > acc_score:\n",
        "    acc_score = this_acc_score\n",
        "    torch.save(cnn, model_save_path)\n",
        "    print(\"Saved the model to \" + model_save_path)\n",
        "  print('Test Accuracy of the model on the %i test images: %.4f %%' % (len(car_type_valid_norm), (100 * correct / total)) )\n",
        "  return acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGVb6d9-IvXm",
        "colab_type": "code",
        "outputId": "a8912df0-e32f-41a0-cfa2-cbeb0f89f57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2292
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Size Data loader\")\n",
        "print(len(dataset_loader))\n",
        "data_loader_len = len(dataset_loader)\n",
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      acc_score =  valid_score(acc_score, cnn, data_transform)\n",
        "      \n",
        "    for i, this_loader in enumerate(dataset_loader):\n",
        "        images = Variable(this_loader[\"image\"]).to(device)\n",
        "        labels = Variable(this_loader[\"label\"]).to(device)\n",
        "        \n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.data.item());\n",
        "        \n",
        "        with open(losses_save_path, 'wb') as fp:\n",
        "          pickle.dump(losses, fp)\n",
        "        \n",
        "        if (i+1) % int(data_loader_len/3) == 0:\n",
        "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
        "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data.item()))\n",
        "          \n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Data loader\n",
            "350\n",
            "Epoch : 1/300, Iter : 116/349,  Loss: 1.5126\n",
            "Epoch : 1/300, Iter : 232/349,  Loss: 1.6869\n",
            "Epoch : 1/300, Iter : 348/349,  Loss: 1.6285\n",
            "Epoch : 2/300, Iter : 116/349,  Loss: 1.6194\n",
            "Epoch : 2/300, Iter : 232/349,  Loss: 1.2432\n",
            "Epoch : 2/300, Iter : 348/349,  Loss: 1.2012\n",
            "Epoch : 3/300, Iter : 116/349,  Loss: 1.3435\n",
            "Epoch : 3/300, Iter : 232/349,  Loss: 1.7100\n",
            "Epoch : 3/300, Iter : 348/349,  Loss: 1.5660\n",
            "Epoch : 4/300, Iter : 116/349,  Loss: 1.5190\n",
            "Epoch : 4/300, Iter : 232/349,  Loss: 1.3145\n",
            "Epoch : 4/300, Iter : 348/349,  Loss: 0.8568\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 26.0000 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : 5/300, Iter : 116/349,  Loss: 1.3829\n",
            "Epoch : 5/300, Iter : 232/349,  Loss: 1.1125\n",
            "Epoch : 5/300, Iter : 348/349,  Loss: 1.0924\n",
            "Epoch : 6/300, Iter : 116/349,  Loss: 1.2934\n",
            "Epoch : 6/300, Iter : 232/349,  Loss: 1.3721\n",
            "Epoch : 6/300, Iter : 348/349,  Loss: 1.1197\n",
            "Epoch : 7/300, Iter : 116/349,  Loss: 0.9475\n",
            "Epoch : 7/300, Iter : 232/349,  Loss: 1.0684\n",
            "Epoch : 7/300, Iter : 348/349,  Loss: 1.2927\n",
            "Epoch : 8/300, Iter : 116/349,  Loss: 1.4014\n",
            "Epoch : 8/300, Iter : 232/349,  Loss: 1.7057\n",
            "Epoch : 8/300, Iter : 348/349,  Loss: 1.3902\n",
            "Epoch : 9/300, Iter : 116/349,  Loss: 1.0298\n",
            "Epoch : 9/300, Iter : 232/349,  Loss: 1.0148\n",
            "Epoch : 9/300, Iter : 348/349,  Loss: 1.2559\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 55.0000 %\n",
            "Epoch : 10/300, Iter : 116/349,  Loss: 1.2409\n",
            "Epoch : 10/300, Iter : 232/349,  Loss: 1.1265\n",
            "Epoch : 10/300, Iter : 348/349,  Loss: 0.9769\n",
            "Epoch : 11/300, Iter : 116/349,  Loss: 1.1743\n",
            "Epoch : 11/300, Iter : 232/349,  Loss: 1.3416\n",
            "Epoch : 11/300, Iter : 348/349,  Loss: 0.9688\n",
            "Epoch : 12/300, Iter : 116/349,  Loss: 1.1043\n",
            "Epoch : 12/300, Iter : 232/349,  Loss: 1.2940\n",
            "Epoch : 12/300, Iter : 348/349,  Loss: 1.3721\n",
            "Epoch : 13/300, Iter : 116/349,  Loss: 1.1894\n",
            "Epoch : 13/300, Iter : 232/349,  Loss: 1.3021\n",
            "Epoch : 13/300, Iter : 348/349,  Loss: 1.4374\n",
            "Epoch : 14/300, Iter : 116/349,  Loss: 1.1677\n",
            "Epoch : 14/300, Iter : 232/349,  Loss: 1.1705\n",
            "Epoch : 14/300, Iter : 348/349,  Loss: 1.3608\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 56.0000 %\n",
            "Epoch : 15/300, Iter : 116/349,  Loss: 1.0787\n",
            "Epoch : 15/300, Iter : 232/349,  Loss: 1.2725\n",
            "Epoch : 15/300, Iter : 348/349,  Loss: 1.6058\n",
            "Epoch : 16/300, Iter : 116/349,  Loss: 1.0472\n",
            "Epoch : 16/300, Iter : 232/349,  Loss: 0.8479\n",
            "Epoch : 16/300, Iter : 348/349,  Loss: 1.2119\n",
            "Epoch : 17/300, Iter : 116/349,  Loss: 1.2519\n",
            "Epoch : 17/300, Iter : 232/349,  Loss: 1.0620\n",
            "Epoch : 17/300, Iter : 348/349,  Loss: 1.1626\n",
            "Epoch : 18/300, Iter : 116/349,  Loss: 1.2176\n",
            "Epoch : 18/300, Iter : 232/349,  Loss: 1.3995\n",
            "Epoch : 18/300, Iter : 348/349,  Loss: 0.9635\n",
            "Epoch : 19/300, Iter : 116/349,  Loss: 1.3007\n",
            "Epoch : 19/300, Iter : 232/349,  Loss: 0.8762\n",
            "Epoch : 19/300, Iter : 348/349,  Loss: 1.1054\n",
            "Test Accuracy of the model on the 552 test images: 56.0000 %\n",
            "Epoch : 20/300, Iter : 116/349,  Loss: 1.1812\n",
            "Epoch : 20/300, Iter : 232/349,  Loss: 1.0415\n",
            "Epoch : 20/300, Iter : 348/349,  Loss: 1.1692\n",
            "Epoch : 21/300, Iter : 116/349,  Loss: 0.8991\n",
            "Epoch : 21/300, Iter : 232/349,  Loss: 1.2392\n",
            "Epoch : 21/300, Iter : 348/349,  Loss: 1.2497\n",
            "Epoch : 22/300, Iter : 116/349,  Loss: 1.5830\n",
            "Epoch : 22/300, Iter : 232/349,  Loss: 1.4024\n",
            "Epoch : 22/300, Iter : 348/349,  Loss: 1.2230\n",
            "Epoch : 23/300, Iter : 116/349,  Loss: 1.2362\n",
            "Epoch : 23/300, Iter : 232/349,  Loss: 1.0772\n",
            "Epoch : 23/300, Iter : 348/349,  Loss: 1.4189\n",
            "Epoch : 24/300, Iter : 116/349,  Loss: 1.2945\n",
            "Epoch : 24/300, Iter : 232/349,  Loss: 1.2353\n",
            "Epoch : 24/300, Iter : 348/349,  Loss: 1.2731\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 58.0000 %\n",
            "Epoch : 25/300, Iter : 116/349,  Loss: 1.0690\n",
            "Epoch : 25/300, Iter : 232/349,  Loss: 1.0611\n",
            "Epoch : 25/300, Iter : 348/349,  Loss: 1.1390\n",
            "Epoch : 26/300, Iter : 116/349,  Loss: 1.0090\n",
            "Epoch : 26/300, Iter : 232/349,  Loss: 1.2057\n",
            "Epoch : 26/300, Iter : 348/349,  Loss: 1.1228\n",
            "Epoch : 27/300, Iter : 116/349,  Loss: 1.2410\n",
            "Epoch : 27/300, Iter : 232/349,  Loss: 1.3785\n",
            "Epoch : 27/300, Iter : 348/349,  Loss: 1.4007\n",
            "Epoch : 28/300, Iter : 116/349,  Loss: 0.9313\n",
            "Epoch : 28/300, Iter : 232/349,  Loss: 1.1023\n",
            "Epoch : 28/300, Iter : 348/349,  Loss: 0.8776\n",
            "Epoch : 29/300, Iter : 116/349,  Loss: 1.1941\n",
            "Epoch : 29/300, Iter : 232/349,  Loss: 0.9749\n",
            "Epoch : 29/300, Iter : 348/349,  Loss: 0.9913\n",
            "Test Accuracy of the model on the 552 test images: 57.0000 %\n",
            "Epoch : 30/300, Iter : 116/349,  Loss: 1.0768\n",
            "Epoch : 30/300, Iter : 232/349,  Loss: 0.6234\n",
            "Epoch : 30/300, Iter : 348/349,  Loss: 1.1694\n",
            "Epoch : 31/300, Iter : 116/349,  Loss: 1.3788\n",
            "Epoch : 31/300, Iter : 232/349,  Loss: 1.1588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c6b07aa22e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DSVlzWTMvgZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_save_path = file_dir + \"model_file_\" + str(find_edges) + \"_1.model\"\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\"_1.model\"\n",
        "torch.save(cnn, model_save_path)\n",
        "print(\"Saved the model to \" + model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUm4UsnDxt_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "car_type_test = CarTypeDataset(pd_dataframe=test,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform,\n",
        "                                     sq_image = sq_image, \n",
        "                                    find_edges = find_edges\n",
        "                                    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(car_type_test,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, this_loader in enumerate(test_loader):\n",
        "    images = Variable(this_loader[\"image\"])\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += this_loader[\"label\"].size(0)\n",
        "    correct += (predicted == this_loader[\"label\"]).sum()\n",
        "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usEoTQQA0j-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "a7795636-6e49-4ba2-c789-6ec812c9d448"
      },
      "cell_type": "code",
      "source": [
        "print(len(losses))\n",
        "# losses_in_epochs = losses[0::60]\n",
        "losses_in_epochs = losses\n",
        "# plt.xkcd();\n",
        "plt.rcdefaults()\n",
        "plt.figure();\n",
        "plt.title(\"Experiment \" + str(model_extra_char))\n",
        "plt.xlabel('Iterations #');\n",
        "plt.ylabel('Loss');\n",
        "plt.plot(losses_in_epochs);\n",
        "plt.show();"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd4FFXbBvB7UyGQhJoEQoDQe+9N\nQBBQRERAQUWaFVTUT3yxUl6Jigr40kWJgqggAiICElrovUOooSeBQEglIcnu90dI2N1smZmd2Znd\nvX/XlUvZzM6ezO7OPHPOc56jMxgMBhARERG5IS+1G0BERESkFAY6RERE5LYY6BAREZHbYqBDRERE\nbouBDhEREbktBjpERETkthjoEBERkdtioENERERui4EOERERuS0GOkTkciZOnAidTqd2M4jIBTDQ\nIfJA0dHR0Ol0Vn/27NmjdhPdwtSpU7Fq1SrB2yclJWHEiBEICQlByZIl0aJFCyxfvlzBFhK5Px3X\nuiLyPNHR0RgxYgQmT56MyMjIYr/v3bs3KlSooELLhMnLy0NeXh5KlCihdlNsKl26NAYOHIjo6Gi7\n26alpaFly5ZISkrC22+/jbCwMCxbtgyxsbH45ZdfMHToUOUbTOSGfNRuABGpp0+fPmjVqpXazRAs\nMzMTpUqVgo+PD3x83Ov0NX/+fJw/fx6bNm1C9+7dAQCvv/462rVrh/feew8DBw6En5+fyq0kcj0c\nuiIiqz777DN4eXlh06ZNJo+/8sor8PPzw9GjRwEAW7duhU6nw++//44PP/wQYWFhKFWqFPr164er\nV68W2+/evXvRu3dvBAcHIyAgAI888gh27txpsk1hHs6pU6cwdOhQlC1bFp06dTL5nTGdToexY8di\n+fLlaNCgAUqWLIn27dvj+PHjAAoCiVq1aqFEiRLo2rUrLl265FC7zp8/j+HDh6NMmTIIDg7GiBEj\nkJWVZdKezMxM/PTTT0VDgsOHD7d6rLdv346KFSsWBTkA4OXlhcGDByMxMRHbtm2z+lwiss69bomI\nSJTU1FQkJyebPKbT6VC+fHkAwMcff4w1a9Zg1KhROH78OAIDA7FhwwZ8//33mDJlCpo2bWry3M8/\n/xw6nQ4ffPABbt68iRkzZqBHjx44cuQISpYsCQDYvHkz+vTpg5YtWxYFUosWLUL37t2xfft2tGnT\nxmSfgwYNQu3atTF16lTYG2nfvn07/vrrL4wZMwYAEBUVhb59+2L8+PGYM2cO3njjDaSkpOCrr77C\nyJEjsXnz5qLnim3X4MGDERkZiaioKBw6dAgLFy5ESEgIvvzySwDA4sWLMXr0aLRp0wavvPIKAKBm\nzZpW256Tk1N0jIwFBAQAAA4ePIiePXva/PuJyAIDEXmcRYsWGQBY/PH39zfZ9vjx4wY/Pz/D6NGj\nDSkpKYbw8HBDq1atDLm5uUXbbNmyxQDAEB4ebkhLSyt6fNmyZQYAhpkzZxoMBoNBr9cbateubejV\nq5dBr9cXbZeVlWWIjIw09OzZs+ixzz77zADAMGTIkGLtL/ydscK2x8fHFz02f/58AwBDWFiYSbsm\nTJhgAFC0rZR2jRw50uT1n376aUP58uVNHitVqpThpZdeKtZ+S958802Dl5eX4dKlSyaPP/fccwYA\nhrFjxwraDxGZ4tAVkQebPXs2Nm7caPKzbt06k20aNWqESZMmYeHChejVqxeSk5Px008/WcyRGTZs\nGAIDA4v+PXDgQFSqVAn//PMPAODIkSM4d+4chg4ditu3byM5ORnJycnIzMzEo48+itjYWOj1epN9\nvvbaa4L/nkcffRTVq1cv+nfbtm0BAM8884xJuwofv3jxomzt6ty5M27fvo20tDTB7TU2evRoeHt7\nY/Dgwdi1axcuXLiAqKgorFy5EgBw7949Sfsl8nQcuiLyYG3atBGUjPz+++/jt99+w759+zB16lQ0\naNDA4na1a9c2+bdOp0OtWrWK8mHOnTsHAHjppZesvlZqairKli1b9G9Ls8KsqVq1qsm/g4ODAQAR\nEREWH09JSZHcLvPXKvxdSkoKgoKCBLe5UJMmTbB06VK89tpr6NixIwAgLCwMM2bMwOuvv47SpUuL\n3icRMdAhIgEuXrxYFAwUJvdKUdgrMm3aNDRr1sziNuYXdEt5K9Z4e3uLetzwIOdHSrvs7VOKgQMH\nol+/fjh69Cjy8/PRokULbN26FQBQp04dyfsl8mQMdIjIJr1ej+HDhyMoKAjjxo3D1KlTMXDgQAwY\nMKDYtoXBUCGDwYDz58+jSZMmAB4m4wYFBaFHjx7KN14gpdolpXqzn58fWrduXfTvmJgYANDU8SJy\nJczRISKbvv32W+zatQsLFizAlClT0KFDB7z++uvFZmsBwM8//4z09PSif//xxx9ISEhAnz59AAAt\nW7ZEzZo18fXXXyMjI6PY82/duqXcH2KDUu0qVaoU7t69K7ld586dw7x589C3b1/26BBJxB4dIg+2\nbt06xMXFFXu8Q4cOqFGjBk6fPo1PPvkEw4cPx5NPPgmgoKpys2bN8MYbb2DZsmUmzytXrhw6deqE\nESNGICkpCTNmzECtWrXw8ssvAyioC7Nw4UL06dMHDRs2xIgRIxAeHo7r169jy5YtCAoKwpo1a5T/\nw80o1a6WLVsiJiYG3377LSpXrozIyMiiRGhLGjRogEGDBqFq1aqIj4/H3LlzUa5cOcybN8+RP4/I\nozHQIfJgn376qcXHFy1ahGrVquGll15ChQoVMGPGjKLf1a5dG1FRUXj77bexbNkyDB48uOh3H374\nIY4dO4aoqCikp6fj0UcfxZw5c4pqwQBA165dsXv3bkyZMgWzZs1CRkYGwsLC0LZtW7z66qvK/bF2\nKNGub7/9Fq+88go+/vhj3Lt3Dy+99JLNQKdp06ZYtGgRkpKSUKFCBQwePBiTJk1CSEiI1D+LyONx\nrSsictjWrVvRrVs3LF++HAMHDlS7OURERZijQ0RERG6LgQ4RERG5LQY6RERE5LaYo0NERERuiz06\nRERE5LYY6BAREZHb8rg6Onq9Hjdu3EBgYKCk8uxERETkfAaDAenp6ahcuTK8vIT303hcoHPjxo1i\nKxkTERGRa7h69SqqVKkieHuPC3QCAwMBFByooKAglVtDREREQqSlpSEiIqLoOi6UxwU6hcNVQUFB\nDHSIiIhcjNi0EyYjExERkdtioENERERui4EOERERuS0GOkREROS2GOgQERGR22KgQ0RERG6LgQ4R\nERG5LQY6RERE5LYY6BAREZHbYqBDREREbouBDhEREbktBjpERETktjxuUU+l5OTlIznjPnQAKpcp\nqXZziIiICOzRkc2xa6no+MVmDP1+j9pNISIiogcY6MjE17vgUObmG1RuCRERERVioCMTHy8dACA3\nX69yS4iIiKgQAx2Z+PkUHMo8PXt0iIiItIKBjkyKenTy2KNDRESkFQx0ZFKUo6NnoENERKQVDHRk\nwmRkIiIi7WGgIxNf74Khq3y9AQYDgx0iIiItYKAjEx/vh4eSvTpERETawEBHJoU9OgCnmBMREWkF\nAx2Z+Br16OSxR4eIiEgTGOjIpHB6OQDcZ48OERGRJjDQkYlOpysavsrjFHMiIiJNYKAjIx+vB9WR\nOXRFRESkCQx0ZFTYo8OhKyIiIm1goCOjwoRk9ugQERFpAwMdGfl4cwVzIiIiLWGgI6OHy0Aw0CEi\nItICBjoyKhq60nPoioiISAsY6MioMBk5N489OkRERFrAQEdGZ5MyAADnb2Wo3BIiIiICGOgo4tPV\nJ9VuAhEREYGBDhEREbkxBjpERETkthjoEBERkdtioENERERui4EOERERuS0GOkREROS2GOgQERGR\n22KgI6OudSsCAIa2rapyS4iIiAhgoCOryAqlAADBJX1VbgkREREBDHRkpUPBWlcGrulJRESkCQx0\nZKQriHNgACMdIiIiLWCgIyOvB4EO4xwiIiJtYKAjI68HXTr5ekY6REREWsBAR0ZeD7p0GOcQERFp\ng6qBTlRUFFq3bo3AwECEhISgf//+OHPmjM3nREdHQ6fTmfyUKFHCSS22Tf8gwjl/K0PllhARERGg\ncqCzbds2jBkzBnv27MHGjRuRm5uLxx57DJmZmTafFxQUhISEhKKfy5cvO6nFtkXvugQAiD17S92G\nEBEREQDAR80XX79+vcm/o6OjERISgoMHD6JLly5Wn6fT6RAWFqZ080TLydOr3QQiIiIyoqkcndTU\nVABAuXLlbG6XkZGBatWqISIiAk899RROnjxpdducnBykpaWZ/BAREZFn0Eygo9frMW7cOHTs2BGN\nGjWyul3dunXx448/YvXq1ViyZAn0ej06dOiAa9euWdw+KioKwcHBRT8RERFK/QlERESkMTqDQRt1\nfF9//XWsW7cOO3bsQJUqVQQ/Lzc3F/Xr18eQIUMwZcqUYr/PyclBTk5O0b/T0tIQERGB1NRUBAUF\nydL2QtX/s7bo/y998YSs+yYiIvJkaWlpCA4OFn39VjVHp9DYsWPx999/IzY2VlSQAwC+vr5o3rw5\nzp8/b/H3/v7+8Pf3l6OZRERE5GJUHboyGAwYO3YsVq5cic2bNyMyMlL0PvLz83H8+HFUqlRJgRYS\nERGRK1O1R2fMmDFYunQpVq9ejcDAQCQmJgIAgoODUbJkSQDAsGHDEB4ejqioKADA5MmT0a5dO9Sq\nVQt3797FtGnTcPnyZYwePVq1v4OIiIi0SdVAZ+7cuQCArl27mjy+aNEiDB8+HABw5coVeHk97HhK\nSUnByy+/jMTERJQtWxYtW7bErl270KBBA2c1m4iIiFyEZpKRnUVqMpMQTEYmIiJShtTrt2amlxMR\nERHJjYEOERERuS0GOkREROS2GOgQERGR22KgI6MWVcuo3QQiIiIywkBHRm8+WhsAUMrPW+WWEBER\nEcBAR1YlfAoCnMplSqrcEiIiIgIY6MjKS1fwX71nlSYiIiLSLAY6MvJ6EOlk5+px9U6Wyq0hIiIi\nBjoy8tIVBDrX795D56+24ODlFJVbpIycvHycS0qHhxXVJiIiF8RAR0aFQ1eF/jpyXZ2GKOzFH/ah\n5/RY/HX0htpNISIisomBjowKe3Tc3b74OwCAX/ZeUbklREREtjHQkZGnBDpERESugoGOjBjnEBER\naQsDHRmZTyvXuXvkw1xkIiLSOAY6MrpxN1vtJhAREZERBjoyahQepHYTiIiIyAgDHRl5m88vJyIi\nIlUx0JGRt7vn5JgxMEmHiIg0joGOjNw++ZiIiMjFMNCREYeuiIiItIWBjow8beiKiIhI6xjoyMjL\n7Ggy7iEiIlIXAx0ZcQkIIiIibWGgIyPzHB0DJyURERGpioGOjNijQ0REpC0MdGRk3qPj7nEPe6yI\niEjrGOjIiLPLiYiItIWBjox0Op3b9+IQERG5EgY6MmMtHSIiIu1goCMzL6PxKx3cO+hhig4REWkd\nAx2ZMU+HiIhIOxjoyMzde3GMec5fSkREroqBjsyMe3SYrkNERKQuBjoy0zG6ISIi0gwGOjLzpDCH\nychERK7lZno2luy5jIycPLWb4jQ+ajfA3bBDh4iItGrIgj24cCsTBy+nYPqzzdRujlOwR0dmxkNX\nSsQ8ZxLTMWTBHhy8fEeBvRMRkTu7cCsTABBzKknlljgPAx2ZGScjKzG089KP+7D74m08M3e3Ansn\nIiJyLwx0ZKZ0MnJiWrai+xfDwFU9iYhI4xjoyIwFA4mIiLSDgY7slM3RISL7jl27i9lbziM3X692\nU4hIZZx1JTNP6tFhzSDSqn6zdgIASvp6Y2SnSJVbQ0RqYo+OzG6m56jdBKdhjg5p3dmkdLWbQEQq\nY6BDREREbouBjoI4skNERKQuBjpERETkthjokGTM0CEiIq1joENERERui4GOgjj9moiISF0MdKjI\nieupeGHhXhy/lqp2U4iIiGTBQIeKDJ6/GzvOJ+OZebsEbc8yOkRErsmTTt8MdKhI1v18AMD9PJbN\nJyIi98BAhyRjChIREWkdAx0iIiJyWwx0SDLm6Iij1xtwNikdej0PnJq4RhuRZ2GgQ+QkX26Iw2PT\nYxG17rTaTfEY5sOrd7Pu45FpW/Hl+jh1GkRF7t3Px4hF+/DL3stqN4XcHAMdBWklhSUjJ0/tJhCA\n+dsuAgC+3x6vcks816Kdl3DlThbmbr2gdlM83uI9l7DlzC18tPKE2k0hN8dAx82tP5GIRp9twLcb\nz6rdFCLV6TlspRnp2bwBI+dgoOPmPlldcLf03aZzsu+blwwiIteklREHZ2CgQ0RERG6LgY7MOteu\n8PAfGgiZ2VNPnoyffyJioEOKS0zNxpXbWWo3w6nSsnOxdO8V3Mm8r3ZTiIg8mqqBTlRUFFq3bo3A\nwECEhISgf//+OHPmjN3nLV++HPXq1UOJEiXQuHFj/PPPP05orTBcsby4dlGb0GXaFqRl56rdFKd5\n9/ej+HDlcYz+ab/aTSEi8miqBjrbtm3DmDFjsGfPHmzcuBG5ubl47LHHkJmZafU5u3btwpAhQzBq\n1CgcPnwY/fv3R//+/XHihDamKBoXI9NpYexKQynDN+7eU7sJThNzOgkAcOjKXZVbQkTk2XzUfPH1\n69eb/Ds6OhohISE4ePAgunTpYvE5M2fORO/evfH+++8DAKZMmYKNGzdi1qxZmDdvnuJttmf7uWS1\nm0BEREQPaCpHJzU1FQBQrlw5q9vs3r0bPXr0MHmsV69e2L17t6Jtk8Kgod4UT2AwGHDieiqyc/PV\nbgrJ6GZaNib8eRwnb6Sq3RQickGaCXT0ej3GjRuHjh07olGjRla3S0xMRGhoqMljoaGhSExMtLh9\nTk4O0tLSTH48iaKzTjQ2pWXZgavo+78dGPbjPrWbQjJ6b/lR/LrvCp74bofaTSFyG9o6eytLM4HO\nmDFjcOLECfz222+y7jcqKgrBwcFFPxEREbLu3xZt5Oi4lnNJ6fhqfRxS74lPXP5l7xUAwL74O3I3\ny6kycvJw9OpdLj75QFxiuuTncm4AEWki0Bk7diz+/vtvbNmyBVWqVLG5bVhYGJKSkkweS0pKQlhY\nmMXtJ0yYgNTU1KKfq1evytZukl/P6bGYs/UCJv11Uu2mqOaJ77bjqdk7sf6E5V5KInfAOJ6cRdVA\nx2AwYOzYsVi5ciU2b96MyMhIu89p3749Nm3aZPLYxo0b0b59e4vb+/v7IygoyOTHE+j1BmyOS8Jt\nF63jcvSa585Wuvyg5tCaYzdUbon7YQcPkedRNdAZM2YMlixZgqVLlyIwMBCJiYlITEzEvXsPpyEP\nGzYMEyZMKPr322+/jfXr1+Obb75BXFwcJk6ciAMHDmDs2LFq/AmateLQNYyMPqDoazjjhqxw+OZ2\nRg5SZAzaTiekofvXW7H2WIJs+yTtYycCkedRNdCZO3cuUlNT0bVrV1SqVKno5/fffy/a5sqVK0hI\neHgx6tChA5YuXYoFCxagadOm+OOPP7Bq1SqbCcxqUTM/YPmBa+q9uBGpeSYGFAQ3nb/agqh1p9Hy\nvzFoPmUj8vL1srRr7NJDuJiciTFLD8myPyISh/lT5Cyq1tERchHcunVrsccGDRqEQYMGKdAi93Hu\npvQETqHEnqfEJmcviL2Iayn3MH/bxaLHsvP0KO3teHyenStPwERERNqmiWRkInM6APl6DjSQvNiJ\nQMZ4jvEMDHRIMkVL9Ci4b3ItnJ0jTULqPSzZcxn37rOApiV/H7uBep+s4+xGD8BAR0Fq3j1ycVHX\nxzpM8vOkmOnJ/+3Ax6tO4Mv1cWo3RZPGLj2M3HwDXltyUO2mkMIY6HiozJw8bI5LQk6e8+72xCyJ\nYe0Sfyk5E/fzLOfXMCwgeig5o2CWYuzZWyq3hEhdDHQUlJ6dp3YTrHr9l0MYGX0AU9eeVrspVlnq\nlOr7vx2o8/E6TPzrJPRm4+uedLdO0jAYJvI8DHQUtHjPZcHb6vUGHLt212k9LIV3eT/tvown/7cD\ni3bGi96HkrkT9nYdvesS1p+0PbbOJRTIlT8CCan3cPhKitrNIBll5uRh0c543Lh7z/7GMrt6Jwsr\nD2uj7IizMdDRiAXbL6LfrJ0Y88thp7/28eupmLTmlEP7iD17Cx+tPC468fHg5Tu4cCtD0mvaqvo8\nM+YcWv03BlfvZBU9lpqVi9Qs8WtoKeXApTt4f/lR3HHR6tXO4qnpZu2jNuPpObtwOkHdhYgzc/IQ\nn5ypahvcxeQ1pzBpzSk8NXun01+781db8M7vR4v+7UlfKwY6GvHDjoIelZjTSXa21KZhP+7DL3uv\nYN62C1a3MU+uvXonC8/M3Y1Hv9lmYVvHTI85i9uZ9zFtwxkAQF6+Hk0n/4umk/+1muMDFCwq+p8V\nx3AtJcvqNvaYD6lZM3Debiw/eA2T1lhZ18uTzkQKcYcg6chVdZdD6fzVFnT7eitO3khVtR3uIPZc\nQU/6rfQclVviWVQtGEju57pZl6ytoYOLNu4S5RpxKLzQGedL3c2y3oPSf/ZOZN7Px7Frqfjn7c6S\nXvPX/VdEbX/pwdpWN9Oy8ft+LjpL2lLY47gl7iYaVg6Wbb+uPKzoDjzp8LNHRyO0euNpMBiKhqNy\n8vLx7rIjKrdIWZkP/tZTDgwXxJyS1is3Ino/vtl4VvLruiteEIm07/zNdPSbtQObNDgqwUBHYXsu\n3lbldeUKnIb9uA/1P12PhNR7+HXvFfx56LpMe7ZNq4GfFAcv3xG03ckb6uZiuJqNp5KYrEs25eTl\nc1KCk4xdehjHrqVi1E/KLiYtBQMdhT23YA+SM8SNxx68nIK3fj2MxNRshVol3PZzyQCAVYdvWEz+\nzcxRZgq90FPThVsZ+HjV8WJDZlryzNzdNn9vNajT0PnZkYvFtrO3MGjeLly8lQG93mAzR0qoi7cy\n8PLPB/D0nF0O74vcU3p2LppM/BfPzt+jdlM8Quo97Uz0MMdAxwnETt1+Zu4u/HX0Bt7/46j9jVV0\n/HoqGn62QbFeKyHVnQfO3YUle65gVPR+t+oFkmL+tguYveW87PvNzMnDI9O2YsKfxyQ9/6Uf92H/\npRS8+eth9Ju9Ay2nbER2rmNlFK6maDewlZujn2sNxctOFXs2GTl5euy7JKxHVUuOXr2LAXN24uBl\n9ljKgYGOE8zeYn0mUqFbFnp9Lt+WPvPHmQpnNqkh5cF08bhE26u1653YfS3b8hsidpOZk4eodXGY\ntuEMUkRMV8+6n4ezSbaP3ZqjN3DlThZ+3edYovSdzPs4cT0N6Tl5RTOJsu7nydLDQ67HHWbEKWXw\n/N04dOUunpnLHks5MNDRCK0NI59JTMdbvzq/pk8hOc+Ber0BvWduF/f6LnYSzst/+AHKzRceODw+\nczsemx5rc5kAsR/N9ScS8d2mc3aHu7Lu56HBpxvQ8cvNIl+BxHCxj7JbE/pe5DD4lxUDHSeKPXsL\nU/85LepCpJan5+zEX0dvyLpP4+DBYDBg4faLVreVM+5LybpvWrdCY2d+a0HV2mMJsr7Oncz7yDer\n8VM4tV3O9/q1JQfx7caz2HXB9pDmqQfJ16wp4hq4UDC5KtbRcaJhP+4DAFQpWxLD2le3u70j5xVH\nz0lZZhWODTDIGh9sPJVUlOgMAE/N3olnWoQX/fvirUwsuGU9ELLEUnAktadMKz1ser0BXl6OH/kT\n11PR93870KFmeSx9uZ0MLSvuxt17JsNQSgYwkpOjXfBirWSTs3Pz8d2mc+jRIBQtqpZV7oWIVMQe\nHRVc86BESmuXI/P8o6NX7+LT1VYqBLsYOa9Lcl3kft1XUMRw14XbmBlzTp6dmunwxWZ0/XqrIvuW\njVYiWI2Yt+0C5my9gAGcveYU/PSpg4EOOY1mrjFaaccDct+w2/vzpsecNVkDzBUpPYxy8PIdfLr6\nBNKytTtlVg7nbkpbZ46058rtLPy+/4pLpEY4G4euNMz8VK5UzRqhNBYfSJYrcC0qlyLyun9PxPRu\npUIKLb8LxrWPJj/VSMWWaOgGgTSty7QtAIC7Wbl49ZGaKrdGW9ij4yKS0rLR8LMNDu1j7NJDmLVZ\n2rCF+YKcQqRk3schDVaunbr2tN1tXDCVQzGufZ01eyNFvrEXb7n3qt38mLufffGuVzdIaQx0VJKv\nN2D6xrPYdSHZ/sYA1h0XNwPH0l3g38cS8PW/0tZSEpqMbLxNl6+2YNA821WB5WSpfZaua2vNjuUl\nG4uLSmoHrx6CuNthys5VZrkBRz9PWg1UXbGnistJuCYGOirQAVhx6BpmbjqHod/vtb6dA2c4LVxs\n01UeahPKFSunFuMC519NXCOMGnEtRb48pWspWaj3yXq8svigbPt0Bk4ZF+61xQfx+Hc7kOdADozc\nR/vK7SzM33YBGRo412r5k8RARyWXb7tPl7hWPuByXkcduSjLeUHPup8Pvd6A1Cz3S4pVO+55f7m0\nJS0s+X1/QdXojRJXrneG2xk5mPjXyaL6Re5O7hhu/clEnE5Iw+EHVb21oNeMWESti8Pna0+Jfq7c\nvVPGe/tw5XFZ9+0oBjoqMP94valIBWLr33IlF8C09dVR+ubx2LVUZV9ABb1mxOLlnw+g6eR/ceK6\njb9PK9GmDep0Hph9Io0aIXaxXVdiaf25CX8eR/SuS3j8u4dVwl3gYyOZUj2IWjpmhZMK9l7UVq/0\n0r1X1G6CCQY6GrBG5grE9tzJEL4WkhBq3ZkrecJxZrFGW8MH11LuYVPcTQDAz7svSW+UA9Q/savX\n9yP1cxCXmIZe02Ox4WSi420Q+Q5cv3sPzy14uGJ34bNPJRTvyRHz96Vn5+H8TdvropFrS8m8j3nb\nLiApLVvtpsiKgY4KhJ5b4pMzMXmN+C5JJRgM0Ebij0gGg+XL5O1M972bV9LmuCR8tT4OeglT9DWR\no6MQ879tzC+HcCYpHa+qkLOjVI2kedsuoMe3sTh2TTtDNySvcb8fwRfr4jDk+z32N3YhDHRUcDM9\nB0KvEz/ujFe2MWKIuFJF/WN/CrejHLluZueyqJYUI6MPYM7WC1hzzLm9kOa0PvtFC8mhjkjPzkW3\nr7fiv38Xv9Ha/KCH0VFS75ty8/WK1hQzGAx45ecDmLTGPSq1i7HtweK+7lZWgYGOClYevo65Wy+o\n3QxF6ADk5esxP9b6OlVJadmvQF24AAAgAElEQVS4fMe9vkjOYG0IQ683mNQrkjsGsLS7xFTX79oW\ncpg0Hk8pZtmBa4hPzsTCHc670UrNysXna0/ZTZbu8tUWNPxsg2LB5PHrqfj3VBIW7bykyP6VJvQj\n60kz7hjouIGcPOFVbqUS852w90VrO3UTluxxXrKaHF/n+3l6nE1KF9iTIO4VhW5tsHJkf959CSMW\n7bf9Gg4cBPN1ybRAyZO0M75Poih4PbK2aylDk5YYDAbB07En/X0S32+PN0mWtiThQZCt1BBabr4L\nRreeE7NIwkDHhR28nIIT11NR9+P1mGKhi9kaaxdMOSw/eE2xfSvp/M109Joea/X3o37aj8emx+IP\nG3/fzfRs3FQhie/XfVftbiO1ZyIh9R7mbZPW+2gei0iPTZx7FrcUhF+9k4Wv1sep8v66slE/HUDL\n/8aY9L78dfQG2k6Nwf82nzfZ1rgn507mfSzZcxmp97RXViFB472ZjHmKY6Djwp5fuAfTNpwBAPyw\nIx57Lt4W1OMgZRq2mGTkdSccn2nibO/8fhRnkqzPKNl+rqCC9eI9ly3+Pi9fjzafb0KbqZsU6xGQ\nsgzH5duZ+GTVCVxNkVZS4OhV+absu8owkPG088KP/HML9mDO1gt4/ZdDzm+QgOOm1xsQn5xp8ftv\nu+SDspfFzXE3kXovF5tOP6wv9Navh5GUZnsywMs/H8DHq07gnd+PKNo+KSb8qa0aMUK4++K09jDQ\ncRJLdS0cZZ5Q+9yCPTZ7HAp9vOqE7G0x5morY+vg+IKpWUaLZKZk2Z++H22UZO54iX/rl7IhC/Zg\n8Z7LiH2QZFjIGUXjlAhsrt7Jws+7LyFb8KKk8lzIC2tPHbysvbXbAOCzv06i29dbbebG2XNEQiG8\nG3fvYf2JRMFDXULPg4XHWa7EZzm5YqL5FI3M3lULAx0nMa5roaQ1xwrXcXLe7bOrd5WKPVLrTyRi\n2oY4q71nN+7a79qe6KQTzw0r3ezjfj/iQgnFD4/zo99sw6erT2JmjLTFad3RP8cTinoav37QwyuU\n8XdXyg1Khy8247UlB7HqyHVB29vLJSNlOKOYqpavAz5qN4DkVXjxTZa5KGB2br5LZukLbbK1YMdg\nMGCJWZXP15YU1EZpFlEWPRuEFnvOnUxxx16Jno9Zm8/ZvRu+cCvD7n7kfMvFHhdL7j9IbLVU/E4s\nOaeoK5n3Zu8K8obZcJqQtyw3X49f913BBZkWtN114TYGtKgiy76I5MYeHRch9DSqVB6EeeKgsQMq\ndefLGXbFWznhx5y+iU+sDPXdTC/oETl4OQWv/HxAxtY4Zuf5ZHz971kcumJ7KGL3BenDqVHr4rD9\n3C37Gxq5bzT7Rgfn5uzcuHsP7y076hHrPJkf1sKhFuPjvWhnPD5dfRJHZV63ae2xBEz48zhyHVj4\n0pYlVnLkLHHB+zLFePqxkBTorF+/Hjt27Cj69+zZs9GsWTMMHToUKSnaHMN2ZX8fu4FJVoY6zD/A\nit5ZuiAhF1NLM2kKD+v5m6a9HnoLO3xm7i7scWCtGaEnIaHbvbf8qKDtZm2xHrwK8eIP+4r+X2zv\niLM/pWOXHsKKQ9cQc7r4optp2bnIy9fjdEIaDAaDpAD6tsw9qHK6lZ6DaRviTB47dLl4gPPdpnNF\nidi2ziO23uoxSw/h131XsEKB2ZcJqfdM8gvtJedrMfldqV5x472q9Wdr8HAXkRTovP/++0hLK7gz\nOn78ON577z08/vjjiI+Px7vvvitrAwkYu9T6op/md6g7z99G1n3XS5ZTk5gT4onrD4+3GifSr9bH\nYeDcXSYzu5RshyOnZanndIPBgAOX7iBFwlBXQuo9RK0rXpX7XFLxYTqdTofj11LRZOK/qPXROvSZ\nuR1ztl6QdML+bb/9Kf6Fsu7nOb2y8+wt9ksEnLuZUWwYTColFkxNz+Z5zRotBxlaICnQiY+PR4MG\nDQAAK1asQN++fTF16lTMnj0b69atk7WBZNvN9OInlL+PJljY0nPZOwm4UrfunK0XcOByCv457vrv\nsbXjvjnuJgbO240u07aI3ueIRfsxf5vwmUcLd5huO8fBXi57ziWlo8GnG1D7o3WCk8Gd+fHcF3/n\nwWvK+6py9GS40NeUNEZSoOPn54esrIIM/ZiYGDz22GMAgHLlyhX19JB6PGX4SshfGZ+cabdnwNLN\ndeFDtgqWfbzqBD5f6/jsKSkXlUvJWbhlIciV0/5Ld1TJv4o5XZBELeUOPi7RtBbS5duZeG7BbqRb\nmRK8+kjxNbuUvKAu3F5QViBPb5AUyDlCyYDeGUGI825InHP+fPGHvSLKJNgm5dBofb04OUmaddWp\nUye8++676NixI/bt24fff/8dAHD27FlUqcLMe9KO49dT0dNGxWNbbqXn2J3d8/12dRZdnbnpHGZu\nOodLXzyhyP7v3c/HoHm7HdqHvfOopeEkue2ykXDt7BP9ptNJ+P3AwyGu+3muu7Ds0r1X8OFK4YXz\n5DnWrtGnYzAYrPZgGR+H7eeSsezAVQxrX91JLfNcknp0Zs2aBR8fH/zxxx+YO3cuwsPDAQDr1q1D\n7969ZW0gaYejpxnXOE0VMBiA1p/HFCu0pyZn5ijck+lO05rkjBxRF0p3MOon6TPzjl69a3VmoLPp\ndFDlvXNej470F8rXG/DU7J0Y/ZOwekGFvZdystR6VywNIidJPTpVq1bF33//Xezx6dOnO9wgclye\nTAvykXy+d6BibaG1VvJyLM0Ec5SXwufF+FumF+3Fuy/hRd7ZWpSUlo33/zgGAIJ68IS8dWpd9/Id\n+Ky6wqX6dEKaqOJ8WrqRcmeSenQOHTqE48cfRvSrV69G//798eGHH+L+fe1Os/QUa44Wzzsg65wR\nFn7+T/GZQEUcOIO/t+woLtyS/07f2XeAn6w+6dTXU9KJ6/JWof3637Oy7g9QZ4Xu7Nx8h4brPL1X\nwtjsLefRVUCO1737+U5bskLL746kQOfVV1/F2bMFX76LFy/iueeeQ0BAAJYvX47x48fL2kASL+0e\np2GKoeUvqD0rDimzWrzSPTrufM3q+78ddhetVJulekKFPl513HZgboG991On02HXhWRR+yy2D4ee\nrQ1yBWvTNpzBpduWl+woDGENBgMafrYejT7boNhCw65CUqBz9uxZNGvWDACwfPlydOnSBUuXLkV0\ndDRWrFghawNJPE8ZuLoucUVuc3O22q8x4mnEnpAtjUg4K5g5fi0VS/de0XzRQmdx9O9asueK/Y00\nwN7n658Trl+CwRF6Q8EPIN+5EiiotN39m62Y7EILhUrK0TEYDNDrC7ogY2Ji0LdvXwBAREQEkpMd\ni9rJcVqdNih3q+ZtkydAUTrx1h4t3qkq3aZrMp54n5xVUKW9XCk/WfZ3UYGhQHeX44QZZOaBTb6d\nXMS1xzwn0LF3YyLnTceKg9dw8VYmLt6Kx6dPNpBvxwqS1KPTqlUr/Pe//8XixYuxbds2PPFEQYJc\nfHw8QkOLL3JInmWayBWUSX06ABdvZeDFH/YWFY1TkphKwkKdTUq3v5EA608myrIfrZEruLR0H7X6\nyA38qdAwqjXPL9wraU2t5IwcpGVbr49la1jPGaQkKBvf3N7P02PrmZv4P4FLwYhlL8DUIkk9OjNm\nzMDzzz+PVatW4aOPPkKtWrUAAH/88Qc6dOggawPJfcyMOYeSft5qN0NztHDaMKBgVfazSRnYfi4Z\nC4e1EvX8vU4IjuSWfd85PXnrTyTikToV7W6Xl6+Hj7frrrP87jLHLqz2eoUsFdas/dE6fDekOfo1\nrSzoNdKzc9HqvzE2t5krYCh765mbqFK2JHp8G4uOtcrjl9HtBL2+EMN+3Gd/Ixt2nE/GjvMcWTEm\nKdBp0qSJyayrQtOmTYO3Ny9kajOvDisXoSXrrbE2PZq0IeHuw/d3tMjV2Id8v6fYY1JHUM17ZpQa\nib3h4OdZqNeWHMSA5uE2t9ly5iZGRe9H1IDGeLZ1Vae0S2uk1gl669fDdgMdg8EAvUG+Ycnhix7W\nydl5/jZupmcjJLCEpH1NXnMK/+lTD34+0oNcu0NXFoJEuWexaeGGzRpJgU6hgwcP4vTpguz8Bg0a\noEWLFrI0irTJuKorySc3X49lPLb4duNZxJxKsluN2hX9efi6zd+/+vNB6A3AByuOOxzoaDHny5my\nc/Ox56JpRezhi/bj/M0MTH+2mTIv6sBV/sed8QgvWxKjOkXK1x4z7jzLUQhJgc7Nmzfx7LPPYtu2\nbShTpgwA4O7du+jWrRt+++03VKxov5uWiAocvnIXh6/cVbsZqvtu0zm1m6CJWi0307IREiStd8Bd\npWblose32wRtO/6PY/jLrJbYtgd5L/svaXOI1dFZUVJyleSwIPYCBreKQJkAeSYCKEVSX9mbb76J\njIwMnDx5Enfu3MGdO3dw4sQJpKWl4a233pK7jUTkgpwdM0TvuuTwPoTMWJy79YKiMxufszAM6GqO\nXkstdowcOWSLdsXjvsCLuXmQY2yllZ61I1cdu9FQe9jmspWaOoUsfRUzcvKQaaOY4HEBFZ6n/hOH\nd34/AkDbFfklBTrr16/HnDlzUL9+/aLHGjRogNmzZ2PdunWyNY6ItE2vN+C0Roaa7thZpV4KSz08\nX66Pw7+nZJ6ZY/Qy7jC9feOpJGyQcfaaXDN9zt+0vJDsjnPWZzrdz9M7HAhpVbevt1r93ZOzdggq\n8rjlTMGxu5Wu3SKZkgIdvV4PX1/fYo/7+voW1dchIvc3I+Ys+szcruhraGA0qZird2zfQQv156Fr\nonqH9l+6g0lrTtq8E9eKNWZ1bLT4Phay9Ra8t/wo+s/eKXqfufl6zdQ0s9aKm3aCk6Hf7y32mJbf\nR2skBTrdu3fH22+/jRs3HnYRXr9+He+88w66d+8uW+OISNu+23xe7Sa4tHeXHcW/p5IEJxAPmrcb\ni3ZewnebreczaePSKi814wWpawfW/mgdIif8o4lgx9bn6yMHV6J3hcBHUqAza9YspKWloXr16qhZ\nsyZq1qyJyMhIpKenY9asWXK3kYjIKdS4JJ28IX7oz3z190LOuOhcuGV5+McWrV8Lc/P1Di04asvU\nf06jfdQmm7lDSr9vtpLsf9l7BeeS0rHMShHPqH9OI0buoVonkzTrKiIiAocOHUJMTAzi4uIAAPXr\n10e9evUwefJkLFiwQNZGEpHrketG1pk3xFlOKiJoTq4lFHLzDYhTOGdKr4EeCrl9t/k8Fu+5jAMf\n95R9399vjwdQUO8nvExJ2fcvh57TY63+bn7sRcyPvYhLXxSsgGD+9ms9iAUcqKOj0+nQs2dP9Oz5\n8INx9OhR/PDDDwx0iFyMDu55AVOK0odqwp/HJD93ogYXWzQAmPCnY0MkSkvJysXdLNOE9pvpzikq\nWchW0vWJ66mYtOYkPuhdz4ktcg8OFQwkIvew/KD86xS5wti9PbFnb1lM/NUbDLiTeV+2hUTN/bpP\nuwUkhQZ5xm//4SspSEqznvh6SsLwnTMoNZxlTdo962twPb9wL1Lv5WLgvN1ObJF9Wqg9ZY/rLqxC\nROQEH1pI1oxaF4cWUzZi+7lbDiebaqFQotIW7bxk8/ePf6fszD2phL61+XoDFm6/iKPXlJuGnmoj\nCLJH+6GIstijQ0Rkg61ZNy/+sA896oc4sTWuQ87RvaQ05w4hFVp9xPbSHYVWHr6OaRvO2N3u+l3L\nFZCVDkTSXaAcgZJEBToDBgyw+fu7d92zqBIRqSMh1bHS+HKwd8GOOX3TKe0w5gKjBbJSYmhViK//\nPStoO0fXZ3Ol7DhX/OyJCnSCg4Pt/n7YsGEONYiIqNAIo1Wi1cIcbWluqtQLo4a1ZsURPYkrxD2i\nAp1FixbJ+uKxsbGYNm0aDh48iISEBKxcuRL9+/e3uv3WrVvRrVu3Yo8nJCQgLCxM1rYRkeMc7ZGJ\nS0xHeYUSfl3dqRtpiDmt3fomGTnOn6ovpcaPlmg5pk7OyEGF0v5qN0MSVZORMzMz0bRpU8yePVvU\n886cOYOEhISin5AQjpETaVH7qM0O7+O2AmtYuTqDoSCB99uNwoZW1ODsNdCOXL2LR78RtsK5NS/8\nsE+m1rifmTGWk+ZdYShL1WTkPn36oE+fPqKfFxISgjJlyijQIiKSi1rF90hZWh3K++e448NHai1Q\nqzP7rxbl5Fn/Pl9LkWftN6W45PTyZs2aoVKlSujZsyd27hS/2JqSqpUPULsJRJrwzb/2Z6GQNK5w\nF+1M7/x+BAtiL6rdDI/V6cstajfBJpcKdCpVqoR58+ZhxYoVWLFiBSIiItC1a1ccOnTI6nNycnKQ\nlpZm8qOk8b1YtZIIAJIzOOREzrHysLBp4Fq15pi0hUOdaf+lFOj1hmLVm3PzNdrFZ8Sl6ujUrVsX\ndevWLfp3hw4dcOHCBUyfPh2LFy+2+JyoqChMmjTJWU1ECV+Xih2JyAXdZhDpVpLScnD1Tha8vLTb\nVRefnInGEzcg0wWHpF3+qtymTRucP3/e6u8nTJiA1NTUop+rV5Utrc4uZSJS2oHLKWo3gWTW+ast\n6PiF48n7SnLFIAdwsR4dS44cOYJKlSpZ/b2/vz/8/Z03JU6n6XQyIiIiz6JqoJORkWHSGxMfH48j\nR46gXLlyqFq1KiZMmIDr16/j559/BgDMmDEDkZGRaNiwIbKzs7Fw4UJs3rwZ//77r1p/QnGMc4jI\njRk0Xe2FqDhVA50DBw6YFAB89913AQAvvfQSoqOjkZCQgCtXrhT9/v79+3jvvfdw/fp1BAQEoEmT\nJoiJibFYRFAtjHOIiEguKZn3USbAV+1muDRVA52uXbvaXPk3Ojra5N/jx4/H+PHjFW4VERFpRW6+\nXu0mqKr5lI0Y0iZC7Wa4NJdPRtYaHbORiciNOTsP8efdl536elr06z5lJ9G4OwY6MmOYQ0TubP3J\nRKe+3skbqU59PXI/DHRkxg4dIiLydNm52pmKzkBHZpxeTkQkH/NKvOQa1Fo3zBIGOkREpFmrj2h/\neQQqTq+h1V8Z6MiMQ1dEROTptDRZjoGOzBjnEBGRp8vTayfSYaAjN0Y6RETk4TQ0csVAh4iIiOSl\npSRyBjoy46wrIiLydPka6tJhoCMzJiMTERFpBwMdIiIiclsMdGTGDh0iIvJ0WroWMtCRGRf1JCIi\n0g4GOkRERCSr3Rduq92EIgx0ZObFDh0iIvJw82Mvqt2EIgx0ZMaRKyIiIu1goENERERui4GO7Nil\nQ0REpBUMdGTGoSsiIiLtYKBDREREbouBjszYoUNERKQdDHRkxoKBRERE2sFAh4iIiNwWAx2ZsT+H\niIhIOxjoyIwjV0RERNrBQEdmOvbpEBERaQYDHZmxR4eIiEg7GOgQERGR22KgQ0RERG6LgY7MOHRF\nRESkHQx0iIiIyG0x0JEZZ10RERFpBwMdmXHoioiISDsY6BAREZHbYqAjs0rBJdRuAhERET3AQEdm\nZQL8sO7tzggN8le7KURERB6PgY4C6lcKQrsa5dVuBhERkcdjoKOQT/o2ULsJREREHo+BjkIqlObQ\nFRERkdoY6BAREZHbYqBDREREbouBDhEREbktBjpERETkthjoEBERkdtioENERERui4EOERERuS0G\nOgry9uJS5kRERGpioKOg7eO7qd0EIiIij8ZAR0GVy5RUuwlEREQejYEOERERuS0GOkREROS2GOg4\nSVAJH7WbQERE5HEY6DjJqE41FNv3k00rK7ZvIiIiV8ZAx0l0Cs40/9+Q5srtnIiIyIUx0HESpeKc\nauUDFNozERGR62Og4yQl/bwV2e9fYzopsl8iIiJ3wEBHYe/3qovHGoRiUMsIh/dVJsC32GNBJZnk\nTEREZA2vkgob061W0f+vfKMDfL290Pd/OyTt6/AnPRE54R+Tx3RKJv8QERG5OAY6TtS8almHnm8r\nqPHSAXqDQ7snIiJyOxy6chNLRrVVuwlERESaw0DHTXSoVUHQdk2rBNv8PVdcJyIid8JAx0U81iBU\nlv20iSwny36IiIhcAQMdF9C3SSV8J1NRQLmTl2uHlJZ1f0RERHJSNdCJjY3Fk08+icqVK0On02HV\nqlV2n7N161a0aNEC/v7+qFWrFqKjo5VvqELKlfJDzYqlbG7TuXYFfD2oKUr4KlOHx5zBIC6juWHl\nIIVaQkRE5DhVA53MzEw0bdoUs2fPFrR9fHw8nnjiCXTr1g1HjhzBuHHjMHr0aGzYsEHhlirjkToV\nMfM52z01i0e1dVqQI0WZAD+1m0BERGSVqtPL+/Tpgz59+gjeft68eYiMjMQ333wDAKhfvz527NiB\n6dOno1evXko1U3Y1KpbCxVuZ6KfBxTjb1SiPXRduC95+XI/aOH8zAwNahOOTVSeQeT9fwdYRERGJ\n41I5Ort370aPHj1MHuvVqxd2795t9Tk5OTlIS0sz+VHb3292wvpxndGtXghEjhQ5zF5Ozfje9UTt\nr0yAH5aMbosBLao40iwiIiJFuFSgk5iYiNBQ09lHoaGhSEtLw7179yw+JyoqCsHBwUU/ERGOL8Xg\nqAA/H9QLK8ht0Tsh0hnZMRKvd62Jv8Z2xIAWVVC+lPXhpgA/b4QE+iveJiIiImdwqUBHigkTJiA1\nNbXo5+rVq2o3yYQzAp3S/t74oHc9NKlSBt5eOozuXMPqto405+tBTaU/mYiISAEuFeiEhYUhKSnJ\n5LGkpCQEBQWhZMmSFp/j7++PoKAgkx8tccqyDU5aD6tP40pWfzeiY3WntIGIiMiYSwU67du3x6ZN\nm0we27hxI9q3b69SixxnPJ27aUQZtKhaRvbX6NMozPQ1YT260umUiYsqlOZwGBEROZ+qgU5GRgaO\nHDmCI0eOACiYPn7kyBFcuXIFQMGw07Bhw4q2f+2113Dx4kWMHz8ecXFxmDNnDpYtW4Z33nlHlfbL\nwTjkWD2mo93p5mLt+k931K+kTi/WgObhRf/fpXZFVdpAxZXUcLkCV1StfIDaTSAiG1QNdA4cOIDm\nzZujefOCi/u7776L5s2b49NPPwUAJCQkFAU9ABAZGYm1a9di48aNaNq0Kb755hssXLjQpaaWm9M7\nMHbVsVZ5u9tULlN8SK91dXmWgbAXQDWNeNg71djOGlvkPGvf6qR2E9xKgJ+qVTqIyA5Vv6Fdu3a1\nWYnXUtXjrl274vDhwwq2yrnM4xzjw2FpCGnpy22x9lgCPuhTD4H+0t6+KmUt5zOZv749HWvaDrS8\nzBYIjShXElfvWJ4dR85To6Jzl+0ILumL1Hu5Tn1NIqJCLpWj445qhlhfAsJSqkyHmhXw+dONEVTC\nV/K6VfaCmVe61AQA9GoYiktfPCHpNQCgVbWyaFIlGE81qyzodck9LX25rdpNICIPxj5XlYUElsDG\nd7qg1IPeGeNEYbkX4BRCpwNGdqyODjXLo5ad4oL24hZfbx3+GuvewySvdKmBBbEX1W4GqUjs+nBE\n5Fzs0dGA2qGBRbk0QSV8ix739lIm0LEXP+l0OtSvFARf74KPx9C2VdG1bvFkYrHnd0v5Qq6uajnX\nTETd+Z/uTnstncW+SffRLEL+mZJEJB8GOhpT1qhqsY9CgU5YUAlR2099ujGiR7Rx+HX/00fc8hKu\nYHAr9SttSxHuxKDTVjkDV/f1oKYm31ki0h4GOh5Ip9Phw8edH3SUdcOVzv18+BWy5aX21dRugqLK\nl/Jz8/4qItfHs7SGKXkCHdExElOfblzs8VI2ZnLFvNvF5N9i79SdlcswtG1Vp7yOO1FqmHRiv4aK\n7FcrAkswzZGKs7d4sjU1K1qfnELSMdDxUL7eXiYBQbe6FfHR4/VtDmnUCglUvF29Goba38iO/z7V\nSIaWCBfg5/oF+BaPdHxo0hI1EuqdqWW1skW5bESFSksMgN39+6IWfkMJAPDqIzXxchfri31aIraD\nRsiXeP6LrcTt1My/73QpVr9HKdEjWgMAflIoSHAX5p+Tpm6SvNuyWlnodDoEl/S1vzGRAAyalcGj\nqkHv96oLAPjimSaKv9a3g5vija410TZSWLXkf97qLGLv8gUck58SNgRSJ1T5XicAaFg5CF3rhgBQ\ndojRlf01tqPFx4M43GPiWRdNaCf5+TPnTxE8qho0plstnJjUC082raz4aw1oUQXje9cT3GXaoLL0\ndbMcCQiGta9e7LH5L7Z0YI+OMV5GI0JjU8xrVBA/zq9E9pS/j+sP6dlSmHPWrob9pVisaVolGN3q\nhTjUjv7NlD9PkDhSz3Vch04ZDHQ0qrTE5R2cyVJy8ZJRzquCW0bCkEGziDKoFxbocPKt8Qyy0KAS\nqBiondXZA/zlOVk2DndsfTJLyepfPdPE7SpkOxL8y6EEL46aI/Uj/mh9x4JesoyBDklm6cvctobj\nC4aWDVAu58HXW4e1b3XGyUm9HAomzTvAmmso72T64Gain2Mp+IiU0DNkb5+DW0cUC4DMY84X2lUV\nNXNu+/huaFmtrColExwlR8znboGjJ+PQlTJ4VMlpzIOD1x6paXG71WM64a1HayvWDm8vncN3wVrO\ny6kdGoi/3xS39IYSRf2sXYDtXZg/e7KhxdIHhczXX4soF4AVr3coWqNNa0Ls9PaV8HXOabhSsLhC\noY4KDdJOL6ez+QlIKrY0W5OzrpTBQMeN/DW2I3o3DBNd+VgqsXeSxstb6HTWKyVXLR+Ad3vWcaRp\nijM/H2nt/NTIaNhJalFDe29v59oV7Dy/YA9ilv4I8PN2mZkncvXGdK5dfHkVoKAYoZxcaQmW5lWV\n6yH9bkhzRJRT9lhInYknZAhcS8PkrsI1zigkSJMqZTDvxZaoVt45ybFVyoo7WVha3kJMz4P5tlLu\nfpy17tIXA6z3SDibXi9/b83+j3rgoyfqC9q2XCk/rH2rEza/9wgAzxtqea6N7WE4by8dXrFQ2mHZ\na+0F7d8AA7pZWIuu2HZ2DvzJSb0wsmOkzW12iVgjzZH3ec7zLaQ/2Y5+TStj+3jnrfVmjaUzUc/6\njtcRA7j+mjkGOiTa4jAy4A0AACAASURBVFFtMKJjdQzvWN3mdkLikEbhwYLvfho5mBxrzpFKzfaC\nLFsVph1VJ7Q0ygb44unm4YK2LyNzzlO/ppVRMdAf9cKC8LGNYMf48DasHIwaFQuqxQodJnusgTwn\nfbU1ixD/uf3o8fqoWVF4dd0fh7e2+XshPRhCPrOu1CukdebfghoVSgmqASZkqFOOXElHNQpXN0nf\nGAMdEq1z7Yr47MmGqkwf3vZ+V6e/piXmpf/Ne4qUHMoKLumLAx/3xLeDmwra3tfbC3+/2Qk1K5bC\nrKHNLW5jLeZ7ysLU5e+GPNzH6M7Wi0zWslIG33yoxjgp3LgdoU4agt3xQTf88JJjhSqlkiM3Sged\nzcB7ZMdILB3dzintaVWtrNG+SIxfXhY2Y/XxRpUUbok8vDQ0ns9Ah1RhHBiI6VmpVl78TCBrC0tK\nPRH3bBBqd9VypYfIxE6PbxQejE3vdUXfJpZrrlg7FpP7SVtOo031clYTvl/uXANfD3oYpFk7llIu\num9LSGKvUjYA5VRegdyR3kV7x+nTJxtYrfX0SJ2KeKNrTWwY18Xi78WS69qmgw5LBV74tUjsu9mr\nYSgqBQvrLfPx1k4AYa5TrYd5e1pqJQMdN6TmnZTx+VqpD3qDSkEo7e+DJlWEDQkUVjB2xMznmuHd\nnnVw6JOe+H5YK7uztuQ44b/cORJjutXEslfbmyz256w8Iymv8s2gpmgUHoRvbPQ2+fl4YWDLKkX/\n9rfSFS8ltegdjSexm1M7XymopC/G966HumGBdtvToJK4oQhH/7bqEm5q7HFWJ4OQwFXRphikT0Jw\nhPGwmpZ69LRflY7ckwPf8r/f7IQ8vcHmF3nu8y3w97EEPN+2KtrXlF65FigocvdUM2H5MHKqVr4U\nXmhX0Bv186i26PjFZgBApweznXQ6HbrXC0FK1n0cvnLXodeyttqy2F6Vfs0q4xmjIMYRSiRRy0nJ\nIEWJ6f6CXtfGH/VJ3wZObIl9z7etil/2XhH1nL0THlWoNaaEfDaMNxFz8yJ02zVjO+HHHfEY1TkS\n/1lxDIccPEcIY9xT74SXE4g9Om5IzS5D4zsmoZ/zAS0KLoxNBfbQeHnp7N6t9GlcCbOfb4EOtSo4\nXJticGvxaxFZesXC5LxPHbxgvGS0HMaPw1vjz9c7OLQ/QDtJpsarPudrMND5oLdjRQmn9G+E+kY9\nI4UXA0cuClq6oJiS1rDgkr6oUNrPbu/L5zZqLVkT4qS8L71Mb0rMu8WHFIUGwXXDAvHlwCaoExqI\nP9/oiBnPNsOrj4hbuNldMNBxQ5o97xkxPof9p089zHm+BX4eaXlMfpBMPQRKElJXZ9aQFjj4cQ+M\n7BRpMpYthPGdtre3eeKzMqGtpc+RveJ3UluyaERr1AsLxCKj2UP5Fi4WxkN4zja8Q3W83lV4UcKw\noBIY3qE6qhrlx7zYrhrWvS1mYVz5WHo//++xOna3KST2YxZYwldS9fH9H/WAj7cXwoJKCJo2D8Dk\nGBtTcpq6LUJidOPDae3Y1gqRuEixhf31bx6OCX2ElYSQSkP5xyYY6JCspOTolPD1xuONKyHYyjRo\npb48xm2tHVJa1LID9pk2+qlmlVGtfADKly4IFH4e2QbHJj4m4+spw7ibvFF4EJaMlj9BtG5YELrV\nDcH6cV1MSghYGroSM+UaAHrUD7W5OK6tCszmnhf5+dg9oTsm9muIWiGBmPdCS/z5hvCeNzFDGY7c\n2Jgn98vZOzT3hRaSFrwt7K3V6XRYNKKNoNXufawk5xfmHsmlT6MwQdvJ1aMDAD+NbIMvn3n4Oe0u\nZBFYle52NRrnMNAh7bN10nd0GMj0deRjXrRx5nPNTXpevLx0JpWiLVH6XFXYq9RCYBXaH19qjTqh\n8l04/n6zE6Y81RB9G1ueLpsvwwF4pE4FPNPCen6VmODWfLq8veYZv9+9G4WhRdWyNrY2pVqOjo3X\nFfL9ML6+1wuznrwspmdMS+a+0FLQdkLinH5GpRts3cw9Uqci+jV9+BkO8NNuai17dMh5XGDsSq4v\nxMhOkSZ3O2IYr7VlANCrobC7NUuM/57t47tJLgHvTLOGNsfEJxvg+2Hq1JBpFB6MF9tXt1okzcEF\n5gEAQ9taLi0ghRJDhHJ+VcMf5Fl1qlUB9Sz0ZAhKkHXSuUPMMjVCj7ulpRHUuu4K6dH5tG9DwfvT\nagBhi1rBuiUMdEhWxh9uZy1QVyZAWg2UN7vXMvl3lzoVRS+GaYl5d32dUHHDLZYoMW2/TIAfhneM\nLBpO05r3e9VF5eAS+PDxeqj7oCdJaDXoQt5etovpWdL0Qfn8ASJfy5jQz5GY+jljulnuBSmc9r3s\ntfYY16M2Zj4nfvX6Qo7mfws91GJqwQg9Rs5KqP/wcdsJ6QF+3hYDHfNinSUtLOophZy92o4y7qX2\n9tJOeKGdlpBHcVYtGFss9STItcxEBaPgYdWYjpL24a+BxS19fR4eIyGVsOUMbquUDcDO/3THK11q\nYtWYjlj7Vif0FpgjYUzsuj+r3uiAf9/pgmmDbFeebmljKKphZXnL37erUQ7v9yp+gf3o8fp48UFB\nzPAyJTGuRx2UL+0vuWfG0oraSmldXfhQnj3W/lwl+hSqlLWed9S9XgjWvtXZYsDYt0ll9KhvOb9G\nVE6W2b7bRCq73MOjdnKCjE+jxusZ+srRJSsT9c+kJDstdRlqjpXvniOVaQt2a7pjPx8vnJjUCycn\n9bI5pv7VwCbFHnunRx20iSxnMoavlgA/H0x9ujGmPNXQarK4kgoDp5J+3mhYOVhSICV2GFGn06FO\naKDV6tOb33sEE/rUw//1kq84ofmnz/zjaO1C+HKXGrKu9j66s/VFPaUtomvtce1cBMWydar4cXhr\nRFYo5fD5xObrG31a5j7fwuLNmZyvbi2h/O1Ha+PYxMdMPhfdZCjOqgQGOiQrX6PuygqlrQ8piTln\nukLgZqmNpf197C6UOLhVRLEFF9/uURvLXm1vt/qy4LY5ePiGtq2KF41q92idtRk45qROPa5RsTRe\nfaSm6kmhY7vVsvq7AP/inx0hH4NAOwnyYll7TblHtbUWNlkrrmj1uyjmfGi0jxbVxPeKda4trrSF\ntfcqNKgEgkr4mgR17WuWxxsaTDRnoEOy8vLSIfb9btj03iOynzSt0dpJTqxVb0gb2rLnq2eaIKiE\nD2ZLuKAHl/QtVmPFVXR4MJss3EbOxhONK+FxK7O9nEloEGp+sRneoTres/H+fD2oKeqGBposwKo2\n8/W0alQQlrsm5BApcSu090PpVZSbVCmDj59QpmaNcSFNKQFjYRBmKXlbDk2qFAwVa+n2VLvz1Mhl\nVS1vv3aGloOTquUCcOVOlqjnONIVr1Qy8ODWERjYsorVWU3mJj/VEJ+uPomoAY3xbKsIwc9TU40K\nxQsIzni2GZbsuYwBNqaVa43YXrfwMiVtDiXVrFgaG94Rv1BnSRu9iJZebtHw1hgRvV/Qvs1r2nz4\neH14e+vwTItwPDN3t6h2WmyfyO3rhgbiTFK61d+HOlhF2VLPogwdOiaFNL0lRDp1QgOx44NuKF/K\nH/U/XS/6+fZocYYYe3Tc0OdPN0bZAF/NrU0DPFxJ/IM+jpXSl5txPsaSUa67arI5McHKsPbVcWJS\nLwxpU9UlghzAtERAoXKl/PDWo7VtJo2aaxwejHphgcKKscmgcLmTZ1pKC8akDOe2q2E/adXbS4dT\nk3vhxKRedrdtXb0sujlwvIIDfDH16cZoWU2eZFqxR2TFGx3wYjvh5QcKe0AsDQs6k3Fw4/MgP6ux\nWZ7OI3VsV5SuUjZA8KyvSAs3E66GPTpuqE5oIA590tNp07vFmNivIV55pKbNYQU1eBkdq6rlA1Av\nLBBxidbv9tyVlJL9xpz+iZPpBX28vSwuzdC6elnsv5SCp2RODP/l5XY4du0u2kZaXnC2r1k1Zx+z\nhGMpPYjv9KiD+dsu2t3OWu6RkFdsHF4G+y+l2N1OC2em0v4+aF61DBbvuSxo++WvtgdQvNerc+0K\n2H4uGVEDTOt5tbHy3lpi71xt/OsyAb54pUsN6PAw0f7nkW3QfMpGAAXFGDuKXGLGkvkvtkRSWjae\nbh6OT1efdHh/amKg46a0GOQABe0SG+TYO6kLmXVSo0IpXEzOxJNNLOdlBAooM2+TEw+3Rt9aTWsb\nWQ574+88fMDCMbT0nVk4rDU2xSWJLiZp7/tX2t8HHWo+vBi1qFYGP+4s+P/jEx8rym/7b/9GWBB7\nEZP7mRaXk/IZKOHrjS51KiL27C3xTwYQEmh/KOf/etVBcEnfojIA1mYfyf0ZNhgMFr+CUl5m0YjW\nRXWbjFW30rOxeFRbpGXnFqt03qByED5+oj7+u/a0STvtea9nHXyz8azJY8a9OKX8ffDh46b5P8bT\nupuLLKdgTatqZYuG1Ve+0QG30nPwyuKDxbab/mwzvP3bEcVykuTAQIdcXufaFdC+Rnk0sFG7ZOWY\njjhxPRXta5jeZc18rhnmbLmAL58xneY9sV9DPLdgD97qbn1mizMZF1hz5am5avn15XZIy85Fs8kb\nRT0vOMAXA1rYX1T2r7Ed8davh3HptrjcrkJPNK4E/ZCCIQjjJP4X2lXDCyKGV5Qye2gLQbl3AX4+\neLtHbSe0SBgpCbFSpkhbW86lYWVhdbmMv9GW2uzj7YWZzzVDTq7epEaXxX3JFEUat6N51bK4cfee\nxe2eahaOng1Ci3oCu9UNwdFPH4OG6gUy0CHts5eP4OPthV9faWdzm+CSvha7c59qFo6nmhXPk2hX\nozzipvSWbYq3oyoFl8SL7aqhhK+XzbH1QAeHnlyN0FO6l5dOcgVtIZpUKYMFw1rhsemxkp6v0+nQ\nz8bio3KpXj4AhS0UmsNXLywQTxj1hBYO5w1pY3+dMGsXXU8N1h2ZiWTpPKUVxsOdfj5eRQuzaoVn\nnRWJRBAT5DjjtD2lfyP77fDM64donnqYxvWog593F+SkSE28XjK6LS7eyrS4npYitDRPWSSh30fj\n7bTy2TRvh5cLn1y0FXYREYngwtdAVUhZ4sG8V8bfxxv1KwU5NERinFOiJil/gqMJ+8YK8xWfkLGm\nk1LhSGiQNtfEE4I9OkRuJCzYsdofjnLhmz5SgHny7beDm+LYtVS76ydpmVzr4QHA+nGdEZ+cWWx6\nuBbpdDqsGdsJT87aoXZTRGOPDpEb+P2VduhcuwLmvdBS7aa4BCVmJdaoUArVywcUrX6uRVL+bDmP\n1IAWVTCxX0PN1GmSusL24U96ol5YoN2VzO0JLOGLJlXKaHKWrKXe0sZVHgZkGmyyVezRIXIDbWuU\nR9sawut2eLoqZeWv4+Tj7YVN73WFM67hzrwwqn1BK+Xvg/ScPJvbSB3ClLqCetlSflg/zn7l6bJm\nCfAKrvXpdK70t7BHh0gGWrwjo+KWjGqLIW2q2lwQ0xHeXjq3+yyo/ecsfKkValYshe+HtbK5nbV2\n2qrbJWUJBTHqhgViQp96mPlcM8HPUft4F9JIM2TBHh3SPDEVRols6VS7AjqJXL1Zi8LLSMvFMr6w\n2yuS+fET9fHNv2cx9enGNrezRY6gr1F4MDa919XudtZWre/ZIBTRuy7Zff7PI9ugajnhy4YI9arR\nMiUu1Alil1YCMiEY6JBmbR/fDYev3kVfDawyTcIYDK51AnQ10SNa48jVu6IrNRfy8fbC98Na4V5u\nvt3Cc6M718CIjpEm68Bp2dSnG+PFH/bh9a418dlfApcsMPrTGocHa2Y2mCOc9f1zpaErBjqkWRHl\nAhChwB2WElzjUqCsng1CNZNk6q661g1BVwmVe431bBAqeFtHgxwhSx6IUaG0H5Iz7qO8hYCkdmgg\ndk/oDr0BwgMd8gjM0SEiWYzsGKl2E8hFFSYFN69qe8bary+3Q98mlfCbWSX0wnhK9FCZk3slhAR+\nhYGsw+vvKcyVem61fSSJiGyoUNr1hxoImPdCS/x56DqebmF7mYPaoYGYNbSFk1qljoKcpEcQGiQt\nD8uVAhBnYY8OkQx4crG/JpmcZg1tjlcfqSFpAUbSnvKl/fFylxp284ZcXZfaFQEAft62L701K5aW\nXIFZzGhh3ybi8x+71a0IPx8v9GkkLU9MDezRISKX07dJZfRtovwimERyGtGxOioG+qNNZDm1mwIA\n+N+Q5vj7WIKo5/w4vDVy8w2aW7jTFtdpKZGGNddwNVxn8dQVqT2dreHDJx+syF6zYilF2xAS6Bo9\nQT7eXujfPByVbdT2cZSY3mXznKbXuz6cCm9tUWOdTudSQQ7AHh0iWbzQrhq8vb3QvoY27tSInOXL\nZ5pg1E8HLP7u1S41UC8sEC2rSatAbM+SUW0xP/YCPu9vudaPtdo6ZNkHveuhyYN1t0rJuHip2tzn\nLyFSkY+3F15sV83h/URWUPbOl0hutkoK+Hh74dH6wqezi2WpAKS3lw7DO1RH2r1cRQoAap3YntV6\nYYGIS0wvWqOtjxvWLWOgQ6QhA1tWUbsJRKK0qFrQWxMapJ3ho4n9GqrdBJcRPaINftt/BUPbVFW7\nKYphoEOkAaM6RWL9iUS80NbxXiEiZwou6YsTk3rZnUlE2hQWXALjetRRuxmKYqBD/9/evQdFdZ5/\nAP8uC8tFWBYBuSi4WFREiSJUBBO1cUdiTNTYXyQOVUSjNeKvUhNNbUw0zUSoSazGMTHNjJcxNCa2\nXlprtBQFoyEgCCiXMSaA0ISLBLmpVWSf3x+/8cRVNBLWXVi/n5kz4573Oee87zNZ9sk55z2HeoBX\nnwrF6qnDbO6FkPRw+KlToXu6Pho1Ll/vgL/7T3umjVXwT8gdWIIT9RAscoh6lr1LxuGpR/yw6/ko\na3eFusE2y3AiIqIf4XDL5Ta1+s7/0Rjq2/uexKxzdrB2F3ocFjpERPRQ8uijwf8+HgyVSgWtU+8u\nEN5+diSqvr+M8MAHM5W/N2OhQ0RmwStv1Bu9OHmotbtgFpyxeXe8R4eIzKIr79ghIrIUFjpERGSz\n9J4P30MDyRQvXRERkc2KHzsQda3X8NhtT1CmhwcLHSIyC96jQz2Rg9oOLz8RYu1ukBXx0hURERHZ\nrB5R6GzZsgV6vR5OTk6IiopCbm7uXWN37NgBlUplsjg59aKnVhIREZHFWL3Q+eSTT7B8+XKsWbMG\np0+fxsiRIxEbG4v6+vq7bqPValFTU6MsFy5csGCPiagzdrx2RUQ9kNULnQ0bNmDhwoVITExEaGgo\ntm7dChcXF2zbtu2u26hUKvj6+iqLj4+PBXtMRLeaFTkAY/R9ETGQDyojop7HqjcjX79+Hfn5+Vi1\napWyzs7ODgaDAdnZ2Xfdrq2tDQMHDoTRaMTo0aOxbt06DB8+vNPYa9eu4dq1a8rnlpYW8w2AiLD+\nf0ZauwtERHdl1TM6DQ0N6OjouOOMjI+PD2prazvdZujQodi2bRsOHDiAjz76CEajETExMfjPf/7T\naXxKSgrc3d2VJSAgwOzjICIiop7J6peuuio6Ohpz587FqFGjMGHCBOzduxfe3t744IMPOo1ftWoV\nmpublaW6utrCPSYiIiJrseqlKy8vL6jVatTV1Zmsr6urg6+v733tw8HBAeHh4fj66687bXd0dISj\no2O3+0pERES9j1XP6Gg0GkRERCAjI0NZZzQakZGRgejo6PvaR0dHB86ePQs/P78H1U0iIiLqpaz+\nZOTly5cjISEBkZGRGDNmDDZu3IjLly8jMTERADB37lz0798fKSkpAIA//OEPGDt2LIKDg9HU1IS3\n3noLFy5cwPPPP2/NYRAREVEPZPVCJy4uDhcvXsRrr72G2tpajBo1CocPH1ZuUK6qqoKd3Q8nni5d\nuoSFCxeitrYWHh4eiIiIwBdffIHQ0FBrDYGIiIh6KJWIiLU7YUktLS1wd3dHc3MztFqttbtDRERE\n9+Gn/n73ullXRERERPeLhQ4RERHZLBY6REREZLNY6BAREZHNYqFDRERENouFDhEREdksFjpERERk\ns6z+wEBLu/nYoJaWFiv3hIiIiO7Xzd/trj7+76ErdFpbWwEAAQEBVu4JERERdVVrayvc3d3vO/6h\nezKy0WjEd999Bzc3N6hUKrPuu6WlBQEBAaiuruZTl7uJuTQv5tO8mE/zYS7Ny5bzKSJobW2Fv7+/\nyauhfsxDd0bHzs4OAwYMeKDH0Gq1NvcfmLUwl+bFfJoX82k+zKV52Wo+u3Im5ybejExEREQ2i4UO\nERER2Sz12rVr11q7E7ZErVZj4sSJsLd/6K4Kmh1zaV7Mp3kxn+bDXJoX82nqobsZmYiIiB4evHRF\nRERENouFDhEREdksFjpERERks1joEBERkc1ioWMmW7ZsgV6vh5OTE6KiopCbm2vtLlldSkoKfv7z\nn8PNzQ39+vXDjBkzcO7cOZOY//73v0hKSoKnpydcXV3xy1/+EnV1dSYxVVVVmDp1KlxcXNCvXz+s\nWLECN27cMInJzMzE6NGj4ejoiODgYOzYseNBD8+qUlNToVKpkJycrKxjLrvm22+/xa9+9St4enrC\n2dkZYWFhyMvLU9pFBK+99hr8/Pzg7OwMg8GA8+fPm+yjsbER8fHx0Gq10Ol0WLBgAdra2kxizpw5\ng8ceewxOTk4ICAjA+vXrLTI+S+ro6MCrr76KoKAgODs742c/+xneeOMNk3cSMZ93d/z4cTz99NPw\n9/eHSqXC/v37Tdotmbs9e/YgJCQETk5OCAsLw6FDh8w/YEsT6rbdu3eLRqORbdu2SUlJiSxcuFB0\nOp3U1dVZu2tWFRsbK9u3b5fi4mIpLCyUJ598UgIDA6WtrU2JWbx4sQQEBEhGRobk5eXJ2LFjJSYm\nRmm/ceOGjBgxQgwGgxQUFMihQ4fEy8tLVq1apcSUl5eLi4uLLF++XEpLS2Xz5s2iVqvl8OHDFh2v\npeTm5oper5dHHnlEli1bpqxnLu9fY2OjDBw4UObNmyc5OTlSXl4uR44cka+//lqJSU1NFXd3d9m/\nf78UFRXJtGnTJCgoSK5evarEPPHEEzJy5Ej58ssv5fPPP5fg4GCZPXu20t7c3Cw+Pj4SHx8vxcXF\n8vHHH4uzs7N88MEHFh3vg/bmm2+Kp6enHDx4UCoqKmTPnj3i6uoqmzZtUmKYz7s7dOiQvPLKK7J3\n714BIPv27TNpt1TuTp48KWq1WtavXy+lpaWyevVqcXBwkLNnzz74JDxALHTMYMyYMZKUlKR87ujo\nEH9/f0lJSbFir3qe+vp6ASBZWVkiItLU1CQODg6yZ88eJaasrEwASHZ2toj8/x8AOzs7qa2tVWLe\nf/990Wq1cu3aNRERWblypQwfPtzkWHFxcRIbG/ugh2Rxra2tMnjwYElPT5cJEyYohQ5z2TUvv/yy\nPProo3dtNxqN4uvrK2+99ZayrqmpSRwdHeXjjz8WEZHS0lIBIKdOnVJiPvvsM1GpVPLtt9+KiMh7\n770nHh4eSn5vHnvo0KHmHpJVTZ06VebPn2+ybubMmRIfHy8izGdX3F7oWDJ3s2bNkqlTp5r0Jyoq\nSn7961+bd5AWxktX3XT9+nXk5+fDYDAo6+zs7GAwGJCdnW3FnvU8zc3NAIC+ffsCAPLz89He3m6S\nu5CQEAQGBiq5y87ORlhYGHx8fJSY2NhYtLS0oKSkRIm5dR83Y2wx/0lJSZg6deod42Uuu+bvf/87\nIiMj8eyzz6Jfv34IDw/Hhx9+qLRXVFSgtrbWJBfu7u6IiooyyadOp0NkZKQSYzAYYGdnh5ycHCVm\n/Pjx0Gg0SkxsbCzOnTuHS5cuPehhWkxMTAwyMjLw1VdfAQCKiopw4sQJTJkyBQDz2R2WzJ2tfv9Z\n6HRTQ0MDOjo6TH48AMDHxwe1tbVW6lXPYzQakZycjHHjxmHEiBEAgNraWmg0Guh0OpPYW3NXW1vb\naW5vtt0rpqWlBVevXn0g47GG3bt34/Tp00hJSbmjjbnsmvLycrz//vsYPHgwjhw5ghdeeAG/+c1v\nsHPnTgA/5ONe3+va2lr069fPpN3e3h59+/btUs5twe9+9zs899xzCAkJgYODA8LDw5GcnIz4+HgA\nzGd3WDJ3d4vp7bnl86HJIpKSklBcXIwTJ05Yuyu9UnV1NZYtW4b09HQ4OTlZuzu9ntFoRGRkJNat\nWwcACA8PR3FxMbZu3YqEhAQr9673+fTTT5GWloa//OUvGD58OAoLC5GcnAx/f3/mk6yOZ3S6ycvL\nC2q1+o7ZLXV1dfD19bVSr3qWpUuX4uDBgzh27BgGDBigrPf19cX169fR1NRkEn9r7nx9fTvN7c22\ne8VotVo4OzubfTzWkJ+fj/r6eowePRr29vawt7dHVlYW3n33Xdjb28PHx4e57AI/Pz+EhoaarBs2\nbBiqqqoA/JCPe32vfX19UV9fb9J+48YNNDY2dinntmDFihXKWZ2wsDDMmTMHv/3tb5Wzj8znT2fJ\n3N0tprfnloVON2k0GkRERCAjI0NZZzQakZGRgejoaCv2zPpEBEuXLsW+fftw9OhRBAUFmbRHRETA\nwcHBJHfnzp1DVVWVkrvo6GicPXvW5Eucnp4OrVar/FBFR0eb7ONmjC3lf9KkSTh79iwKCwuVJTIy\nEvHx8cq/mcv7N27cuDsedfDVV19h4MCBAICgoCD4+vqa5KKlpQU5OTkm+WxqakJ+fr4Sc/ToURiN\nRkRFRSkxx48fR3t7uxKTnp6OoUOHwsPD44GNz9KuXLkCOzvTnxO1Wg2j0QiA+ewOS+bOZr//1r4b\n2hbs3r1bHB0dZceOHVJaWiqLFi0SnU5nMrvlYfTCCy+Iu7u7ZGZmSk1NjbJcuXJFiVm8eLEEBgbK\n0aNHJS8vT6KjoyU6OlppvzklevLkyVJYWCiHDx8Wb2/vTqdEr1ixQsrKymTLli02OSX6drfOuhJh\nLrsiNzdX7O3t5c0335Tz589LWlqauLi4yEcffaTEpKamik6nkwMHDsiZM2dk+vTpnU7pDQ8Pl5yc\nHDlx4oQMHjzYY2RX9wAAB/9JREFUZEpvU1OT+Pj4yJw5c6S4uFh2794tLi4uvX469O0SEhKkf//+\nyvTyvXv3ipeXl6xcuVKJYT7vrrW1VQoKCqSgoEAAyIYNG6SgoEAuXLggIpbL3cmTJ8Xe3l7efvtt\nKSsrkzVr1nB6Of1g8+bNEhgYKBqNRsaMGSNffvmltbtkdQA6XbZv367EXL16VZYsWSIeHh7i4uIi\nzzzzjNTU1Jjsp7KyUqZMmSLOzs7i5eUlL774orS3t5vEHDt2TEaNGiUajUYGDRpkcgxbdXuhw1x2\nzT/+8Q8ZMWKEODo6SkhIiPz5z382aTcajfLqq6+Kj4+PODo6yqRJk+TcuXMmMd9//73Mnj1bXF1d\nRavVSmJiorS2tprEFBUVyaOPPiqOjo7Sv39/SU1NfeBjs7SWlhZZtmyZBAYGipOTkwwaNEheeeUV\nk6nMzOfdHTt2rNO/lQkJCSJi2dx9+umnMmTIENFoNDJ8+HD55z//+cDGbSkqkVseXUlERERkQ3iP\nDhEREdksFjpERERks1joEBERkc1ioUNEREQ2i4UOERER2SwWOkRERGSzWOgQERGRzWKhQ0Q2Qa/X\nY+PGjdbuBhH1MCx0iKhL5s2bhxkzZiifJ06ciOTkZIsdf8eOHdDpdHesP3XqFBYtWmSxfvyYpKQk\n/P73vwcArFu3DvPnz7dyj4geTix0iKhHuH79ere29/b2houLi5l6033Z2dkYN24cAODzzz9X/k1E\nlsVCh4h+snnz5iErKwubNm2CSqWCSqVCZWUlAKC4uBhTpkyBq6srfHx8MGfOHDQ0NCjbTpw4EUuX\nLkVycjK8vLwQGxsLANiwYQPCwsLQp08fBAQEYMmSJWhrawMAZGZmIjExEc3Nzcrx1q5dC+DOS1dV\nVVWYPn06XF1dodVqMWvWLNTV1Snta9euxahRo7Br1y7o9Xq4u7vjueeeQ2trqxLz17/+FWFhYXB2\ndoanpycMBgMuX778o3m5fPkyiouLERMTA6PRaFL0EJFlsdAhop9s06ZNiI6OxsKFC1FTU4OamhoE\nBASgqakJjz/+OMLDw5GXl4fDhw+jrq4Os2bNMtl+586d0Gg0OHnyJLZu3QoAsLOzw7vvvouSkhLs\n3LkTR48excqVKwEAMTEx2LhxI7RarXK8l1566Y5+GY1GTJ8+HY2NjcjKykJ6ejrKy8sRFxdnEvfN\nN99g//79OHjwIA4ePIisrCykpqYCAGpqajB79mzMnz8fZWVlyMzMxMyZM3Gv1wMuWbIEOp0Ofn5+\naG9vR1BQEDw8PNDc3IyxY8dCp9OhqqqqWzknoi6y8ktFiaiXSUhIkOnTpyufb3+LuojIG2+8IZMn\nTzZZV11dLQCUty5PmDBBwsPDf/R4e/bsEU9PT+Xz9u3bxd3d/Y64gQMHyp/+9CcREfnXv/4larVa\nqqqqlPaSkhIBILm5uSIismbNGnFxcZGWlhYlZsWKFRIVFSUiIvn5+QJAKisrf7SPN128eFEqKipk\nwYIFsmDBAqmoqJBVq1bJM888IxUVFVJRUXHH2+KJ6MHiGR0iMruioiIcO3YMrq6uyhISEgLg/8+i\n3BQREXHHtv/+978xadIk9O/fH25ubpgzZw6+//57XLly5b6PX1ZWhoCAAAQEBCjrQkNDodPpUFZW\npqzT6/Vwc3NTPvv5+aG+vh4AMHLkSEyaNAlhYWF49tln8eGHH+LSpUv3PK6Xlxf0ej2++OILxMXF\nQa/X49SpU5g5cyb0ej30ej3s7e3vexxE1H0sdIjI7Nra2vD000+jsLDQZDl//jzGjx+vxPXp08dk\nu8rKSjz11FN45JFH8Le//Q35+fnYsmULgO7frNwZBwcHk88qlQpGoxEAoFarkZ6ejs8++wyhoaHY\nvHkzhg4dioqKik73lZaWphR1ZWVlmDFjBlxdXZGRkYFFixbB1dUVaWlpZh8DEd0bCx0i6haNRoOO\njg6TdaNHj0ZJSQn0ej2Cg4NNltuLm1vl5+fDaDTinXfewdixYzFkyBB89913P3q82w0bNgzV1dWo\nrq5W1pWWlqKpqQmhoaH3PTaVSoVx48bh9ddfR0FBATQaDfbt29dp7LRp01BYWIjXX38dMTExKCoq\nwnvvvYfg4GCcOXMGhYWFmDZt2n0fm4jMg4UOEXWLXq9HTk4OKisr0dDQAKPRiKSkJDQ2NmL27Nk4\ndeoUvvnmGxw5cgSJiYn3LFKCg4PR3t6OzZs3o7y8HLt27VJuUr71eG1tbcjIyEBDQ0Onl7QMBgPC\nwsIQHx+P06dPIzc3F3PnzsWECRMQGRl5X+PKycnBunXrkJeXh6qqKuzduxcXL17EsGHDOo13c3ND\ncHAwzp8/D4PBgODgYFRWVuIXv/iFUuTdepmMiCyDhQ4RdctLL70EtVqN0NBQeHt7o6qqCv7+/jh5\n8iQ6OjowefJkhIWFITk5GTqdDnZ2d/+zM3LkSGzYsAF//OMfMWLECKSlpSElJcUkJiYmBosXL0Zc\nXBy8vb2xfv36O/ajUqlw4MABeHh4YPz48TAYDBg0aBA++eST+x6XVqvF8ePH8eSTT2LIkCFYvXo1\n3nnnHUyZMuWe22VmZiqX57Kyskwu1RGR5alE7jFXkoiIiKgX4xkdIiIislksdIiIiMhmsdAhIiIi\nm8VCh4iIiGwWCx0iIiKyWSx0iIiIyGax0CEiIiKbxUKHiIiIbBYLHSIiIrJZLHSIiIjIZrHQISIi\nIpvFQoeIiIhs1v8B0ewVsN/HpBMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb5b4c4c7f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}