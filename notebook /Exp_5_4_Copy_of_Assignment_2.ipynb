{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp 5 4 Copy of Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f0ayvowQNK3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Referred Material\n",
        "\n",
        "**-Loading and transforming data **\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "\n",
        "-**Intro to pytorch **\n",
        "\n",
        "https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
        "\n",
        "\n",
        "-**Image preprocessing over view: **\n",
        "\n",
        "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258\n",
        " \n",
        " (*Try this*) https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        " \n",
        " (*Try this*) https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
        " \n",
        " -**List of things to try w.r.t pre-processing**\n",
        " \n",
        "\n",
        "*   Square images + batch size 10  (**Done**)\n",
        "*   Square images + bw + batch size 100 (**Done**)\n",
        "*   Square images + batch size 100  (**Done**)\n",
        "*   Random flips and rotation  (**Done**)\n",
        "*   Five crop images + batch size 100  (**Done**)\n",
        "*   Other transformation techniques  (**Done**)\n",
        "*   Without normalization  (**Done**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m29L6L_EYtQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Mounting the google drive for loading Dataset sand saving other files"
      ]
    },
    {
      "metadata": {
        "id": "kiT0P1Zh0T4O",
        "colab_type": "code",
        "outputId": "9061035f-9dee-4ae5-b827-72666d92ec86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJz_lmGZDF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Installing and loading necessary modules"
      ]
    },
    {
      "metadata": {
        "id": "L5xPhzElgxSe",
        "colab_type": "code",
        "outputId": "d7504d0c-d548-4bb1-f881-db46b3ed6763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random;\n",
        "import math;\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from IPython.display import clear_output, display\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 41.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQHizK52OvDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e4e5a21-48fb-4332-9c94-358372a7c358"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMN54-l0Y2Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading Dataset to pandas dataframe and splitting it into train, test and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "jpn74UIA1LG-",
        "colab_type": "code",
        "outputId": "db56403d-d7d5-49f2-f026-6ad4efa90f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/train_cars.csv', 'r') as f:\n",
        "#   print(f.read())  \n",
        "\n",
        "file_dir = \"/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/\"\n",
        "img_dir = file_dir + \"train/\"\n",
        "sq_img_dir = file_dir + \"train_sq/\"\n",
        "file_name = file_dir + \"train_cars.csv\"\n",
        "sep_datasets = file_dir + \"sep datasets/\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_entire_dataset = pd.read_csv(file_name)\n",
        "\n",
        "print(df_entire_dataset.columns)\n",
        "unique_car_type = df_entire_dataset.target.unique()\n",
        "\n",
        "print(unique_car_type)\n",
        "\n",
        "unique_car_type_dict = {}\n",
        "df_entire_dataset[\"num_target\"] = df_entire_dataset[\"target\"]\n",
        "for index, per_car_type in enumerate(unique_car_type):\n",
        "  df_entire_dataset[\"num_target\"] = df_entire_dataset[\"num_target\"].replace(per_car_type, index)\n",
        "\n",
        "# print(df_entire_dataset)\n",
        "train_valid, test = train_test_split(df_entire_dataset, test_size=0.05, random_state =10, stratify=df_entire_dataset[\"num_target\"])\n",
        "train, valid = train_test_split(train_valid, test_size=0.05, random_state=10, stratify=train_valid[\"num_target\"])\n",
        "\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)\n",
        "test.reset_index(inplace = True, drop=True)\n",
        "\n",
        "train_data_file = sep_datasets + \"train_dataset.csv\"\n",
        "train.to_csv(train_data_file)\n",
        "valid_data_file = sep_datasets + \"valid_dataset.csv\"\n",
        "valid.to_csv(valid_data_file)\n",
        "test_data_file = sep_datasets + \"test_dataset.csv\"\n",
        "test.to_csv(test_data_file)\n",
        "\n",
        "\n",
        "print(df_entire_dataset.groupby(\"target\").size())\n",
        "# print(train.groupby(\"target\").size())\n",
        "# print(valid.groupby(\"target\").size())\n",
        "# print(test.groupby(\"target\").size())\n",
        "print(train.size)\n",
        "print(valid.size)\n",
        "print(test.size)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['image_name', 'target'], dtype='object')\n",
            "['sedan' 'truck' 'dedicated agricultural vehicle' 'jeep' 'crane truck'\n",
            " 'prime mover' 'cement mixer' 'hatchback' 'minivan' 'pickup' 'van'\n",
            " 'light truck' 'bus' 'tanker' 'minibus']\n",
            "target\n",
            "bus                                 53\n",
            "cement mixer                        17\n",
            "crane truck                         16\n",
            "dedicated agricultural vehicle       5\n",
            "hatchback                         3080\n",
            "jeep                               865\n",
            "light truck                        164\n",
            "minibus                             25\n",
            "minivan                            586\n",
            "pickup                             435\n",
            "prime mover                         44\n",
            "sedan                             5783\n",
            "tanker                               3\n",
            "truck                              179\n",
            "van                                362\n",
            "dtype: int64\n",
            "31452\n",
            "1656\n",
            "1743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKm-1x3KZLsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Class to load and transform the dataset"
      ]
    },
    {
      "metadata": {
        "id": "LRWlulvT6gB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#referred from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CarTypeDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, pd_dataframe, root_dir, transform=None, sq_image = False, image_channel = \"RGB\", find_edges = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pd_dataframe (dataframe): Pandas dataframe with the respectve data\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.cartype_frame = pd_dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.sq_image = sq_image\n",
        "        self.image_channel = image_channel\n",
        "        self.find_edges = find_edges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cartype_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir + self.cartype_frame.iloc[idx, 0]\n",
        "        # read the image which returns numerical transformation of image plot using plt.imshow\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        actual_image = image \n",
        "        \n",
        "        if self.find_edges: \n",
        "          image = cv2.Canny(image,10,100, L2gradient= True)\n",
        "          \n",
        "        \n",
        "        pil_image = Image.fromarray(image)\n",
        "        \n",
        "        if self.sq_image: \n",
        "          pil_image = CarTypeDataset.make_square(pil_image)\n",
        "        \n",
        "#         if self.image_channel:\n",
        "        pil_image = pil_image.convert(self.image_channel)\n",
        "\n",
        "        image = pil_image\n",
        "        num_car_type = self.cartype_frame.iloc[idx, 2]\n",
        "        car_type = self.cartype_frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': num_car_type}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def make_square(im, min_size=80, fill_color=(0, 0, 0, 0)):\n",
        "        x, y = im.size\n",
        "        min_size = x if x > y else y \n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        val_x = int((size - x) / 2)\n",
        "        val_y = int((size - y) / 2)\n",
        "\n",
        "        new_im.paste(im, (val_x, val_y))\n",
        "        return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_dCHX5hXP-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Calculating Mean and Standard Deviation across all the train images data\n",
        "\n",
        "(Outputs are commented below the print statements)"
      ]
    },
    {
      "metadata": {
        "id": "37RiX6XnU9Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# composed = transforms.Compose([\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "\n",
        "# car_type_train = CarTypeDataset(pd_dataframe=train,\n",
        "#                                     root_dir=img_dir,\n",
        "#                                     transform = composed)\n",
        "\n",
        "\n",
        "# tensor_mean_list = []\n",
        "# tensor_std_list = []\n",
        "\n",
        "# for index in range(0,len(car_type_train)):\n",
        "# #   print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "#   this_car_type = car_type_train[index]\n",
        "#   this_mean = this_car_type[\"image\"].mean(1).mean(1)\n",
        "#   this_std = this_car_type[\"image\"].std(1).std(1)\n",
        "#   if index % 1000 == 0:\n",
        "#     print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "    \n",
        "#     print(this_mean)\n",
        "#     print(this_std)\n",
        "#   tensor_mean_list.append(this_mean)\n",
        "#   tensor_std_list.append(this_std)\n",
        "  \n",
        "# tensor_mean_tuple = tuple(tensor_mean_list)\n",
        "# tensor_std_tuple = tuple(tensor_std_list)\n",
        "\n",
        "# # print(tensor_mean_tuple)\n",
        "\n",
        "# image_means = torch.stack(tensor_mean_tuple)\n",
        "# print(image_means.mean(0))\n",
        "# # tensor([0.4961, 0.5154, 0.5685])\n",
        "\n",
        "# image_std = torch.stack(tensor_std_tuple)\n",
        "# print(image_std.mean(0))\n",
        "# # tensor([0.0538, 0.0556, 0.0510])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSqClVOB3MBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Edge Dectection Sample Code\n",
        "(The sample outputs are included in the report)"
      ]
    },
    {
      "metadata": {
        "id": "B3yhsGxR3JIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# from random import * \n",
        "\n",
        "# def plot_edges(car_type):\n",
        "\n",
        "#   car_type_df = train.loc[train['target'] == car_type]\n",
        "#   car_img = car_type_df.iloc[randint(0,len(car_type_df))]\n",
        "#   image = car_img[\"image_name\"]\n",
        "#   img_name = img_dir + image\n",
        "#   io_image  = io.imread(img_name)\n",
        "#   print(type(io_image))\n",
        "\n",
        "#   edges_1 = cv2.Canny(io_image,10,100, L2gradient= True)\n",
        "\n",
        "#   plt.subplot(121),plt.imshow(edges_1)\n",
        "#   plt.title('Edge Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "#   plt.subplot(122)\n",
        "#   plt.imshow(io_image)\n",
        "#   plt.title('Oriignal Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# plot_edges(\"sedan\")\n",
        "# plot_edges(\"truck\")\n",
        "# plot_edges(\"jeep\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB3dw_BUK1or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 300;\n",
        "batch_size = 10;\n",
        "learning_rate = 0.001;\n",
        "find_edges = True\n",
        "kernel_size = (5,5)\n",
        "neuron_count = 32\n",
        "\n",
        "sq_image = False\n",
        "acc_score = 0\n",
        "model_extra_char = \"5\"\n",
        "# model_extra_char = input(\"Enter that extra character to apply to the best model name\")\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\".model\"\n",
        "\n",
        "resize_height = 72\n",
        "resize_width = 30\n",
        "rotation_degree= 10\n",
        "\n",
        "if find_edges:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor()\n",
        "\n",
        "      ])\n",
        "else:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4961, 0.5154, 0.5685), (0.0538, 0.0556, 0.0510))\n",
        "      ])\n",
        "\n",
        "\n",
        "car_type_train_norm = CarTypeDataset(pd_dataframe=train,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform, \n",
        "                                    sq_image = sq_image, \n",
        "                                    find_edges = find_edges)\n",
        "\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(car_type_train_norm,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzPN8EchhjzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "          \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.MaxPool2d(2))\n",
        "  \n",
        "        self.layer_hd = nn.Sequential(\n",
        "            nn.Conv2d(neuron_count, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.fcS = nn.Linear(64, neuron_count)\n",
        "        self.fc_c = nn.Linear(neuron_count, neuron_count)      \n",
        "        self.fcL = nn.Linear(neuron_count, 15)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)     #1 \n",
        "        out = self.layer_hd(out) #2\n",
        "        out = self.layer_hd(out) #3\n",
        "        out = self.layer_hd(out) #4\n",
        "        out = self.layer_hd(out) #5\n",
        "        \n",
        "\n",
        "        \n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fcS(out)  #First\n",
        "        out = self.fc_c(out) #1\n",
        "        out = self.fcL(out)  #Last\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uGZHD17hmVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#instance of the Conv Net\n",
        "cnn = CNN();\n",
        "cnn.to(device)\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16kZUe0Axb30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_score(acc_score, cnn, data_transform):\n",
        "  car_type_valid_norm = CarTypeDataset(pd_dataframe=valid,\n",
        "                                      root_dir=img_dir,\n",
        "                                      transform = data_transform,\n",
        "                                       sq_image = sq_image, \n",
        "                                      find_edges = find_edges\n",
        "                                      )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(car_type_valid_norm,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=8)\n",
        "  cnn.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, this_loader in enumerate(valid_loader):\n",
        "      images = Variable(this_loader[\"image\"]).to(device)\n",
        "\n",
        "      outputs = cnn(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += this_loader[\"label\"].size(0)\n",
        "      correct += (predicted == this_loader[\"label\"].to(device)).sum()\n",
        "    \n",
        "  this_acc_score = (100 * correct / total)\n",
        "  if this_acc_score > acc_score:\n",
        "    acc_score = this_acc_score\n",
        "    torch.save(cnn, model_save_path)\n",
        "    print(\"Saved the model to \" + model_save_path)\n",
        "  print('Test Accuracy of the model on the %i test images: %.4f %%' % (len(car_type_valid_norm), (100 * correct / total)) )\n",
        "  return acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGVb6d9-IvXm",
        "colab_type": "code",
        "outputId": "a0c6e03e-7694-479b-9585-c11ab4812c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2969
        }
      },
      "cell_type": "code",
      "source": [
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      acc_score =  valid_score(acc_score, cnn, data_transform)\n",
        "      \n",
        "    for i, this_loader in enumerate(dataset_loader):\n",
        "        images = Variable(this_loader[\"image\"]).to(device)\n",
        "        labels = Variable(this_loader[\"label\"]).to(device)\n",
        "        \n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.data.item());\n",
        "        \n",
        "        if (i+1) % 500 == 0:\n",
        "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
        "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data.item()))\n",
        "          \n",
        "    "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1/300, Iter : 500/1048,  Loss: 0.6141\n",
            "Epoch : 1/300, Iter : 1000/1048,  Loss: 1.2578\n",
            "Epoch : 2/300, Iter : 500/1048,  Loss: 1.1522\n",
            "Epoch : 2/300, Iter : 1000/1048,  Loss: 1.2568\n",
            "Epoch : 3/300, Iter : 500/1048,  Loss: 0.9439\n",
            "Epoch : 3/300, Iter : 1000/1048,  Loss: 1.4936\n",
            "Epoch : 4/300, Iter : 500/1048,  Loss: 0.6769\n",
            "Epoch : 4/300, Iter : 1000/1048,  Loss: 1.6066\n",
            "Test Accuracy of the model on the 552 test images: 63.0000 %\n",
            "Epoch : 5/300, Iter : 500/1048,  Loss: 0.6183\n",
            "Epoch : 5/300, Iter : 1000/1048,  Loss: 1.4255\n",
            "Epoch : 6/300, Iter : 500/1048,  Loss: 0.7668\n",
            "Epoch : 6/300, Iter : 1000/1048,  Loss: 1.0557\n",
            "Epoch : 7/300, Iter : 500/1048,  Loss: 1.0353\n",
            "Epoch : 7/300, Iter : 1000/1048,  Loss: 0.7616\n",
            "Epoch : 8/300, Iter : 500/1048,  Loss: 0.6105\n",
            "Epoch : 8/300, Iter : 1000/1048,  Loss: 0.9566\n",
            "Epoch : 9/300, Iter : 500/1048,  Loss: 0.9116\n",
            "Epoch : 9/300, Iter : 1000/1048,  Loss: 0.5863\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 10/300, Iter : 500/1048,  Loss: 1.6602\n",
            "Epoch : 10/300, Iter : 1000/1048,  Loss: 0.4050\n",
            "Epoch : 11/300, Iter : 500/1048,  Loss: 1.1137\n",
            "Epoch : 11/300, Iter : 1000/1048,  Loss: 1.1174\n",
            "Epoch : 12/300, Iter : 500/1048,  Loss: 1.2604\n",
            "Epoch : 12/300, Iter : 1000/1048,  Loss: 1.1124\n",
            "Epoch : 13/300, Iter : 500/1048,  Loss: 0.8145\n",
            "Epoch : 13/300, Iter : 1000/1048,  Loss: 0.4427\n",
            "Epoch : 14/300, Iter : 500/1048,  Loss: 0.9641\n",
            "Epoch : 14/300, Iter : 1000/1048,  Loss: 0.7068\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 15/300, Iter : 500/1048,  Loss: 1.7357\n",
            "Epoch : 15/300, Iter : 1000/1048,  Loss: 0.7060\n",
            "Epoch : 16/300, Iter : 500/1048,  Loss: 0.8638\n",
            "Epoch : 16/300, Iter : 1000/1048,  Loss: 0.6323\n",
            "Epoch : 17/300, Iter : 500/1048,  Loss: 0.8729\n",
            "Epoch : 17/300, Iter : 1000/1048,  Loss: 0.9581\n",
            "Epoch : 18/300, Iter : 500/1048,  Loss: 1.2703\n",
            "Epoch : 18/300, Iter : 1000/1048,  Loss: 0.9020\n",
            "Epoch : 19/300, Iter : 500/1048,  Loss: 1.0412\n",
            "Epoch : 19/300, Iter : 1000/1048,  Loss: 1.0383\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 20/300, Iter : 500/1048,  Loss: 0.7751\n",
            "Epoch : 20/300, Iter : 1000/1048,  Loss: 1.2909\n",
            "Epoch : 21/300, Iter : 500/1048,  Loss: 0.8070\n",
            "Epoch : 21/300, Iter : 1000/1048,  Loss: 0.9287\n",
            "Epoch : 22/300, Iter : 500/1048,  Loss: 0.3790\n",
            "Epoch : 22/300, Iter : 1000/1048,  Loss: 0.8954\n",
            "Epoch : 23/300, Iter : 500/1048,  Loss: 0.3684\n",
            "Epoch : 23/300, Iter : 1000/1048,  Loss: 1.2545\n",
            "Epoch : 24/300, Iter : 500/1048,  Loss: 0.5480\n",
            "Epoch : 24/300, Iter : 1000/1048,  Loss: 1.1237\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 25/300, Iter : 500/1048,  Loss: 1.0437\n",
            "Epoch : 25/300, Iter : 1000/1048,  Loss: 1.1826\n",
            "Epoch : 26/300, Iter : 500/1048,  Loss: 0.8134\n",
            "Epoch : 26/300, Iter : 1000/1048,  Loss: 0.4039\n",
            "Epoch : 27/300, Iter : 500/1048,  Loss: 0.5949\n",
            "Epoch : 27/300, Iter : 1000/1048,  Loss: 0.2857\n",
            "Epoch : 28/300, Iter : 500/1048,  Loss: 1.5707\n",
            "Epoch : 28/300, Iter : 1000/1048,  Loss: 0.7582\n",
            "Epoch : 29/300, Iter : 500/1048,  Loss: 0.8214\n",
            "Epoch : 29/300, Iter : 1000/1048,  Loss: 0.4046\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 30/300, Iter : 500/1048,  Loss: 0.7121\n",
            "Epoch : 30/300, Iter : 1000/1048,  Loss: 0.9988\n",
            "Epoch : 31/300, Iter : 500/1048,  Loss: 1.0577\n",
            "Epoch : 31/300, Iter : 1000/1048,  Loss: 0.9487\n",
            "Epoch : 32/300, Iter : 500/1048,  Loss: 0.6513\n",
            "Epoch : 32/300, Iter : 1000/1048,  Loss: 0.4580\n",
            "Epoch : 33/300, Iter : 500/1048,  Loss: 0.6524\n",
            "Epoch : 33/300, Iter : 1000/1048,  Loss: 0.8808\n",
            "Epoch : 34/300, Iter : 500/1048,  Loss: 0.9548\n",
            "Epoch : 34/300, Iter : 1000/1048,  Loss: 0.6806\n",
            "Test Accuracy of the model on the 552 test images: 68.0000 %\n",
            "Epoch : 35/300, Iter : 500/1048,  Loss: 1.1164\n",
            "Epoch : 35/300, Iter : 1000/1048,  Loss: 0.7577\n",
            "Epoch : 36/300, Iter : 500/1048,  Loss: 0.7994\n",
            "Epoch : 36/300, Iter : 1000/1048,  Loss: 0.9950\n",
            "Epoch : 37/300, Iter : 500/1048,  Loss: 0.9040\n",
            "Epoch : 37/300, Iter : 1000/1048,  Loss: 0.5604\n",
            "Epoch : 38/300, Iter : 500/1048,  Loss: 0.3436\n",
            "Epoch : 38/300, Iter : 1000/1048,  Loss: 0.5224\n",
            "Epoch : 39/300, Iter : 500/1048,  Loss: 0.6633\n",
            "Epoch : 39/300, Iter : 1000/1048,  Loss: 0.9947\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 40/300, Iter : 500/1048,  Loss: 0.8022\n",
            "Epoch : 40/300, Iter : 1000/1048,  Loss: 0.3107\n",
            "Epoch : 41/300, Iter : 500/1048,  Loss: 0.5337\n",
            "Epoch : 41/300, Iter : 1000/1048,  Loss: 0.6960\n",
            "Epoch : 42/300, Iter : 500/1048,  Loss: 1.2599\n",
            "Epoch : 42/300, Iter : 1000/1048,  Loss: 1.4626\n",
            "Epoch : 43/300, Iter : 500/1048,  Loss: 1.1514\n",
            "Epoch : 43/300, Iter : 1000/1048,  Loss: 0.6653\n",
            "Epoch : 44/300, Iter : 500/1048,  Loss: 0.6743\n",
            "Epoch : 44/300, Iter : 1000/1048,  Loss: 1.5160\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 45/300, Iter : 500/1048,  Loss: 0.3909\n",
            "Epoch : 45/300, Iter : 1000/1048,  Loss: 0.7415\n",
            "Epoch : 46/300, Iter : 500/1048,  Loss: 1.1032\n",
            "Epoch : 46/300, Iter : 1000/1048,  Loss: 0.9255\n",
            "Epoch : 47/300, Iter : 500/1048,  Loss: 0.2001\n",
            "Epoch : 47/300, Iter : 1000/1048,  Loss: 0.3832\n",
            "Epoch : 48/300, Iter : 500/1048,  Loss: 0.3457\n",
            "Epoch : 48/300, Iter : 1000/1048,  Loss: 1.0186\n",
            "Epoch : 49/300, Iter : 500/1048,  Loss: 0.2943\n",
            "Epoch : 49/300, Iter : 1000/1048,  Loss: 1.0019\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 50/300, Iter : 500/1048,  Loss: 1.1617\n",
            "Epoch : 50/300, Iter : 1000/1048,  Loss: 0.7013\n",
            "Epoch : 51/300, Iter : 500/1048,  Loss: 0.6803\n",
            "Epoch : 51/300, Iter : 1000/1048,  Loss: 0.6150\n",
            "Epoch : 52/300, Iter : 500/1048,  Loss: 1.1650\n",
            "Epoch : 52/300, Iter : 1000/1048,  Loss: 0.3074\n",
            "Epoch : 53/300, Iter : 500/1048,  Loss: 0.7235\n",
            "Epoch : 53/300, Iter : 1000/1048,  Loss: 1.1171\n",
            "Epoch : 54/300, Iter : 500/1048,  Loss: 0.4311\n",
            "Epoch : 54/300, Iter : 1000/1048,  Loss: 0.6991\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cd1370551a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mvalid_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DSVlzWTMvgZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "04885d90-c405-4cdf-852e-3bc7cd1771dc"
      },
      "cell_type": "code",
      "source": [
        "# model_save_path = file_dir + \"model_file_\" + str(find_edges) + \"_1.model\"\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\".model\"\n",
        "torch.save(cnn, model_save_path)\n",
        "print(\"Saved the model to \" + model_save_path)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment5.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zUm4UsnDxt_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "car_type_test = CarTypeDataset(pd_dataframe=test,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform,\n",
        "                                     sq_image = sq_image, \n",
        "                                    find_edges = find_edges\n",
        "                                    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(car_type_test,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, this_loader in enumerate(test_loader):\n",
        "    images = Variable(this_loader[\"image\"])\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += this_loader[\"label\"].size(0)\n",
        "    correct += (predicted == this_loader[\"label\"]).sum()\n",
        "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usEoTQQA0j-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "f04c3257-9f08-46dc-cfcf-1629f78e490d"
      },
      "cell_type": "code",
      "source": [
        "print(len(losses))\n",
        "# losses_in_epochs = losses[0::60]\n",
        "losses_in_epochs = losses\n",
        "# plt.xkcd();\n",
        "plt.rcdefaults()\n",
        "plt.figure();\n",
        "plt.xlabel('Iterations #');\n",
        "plt.ylabel('Loss');\n",
        "plt.plot(losses_in_epochs);\n",
        "plt.show();"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAG0CAYAAAA7Go31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwxhjjDGj9T+CICgWNNuJFAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2ad8ecc828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}