{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp 1 5 Copy of Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f0ayvowQNK3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Referred Material\n",
        "\n",
        "**-Loading and transforming data **\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "\n",
        "-**Intro to pytorch **\n",
        "\n",
        "https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
        "\n",
        "\n",
        "-**Image preprocessing over view: **\n",
        "\n",
        "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258\n",
        " \n",
        " (*Try this*) https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        " \n",
        " (*Try this*) https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
        " \n",
        " -**List of things to try w.r.t pre-processing**\n",
        " \n",
        "\n",
        "*   Square images + batch size 10  (**Done**)\n",
        "*   Square images + bw + batch size 100 (**Done**)\n",
        "*   Square images + batch size 100  (**Done**)\n",
        "*   Random flips and rotation  (**Done**)\n",
        "*   Five crop images + batch size 100  (**Done**)\n",
        "*   Other transformation techniques  (**Done**)\n",
        "*   Without normalization  (**Done**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m29L6L_EYtQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Mounting the google drive for loading Dataset sand saving other files"
      ]
    },
    {
      "metadata": {
        "id": "kiT0P1Zh0T4O",
        "colab_type": "code",
        "outputId": "5a4f535a-3d18-44d3-a804-1c4c1272f070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJz_lmGZDF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Installing and loading necessary modules"
      ]
    },
    {
      "metadata": {
        "id": "L5xPhzElgxSe",
        "colab_type": "code",
        "outputId": "2616c4cc-a39e-42d4-a1ee-2adb4c9bd1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random;\n",
        "import math;\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from IPython.display import clear_output, display\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 3.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQHizK52OvDl",
        "colab_type": "code",
        "outputId": "00f9dd86-9d45-42d7-dc88-e4685f758781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMN54-l0Y2Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading Dataset to pandas dataframe and splitting it into train, test and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "jpn74UIA1LG-",
        "colab_type": "code",
        "outputId": "4a56e7dc-61cf-463f-f2b4-10ba39e4880b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/train_cars.csv', 'r') as f:\n",
        "#   print(f.read())  \n",
        "\n",
        "file_dir = \"/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/\"\n",
        "img_dir = file_dir + \"train/\"\n",
        "sq_img_dir = file_dir + \"train_sq/\"\n",
        "file_name = file_dir + \"train_cars.csv\"\n",
        "sep_datasets = file_dir + \"sep datasets/\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_entire_dataset = pd.read_csv(file_name)\n",
        "\n",
        "print(df_entire_dataset.columns)\n",
        "unique_car_type = df_entire_dataset.target.unique()\n",
        "\n",
        "print(unique_car_type)\n",
        "\n",
        "unique_car_type_dict = {}\n",
        "df_entire_dataset[\"num_target\"] = df_entire_dataset[\"target\"]\n",
        "for index, per_car_type in enumerate(unique_car_type):\n",
        "  df_entire_dataset[\"num_target\"] = df_entire_dataset[\"num_target\"].replace(per_car_type, index)\n",
        "\n",
        "# print(df_entire_dataset)\n",
        "train_valid, test = train_test_split(df_entire_dataset, test_size=0.05, random_state =10, stratify=df_entire_dataset[\"num_target\"])\n",
        "train, valid = train_test_split(train_valid, test_size=0.05, random_state=10, stratify=train_valid[\"num_target\"])\n",
        "\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)\n",
        "test.reset_index(inplace = True, drop=True)\n",
        "\n",
        "train_data_file = sep_datasets + \"train_dataset.csv\"\n",
        "train.to_csv(train_data_file)\n",
        "valid_data_file = sep_datasets + \"valid_dataset.csv\"\n",
        "valid.to_csv(valid_data_file)\n",
        "test_data_file = sep_datasets + \"test_dataset.csv\"\n",
        "test.to_csv(test_data_file)\n",
        "\n",
        "\n",
        "print(df_entire_dataset.groupby(\"target\").size())\n",
        "# print(train.groupby(\"target\").size())\n",
        "# print(valid.groupby(\"target\").size())\n",
        "# print(test.groupby(\"target\").size())\n",
        "print(train.size)\n",
        "print(valid.size)\n",
        "print(test.size)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['image_name', 'target'], dtype='object')\n",
            "['sedan' 'truck' 'dedicated agricultural vehicle' 'jeep' 'crane truck'\n",
            " 'prime mover' 'cement mixer' 'hatchback' 'minivan' 'pickup' 'van'\n",
            " 'light truck' 'bus' 'tanker' 'minibus']\n",
            "target\n",
            "bus                                 53\n",
            "cement mixer                        17\n",
            "crane truck                         16\n",
            "dedicated agricultural vehicle       5\n",
            "hatchback                         3080\n",
            "jeep                               865\n",
            "light truck                        164\n",
            "minibus                             25\n",
            "minivan                            586\n",
            "pickup                             435\n",
            "prime mover                         44\n",
            "sedan                             5783\n",
            "tanker                               3\n",
            "truck                              179\n",
            "van                                362\n",
            "dtype: int64\n",
            "31452\n",
            "1656\n",
            "1743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKm-1x3KZLsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Class to load and transform the dataset"
      ]
    },
    {
      "metadata": {
        "id": "LRWlulvT6gB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#referred from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CarTypeDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, pd_dataframe, root_dir, transform=None, sq_image = False, image_channel = \"RGB\", find_edges = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pd_dataframe (dataframe): Pandas dataframe with the respectve data\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.cartype_frame = pd_dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.sq_image = sq_image\n",
        "        self.image_channel = image_channel\n",
        "        self.find_edges = find_edges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cartype_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir + self.cartype_frame.iloc[idx, 0]\n",
        "        # read the image which returns numerical transformation of image plot using plt.imshow\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        actual_image = image \n",
        "        \n",
        "        if self.find_edges: \n",
        "          image = cv2.Canny(image,10,100, L2gradient= True)\n",
        "          \n",
        "        \n",
        "        pil_image = Image.fromarray(image)\n",
        "        \n",
        "        if self.sq_image: \n",
        "          pil_image = CarTypeDataset.make_square(pil_image)\n",
        "        \n",
        "#         if self.image_channel:\n",
        "        pil_image = pil_image.convert(self.image_channel)\n",
        "\n",
        "        image = pil_image\n",
        "        num_car_type = self.cartype_frame.iloc[idx, 2]\n",
        "        car_type = self.cartype_frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': num_car_type}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def make_square(im, min_size=80, fill_color=(0, 0, 0, 0)):\n",
        "        x, y = im.size\n",
        "        min_size = x if x > y else y \n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        val_x = int((size - x) / 2)\n",
        "        val_y = int((size - y) / 2)\n",
        "\n",
        "        new_im.paste(im, (val_x, val_y))\n",
        "        return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_dCHX5hXP-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Calculating Mean and Standard Deviation across all the train images data\n",
        "\n",
        "(Outputs are commented below the print statements)"
      ]
    },
    {
      "metadata": {
        "id": "37RiX6XnU9Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# composed = transforms.Compose([\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "\n",
        "# car_type_train = CarTypeDataset(pd_dataframe=train,\n",
        "#                                     root_dir=img_dir,\n",
        "#                                     transform = composed)\n",
        "\n",
        "\n",
        "# tensor_mean_list = []\n",
        "# tensor_std_list = []\n",
        "\n",
        "# for index in range(0,len(car_type_train)):\n",
        "# #   print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "#   this_car_type = car_type_train[index]\n",
        "#   this_mean = this_car_type[\"image\"].mean(1).mean(1)\n",
        "#   this_std = this_car_type[\"image\"].std(1).std(1)\n",
        "#   if index % 1000 == 0:\n",
        "#     print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "    \n",
        "#     print(this_mean)\n",
        "#     print(this_std)\n",
        "#   tensor_mean_list.append(this_mean)\n",
        "#   tensor_std_list.append(this_std)\n",
        "  \n",
        "# tensor_mean_tuple = tuple(tensor_mean_list)\n",
        "# tensor_std_tuple = tuple(tensor_std_list)\n",
        "\n",
        "# # print(tensor_mean_tuple)\n",
        "\n",
        "# image_means = torch.stack(tensor_mean_tuple)\n",
        "# print(image_means.mean(0))\n",
        "# # tensor([0.4961, 0.5154, 0.5685])\n",
        "\n",
        "# image_std = torch.stack(tensor_std_tuple)\n",
        "# print(image_std.mean(0))\n",
        "# # tensor([0.0538, 0.0556, 0.0510])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSqClVOB3MBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Edge Dectection Sample Code\n",
        "(The sample outputs are included in the report)"
      ]
    },
    {
      "metadata": {
        "id": "B3yhsGxR3JIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# from random import * \n",
        "\n",
        "# def plot_edges(car_type):\n",
        "\n",
        "#   car_type_df = train.loc[train['target'] == car_type]\n",
        "#   car_img = car_type_df.iloc[randint(0,len(car_type_df))]\n",
        "#   image = car_img[\"image_name\"]\n",
        "#   img_name = img_dir + image\n",
        "#   io_image  = io.imread(img_name)\n",
        "#   print(type(io_image))\n",
        "\n",
        "#   edges_1 = cv2.Canny(io_image,10,100, L2gradient= True)\n",
        "\n",
        "#   plt.subplot(121),plt.imshow(edges_1)\n",
        "#   plt.title('Edge Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "#   plt.subplot(122)\n",
        "#   plt.imshow(io_image)\n",
        "#   plt.title('Oriignal Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# plot_edges(\"sedan\")\n",
        "# plot_edges(\"truck\")\n",
        "# plot_edges(\"jeep\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB3dw_BUK1or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 300;\n",
        "batch_size = 10;\n",
        "learning_rate = 0.001;\n",
        "find_edges = False\n",
        "kernel_size = (3,3)\n",
        "neuron_count = 32\n",
        "\n",
        "sq_image = False\n",
        "acc_score = 68\n",
        "model_extra_char = \"1\"\n",
        "# model_extra_char = input(\"Enter that extra character to apply to the best model name\")\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\".model\"\n",
        "losses_save_path = file_dir + \"losses/losses_file_experiment_\" + str(model_extra_char) +\".csv\"\n",
        "\n",
        "\n",
        "resize_height = 72\n",
        "resize_width = 30\n",
        "rotation_degree= 10\n",
        "\n",
        "if find_edges:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor()\n",
        "\n",
        "      ])\n",
        "else:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4961, 0.5154, 0.5685), (0.0538, 0.0556, 0.0510))\n",
        "      ])\n",
        "\n",
        "\n",
        "car_type_train_norm = CarTypeDataset(pd_dataframe=train,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform, \n",
        "                                    sq_image = sq_image, \n",
        "                                    find_edges = find_edges)\n",
        "\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(car_type_train_norm,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzPN8EchhjzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "          \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.MaxPool2d(2))\n",
        "  \n",
        "        self.layer_hd = nn.Sequential(\n",
        "            nn.Conv2d(neuron_count, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.fcS = nn.Linear(128, neuron_count)\n",
        "        self.fc_c = nn.Linear(neuron_count, neuron_count)      \n",
        "        self.fcL = nn.Linear(neuron_count, 15)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)     #1 \n",
        "        out = self.layer_hd(out) #2\n",
        "        out = self.layer_hd(out) #3\n",
        "        out = self.layer_hd(out) #4\n",
        "        out = self.layer_hd(out) #5\n",
        "        out = self.layer_hd(out) #6\n",
        "        out = self.layer_hd(out) #7        \n",
        "        out = self.layer_hd(out) #8\n",
        "        out = self.layer_hd(out) #9\n",
        "        out = self.layer_hd(out) #10\n",
        "        \n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fcS(out)  #First\n",
        "        out = self.fc_c(out) #1\n",
        "        out = self.fc_c(out) #2\n",
        "        out = self.fc_c(out) #3\n",
        "        out = self.fc_c(out) #4\n",
        "        out = self.fc_c(out) #5\n",
        "        out = self.fc_c(out) #6        \n",
        "        out = self.fcL(out)  #Last\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uGZHD17hmVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#instance of the Conv Net\n",
        "cnn = CNN();\n",
        "cnn.to(device)\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16kZUe0Axb30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_score(acc_score, cnn, data_transform):\n",
        "  car_type_valid_norm = CarTypeDataset(pd_dataframe=valid,\n",
        "                                      root_dir=img_dir,\n",
        "                                      transform = data_transform,\n",
        "                                       sq_image = sq_image, \n",
        "                                      find_edges = find_edges\n",
        "                                      )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(car_type_valid_norm,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=8)\n",
        "  cnn.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, this_loader in enumerate(valid_loader):\n",
        "      images = Variable(this_loader[\"image\"].to(device))\n",
        "\n",
        "      outputs = cnn(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += this_loader[\"label\"].size(0)\n",
        "      correct += (predicted == this_loader[\"label\"].to(device)).sum()\n",
        "    \n",
        "  this_acc_score = (100 * correct / total)\n",
        "  if this_acc_score > acc_score:\n",
        "    acc_score = this_acc_score\n",
        "    torch.save(cnn, model_save_path)\n",
        "    print(\"Saved the model to \" + model_save_path)\n",
        "  print('Test Accuracy of the model on the %i test images: %.4f %%' % (len(car_type_valid_norm), (100 * correct / total)) )\n",
        "  return acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGVb6d9-IvXm",
        "colab_type": "code",
        "outputId": "6d6a2244-e248-4df2-99a8-6e3c3050f99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2326
        }
      },
      "cell_type": "code",
      "source": [
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      acc_score =  valid_score(acc_score, cnn, data_transform)\n",
        "      \n",
        "    for i, this_loader in enumerate(dataset_loader):\n",
        "        images = Variable(this_loader[\"image\"].to(device))\n",
        "        labels = Variable(this_loader[\"label\"].to(device))\n",
        "        \n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.data.item());\n",
        "        \n",
        "        with open(losses_save_path, 'wb') as fp:\n",
        "          pickle.dump(losses, fp)\n",
        "        \n",
        "        if (i+1) % 500 == 0:\n",
        "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
        "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data.item()))\n",
        "          \n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1/300, Iter : 500/1048,  Loss: 1.5465\n",
            "Epoch : 1/300, Iter : 1000/1048,  Loss: 1.0001\n",
            "Epoch : 2/300, Iter : 500/1048,  Loss: 1.3385\n",
            "Epoch : 2/300, Iter : 1000/1048,  Loss: 1.3338\n",
            "Epoch : 3/300, Iter : 500/1048,  Loss: 1.1287\n",
            "Epoch : 3/300, Iter : 1000/1048,  Loss: 1.1197\n",
            "Epoch : 4/300, Iter : 500/1048,  Loss: 1.1031\n",
            "Epoch : 4/300, Iter : 1000/1048,  Loss: 1.3517\n",
            "Test Accuracy of the model on the 552 test images: 32.0000 %\n",
            "Epoch : 5/300, Iter : 500/1048,  Loss: 0.7301\n",
            "Epoch : 5/300, Iter : 1000/1048,  Loss: 0.9675\n",
            "Epoch : 6/300, Iter : 500/1048,  Loss: 1.0489\n",
            "Epoch : 6/300, Iter : 1000/1048,  Loss: 1.1267\n",
            "Epoch : 7/300, Iter : 500/1048,  Loss: 1.1434\n",
            "Epoch : 7/300, Iter : 1000/1048,  Loss: 0.9081\n",
            "Epoch : 8/300, Iter : 500/1048,  Loss: 1.4454\n",
            "Epoch : 8/300, Iter : 1000/1048,  Loss: 0.9316\n",
            "Epoch : 9/300, Iter : 500/1048,  Loss: 0.4539\n",
            "Epoch : 9/300, Iter : 1000/1048,  Loss: 0.5761\n",
            "Test Accuracy of the model on the 552 test images: 64.0000 %\n",
            "Epoch : 10/300, Iter : 500/1048,  Loss: 0.6242\n",
            "Epoch : 10/300, Iter : 1000/1048,  Loss: 1.0477\n",
            "Epoch : 11/300, Iter : 500/1048,  Loss: 0.8668\n",
            "Epoch : 11/300, Iter : 1000/1048,  Loss: 0.8139\n",
            "Epoch : 12/300, Iter : 500/1048,  Loss: 1.1204\n",
            "Epoch : 12/300, Iter : 1000/1048,  Loss: 0.9621\n",
            "Epoch : 13/300, Iter : 500/1048,  Loss: 1.0632\n",
            "Epoch : 13/300, Iter : 1000/1048,  Loss: 1.0814\n",
            "Epoch : 14/300, Iter : 500/1048,  Loss: 0.4089\n",
            "Epoch : 14/300, Iter : 1000/1048,  Loss: 1.4416\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 15/300, Iter : 500/1048,  Loss: 0.9838\n",
            "Epoch : 15/300, Iter : 1000/1048,  Loss: 1.0756\n",
            "Epoch : 16/300, Iter : 500/1048,  Loss: 0.3931\n",
            "Epoch : 16/300, Iter : 1000/1048,  Loss: 0.9854\n",
            "Epoch : 17/300, Iter : 500/1048,  Loss: 0.7035\n",
            "Epoch : 17/300, Iter : 1000/1048,  Loss: 0.8097\n",
            "Epoch : 18/300, Iter : 500/1048,  Loss: 0.4995\n",
            "Epoch : 18/300, Iter : 1000/1048,  Loss: 0.7854\n",
            "Epoch : 19/300, Iter : 500/1048,  Loss: 0.6401\n",
            "Epoch : 19/300, Iter : 1000/1048,  Loss: 0.5519\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 20/300, Iter : 500/1048,  Loss: 0.5139\n",
            "Epoch : 20/300, Iter : 1000/1048,  Loss: 1.2914\n",
            "Epoch : 21/300, Iter : 500/1048,  Loss: 0.8168\n",
            "Epoch : 21/300, Iter : 1000/1048,  Loss: 0.5834\n",
            "Epoch : 22/300, Iter : 500/1048,  Loss: 0.6467\n",
            "Epoch : 22/300, Iter : 1000/1048,  Loss: 0.9115\n",
            "Epoch : 23/300, Iter : 500/1048,  Loss: 1.4266\n",
            "Epoch : 23/300, Iter : 1000/1048,  Loss: 1.0930\n",
            "Epoch : 24/300, Iter : 500/1048,  Loss: 0.5600\n",
            "Epoch : 24/300, Iter : 1000/1048,  Loss: 0.8191\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 25/300, Iter : 500/1048,  Loss: 0.8961\n",
            "Epoch : 25/300, Iter : 1000/1048,  Loss: 0.6697\n",
            "Epoch : 26/300, Iter : 500/1048,  Loss: 0.6247\n",
            "Epoch : 26/300, Iter : 1000/1048,  Loss: 0.4563\n",
            "Epoch : 27/300, Iter : 500/1048,  Loss: 0.5014\n",
            "Epoch : 27/300, Iter : 1000/1048,  Loss: 0.4594\n",
            "Epoch : 28/300, Iter : 500/1048,  Loss: 0.7246\n",
            "Epoch : 28/300, Iter : 1000/1048,  Loss: 0.9601\n",
            "Epoch : 29/300, Iter : 500/1048,  Loss: 0.7537\n",
            "Epoch : 29/300, Iter : 1000/1048,  Loss: 0.8654\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 30/300, Iter : 500/1048,  Loss: 0.5684\n",
            "Epoch : 30/300, Iter : 1000/1048,  Loss: 1.4726\n",
            "Epoch : 31/300, Iter : 500/1048,  Loss: 0.6500\n",
            "Epoch : 31/300, Iter : 1000/1048,  Loss: 0.6607\n",
            "Epoch : 32/300, Iter : 500/1048,  Loss: 0.8690\n",
            "Epoch : 32/300, Iter : 1000/1048,  Loss: 0.8083\n",
            "Epoch : 33/300, Iter : 500/1048,  Loss: 0.5020\n",
            "Epoch : 33/300, Iter : 1000/1048,  Loss: 1.0108\n",
            "Epoch : 34/300, Iter : 500/1048,  Loss: 0.9675\n",
            "Epoch : 34/300, Iter : 1000/1048,  Loss: 1.3090\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 35/300, Iter : 500/1048,  Loss: 0.6760\n",
            "Epoch : 35/300, Iter : 1000/1048,  Loss: 1.0061\n",
            "Epoch : 36/300, Iter : 500/1048,  Loss: 0.9121\n",
            "Epoch : 36/300, Iter : 1000/1048,  Loss: 0.8638\n",
            "Epoch : 37/300, Iter : 500/1048,  Loss: 0.9116\n",
            "Epoch : 37/300, Iter : 1000/1048,  Loss: 0.5536\n",
            "Epoch : 38/300, Iter : 500/1048,  Loss: 0.6588\n",
            "Epoch : 38/300, Iter : 1000/1048,  Loss: 0.7440\n",
            "Epoch : 39/300, Iter : 500/1048,  Loss: 0.9157\n",
            "Epoch : 39/300, Iter : 1000/1048,  Loss: 0.7414\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 40/300, Iter : 500/1048,  Loss: 1.0228\n",
            "Epoch : 40/300, Iter : 1000/1048,  Loss: 0.8922\n",
            "Epoch : 41/300, Iter : 500/1048,  Loss: 0.7936\n",
            "Epoch : 41/300, Iter : 1000/1048,  Loss: 0.9104\n",
            "Epoch : 42/300, Iter : 500/1048,  Loss: 1.0349\n",
            "Epoch : 42/300, Iter : 1000/1048,  Loss: 0.7577\n",
            "Epoch : 43/300, Iter : 500/1048,  Loss: 1.0327\n",
            "Epoch : 43/300, Iter : 1000/1048,  Loss: 0.5218\n",
            "Epoch : 44/300, Iter : 500/1048,  Loss: 0.6089\n",
            "Epoch : 44/300, Iter : 1000/1048,  Loss: 1.2873\n",
            "Test Accuracy of the model on the 552 test images: 68.0000 %\n",
            "Epoch : 45/300, Iter : 500/1048,  Loss: 0.5590\n",
            "Epoch : 45/300, Iter : 1000/1048,  Loss: 0.6405\n",
            "Epoch : 46/300, Iter : 500/1048,  Loss: 0.3924\n",
            "Epoch : 46/300, Iter : 1000/1048,  Loss: 1.1254\n",
            "Epoch : 47/300, Iter : 500/1048,  Loss: 0.5391\n",
            "Epoch : 47/300, Iter : 1000/1048,  Loss: 1.2834\n",
            "Epoch : 48/300, Iter : 500/1048,  Loss: 0.2644\n",
            "Epoch : 48/300, Iter : 1000/1048,  Loss: 0.7483\n",
            "Epoch : 49/300, Iter : 500/1048,  Loss: 0.6774\n",
            "Epoch : 49/300, Iter : 1000/1048,  Loss: 0.9211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment1.model\n",
            "Test Accuracy of the model on the 552 test images: 69.0000 %\n",
            "Epoch : 50/300, Iter : 500/1048,  Loss: 0.9884\n",
            "Epoch : 50/300, Iter : 1000/1048,  Loss: 0.7020\n",
            "Epoch : 51/300, Iter : 500/1048,  Loss: 0.3652\n",
            "Epoch : 51/300, Iter : 1000/1048,  Loss: 1.0298\n",
            "Epoch : 52/300, Iter : 500/1048,  Loss: 1.0228\n",
            "Epoch : 52/300, Iter : 1000/1048,  Loss: 1.1834\n",
            "Epoch : 53/300, Iter : 500/1048,  Loss: 0.6495\n",
            "Epoch : 53/300, Iter : 1000/1048,  Loss: 0.9774\n",
            "Epoch : 54/300, Iter : 500/1048,  Loss: 0.6691\n",
            "Epoch : 54/300, Iter : 1000/1048,  Loss: 0.2998\n",
            "Test Accuracy of the model on the 552 test images: 68.0000 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-19df443b8e63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DSVlzWTMvgZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_save_path = file_dir + \"model_file_\" + str(find_edges) + \"_1.model\"\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\"_1.model\"\n",
        "torch.save(cnn, model_save_path)\n",
        "print(\"Saved the model to \" + model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUm4UsnDxt_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "car_type_test = CarTypeDataset(pd_dataframe=test,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform,\n",
        "                                     sq_image = sq_image, \n",
        "                                    find_edges = find_edges\n",
        "                                    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(car_type_test,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, this_loader in enumerate(test_loader):\n",
        "    images = Variable(this_loader[\"image\"])\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += this_loader[\"label\"].size(0)\n",
        "    correct += (predicted == this_loader[\"label\"]).sum()\n",
        "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usEoTQQA0j-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "4def287b-d4aa-4898-96b0-8ccf3b23ba79"
      },
      "cell_type": "code",
      "source": [
        "print(len(losses))\n",
        "# losses_in_epochs = losses[0::60]\n",
        "losses_in_epochs = losses\n",
        "# plt.xkcd();\n",
        "plt.rcdefaults()\n",
        "plt.figure();\n",
        "plt.title(\"Experiment \" + str(model_extra_char))\n",
        "plt.xlabel('Iterations #');\n",
        "plt.ylabel('Loss');\n",
        "plt.plot(losses_in_epochs);\n",
        "plt.show();"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc5a602b518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}