{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp 11 4 Copy of Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f0ayvowQNK3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Referred Material\n",
        "\n",
        "**-Loading and transforming data **\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "\n",
        "-**Intro to pytorch **\n",
        "\n",
        "https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
        "\n",
        "\n",
        "-**Image preprocessing over view: **\n",
        "\n",
        "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258\n",
        " \n",
        " (*Try this*) https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        " \n",
        " (*Try this*) https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
        " \n",
        " -**List of things to try w.r.t pre-processing**\n",
        " \n",
        "\n",
        "*   Square images + batch size 10  (**Done**)\n",
        "*   Square images + bw + batch size 100 (**Done**)\n",
        "*   Square images + batch size 100  (**Done**)\n",
        "*   Random flips and rotation  (**Done**)\n",
        "*   Five crop images + batch size 100  (**Done**)\n",
        "*   Other transformation techniques  (**Done**)\n",
        "*   Without normalization  (**Done**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m29L6L_EYtQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Mounting the google drive for loading Dataset sand saving other files"
      ]
    },
    {
      "metadata": {
        "id": "kiT0P1Zh0T4O",
        "colab_type": "code",
        "outputId": "0024f566-6179-472f-d422-d730eeef99e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJz_lmGZDF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Installing and loading necessary modules"
      ]
    },
    {
      "metadata": {
        "id": "L5xPhzElgxSe",
        "colab_type": "code",
        "outputId": "532af643-3b09-4f8b-eb14-c12351f003ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random;\n",
        "import math;\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from IPython.display import clear_output, display\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 35.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQHizK52OvDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b473605a-d8de-498c-ee0a-20e37135de05"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMN54-l0Y2Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading Dataset to pandas dataframe and splitting it into train, test and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "jpn74UIA1LG-",
        "colab_type": "code",
        "outputId": "9af27cc2-9af8-4f88-d651-8065024c8253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/train_cars.csv', 'r') as f:\n",
        "#   print(f.read())  \n",
        "\n",
        "file_dir = \"/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/\"\n",
        "img_dir = file_dir + \"train/\"\n",
        "sq_img_dir = file_dir + \"train_sq/\"\n",
        "file_name = file_dir + \"train_cars.csv\"\n",
        "sep_datasets = file_dir + \"sep datasets/\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_entire_dataset = pd.read_csv(file_name)\n",
        "\n",
        "print(df_entire_dataset.columns)\n",
        "unique_car_type = df_entire_dataset.target.unique()\n",
        "\n",
        "print(unique_car_type)\n",
        "\n",
        "unique_car_type_dict = {}\n",
        "df_entire_dataset[\"num_target\"] = df_entire_dataset[\"target\"]\n",
        "for index, per_car_type in enumerate(unique_car_type):\n",
        "  df_entire_dataset[\"num_target\"] = df_entire_dataset[\"num_target\"].replace(per_car_type, index)\n",
        "\n",
        "# print(df_entire_dataset)\n",
        "train_valid, test = train_test_split(df_entire_dataset, test_size=0.05, random_state =10, stratify=df_entire_dataset[\"num_target\"])\n",
        "train, valid = train_test_split(train_valid, test_size=0.05, random_state=10, stratify=train_valid[\"num_target\"])\n",
        "\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)\n",
        "test.reset_index(inplace = True, drop=True)\n",
        "\n",
        "train_data_file = sep_datasets + \"train_dataset.csv\"\n",
        "train.to_csv(train_data_file)\n",
        "valid_data_file = sep_datasets + \"valid_dataset.csv\"\n",
        "valid.to_csv(valid_data_file)\n",
        "test_data_file = sep_datasets + \"test_dataset.csv\"\n",
        "test.to_csv(test_data_file)\n",
        "\n",
        "\n",
        "print(df_entire_dataset.groupby(\"target\").size())\n",
        "# print(train.groupby(\"target\").size())\n",
        "# print(valid.groupby(\"target\").size())\n",
        "# print(test.groupby(\"target\").size())\n",
        "print(train.size)\n",
        "print(valid.size)\n",
        "print(test.size)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['image_name', 'target'], dtype='object')\n",
            "['sedan' 'truck' 'dedicated agricultural vehicle' 'jeep' 'crane truck'\n",
            " 'prime mover' 'cement mixer' 'hatchback' 'minivan' 'pickup' 'van'\n",
            " 'light truck' 'bus' 'tanker' 'minibus']\n",
            "target\n",
            "bus                                 53\n",
            "cement mixer                        17\n",
            "crane truck                         16\n",
            "dedicated agricultural vehicle       5\n",
            "hatchback                         3080\n",
            "jeep                               865\n",
            "light truck                        164\n",
            "minibus                             25\n",
            "minivan                            586\n",
            "pickup                             435\n",
            "prime mover                         44\n",
            "sedan                             5783\n",
            "tanker                               3\n",
            "truck                              179\n",
            "van                                362\n",
            "dtype: int64\n",
            "31452\n",
            "1656\n",
            "1743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKm-1x3KZLsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Class to load and transform the dataset"
      ]
    },
    {
      "metadata": {
        "id": "LRWlulvT6gB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#referred from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CarTypeDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, pd_dataframe, root_dir, transform=None, sq_image = False, image_channel = \"RGB\", find_edges = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pd_dataframe (dataframe): Pandas dataframe with the respectve data\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.cartype_frame = pd_dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.sq_image = sq_image\n",
        "        self.image_channel = image_channel\n",
        "        self.find_edges = find_edges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cartype_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir + self.cartype_frame.iloc[idx, 0]\n",
        "        # read the image which returns numerical transformation of image plot using plt.imshow\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        actual_image = image \n",
        "        \n",
        "        if self.find_edges: \n",
        "          image = cv2.Canny(image,10,100, L2gradient= True)\n",
        "          \n",
        "        \n",
        "        pil_image = Image.fromarray(image)\n",
        "        \n",
        "        if self.sq_image: \n",
        "          pil_image = CarTypeDataset.make_square(pil_image)\n",
        "        \n",
        "#         if self.image_channel:\n",
        "        pil_image = pil_image.convert(self.image_channel)\n",
        "\n",
        "        image = pil_image\n",
        "        num_car_type = self.cartype_frame.iloc[idx, 2]\n",
        "        car_type = self.cartype_frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': num_car_type}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def make_square(im, min_size=80, fill_color=(0, 0, 0, 0)):\n",
        "        x, y = im.size\n",
        "        min_size = x if x > y else y \n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        val_x = int((size - x) / 2)\n",
        "        val_y = int((size - y) / 2)\n",
        "\n",
        "        new_im.paste(im, (val_x, val_y))\n",
        "        return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_dCHX5hXP-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Calculating Mean and Standard Deviation across all the train images data\n",
        "\n",
        "(Outputs are commented below the print statements)"
      ]
    },
    {
      "metadata": {
        "id": "37RiX6XnU9Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# composed = transforms.Compose([\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "\n",
        "# car_type_train = CarTypeDataset(pd_dataframe=train,\n",
        "#                                     root_dir=img_dir,\n",
        "#                                     transform = composed)\n",
        "\n",
        "\n",
        "# tensor_mean_list = []\n",
        "# tensor_std_list = []\n",
        "\n",
        "# for index in range(0,len(car_type_train)):\n",
        "# #   print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "#   this_car_type = car_type_train[index]\n",
        "#   this_mean = this_car_type[\"image\"].mean(1).mean(1)\n",
        "#   this_std = this_car_type[\"image\"].std(1).std(1)\n",
        "#   if index % 1000 == 0:\n",
        "#     print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "    \n",
        "#     print(this_mean)\n",
        "#     print(this_std)\n",
        "#   tensor_mean_list.append(this_mean)\n",
        "#   tensor_std_list.append(this_std)\n",
        "  \n",
        "# tensor_mean_tuple = tuple(tensor_mean_list)\n",
        "# tensor_std_tuple = tuple(tensor_std_list)\n",
        "\n",
        "# # print(tensor_mean_tuple)\n",
        "\n",
        "# image_means = torch.stack(tensor_mean_tuple)\n",
        "# print(image_means.mean(0))\n",
        "# # tensor([0.4961, 0.5154, 0.5685])\n",
        "\n",
        "# image_std = torch.stack(tensor_std_tuple)\n",
        "# print(image_std.mean(0))\n",
        "# # tensor([0.0538, 0.0556, 0.0510])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSqClVOB3MBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Edge Dectection Sample Code\n",
        "(The sample outputs are included in the report)"
      ]
    },
    {
      "metadata": {
        "id": "B3yhsGxR3JIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# from random import * \n",
        "\n",
        "# def plot_edges(car_type):\n",
        "\n",
        "#   car_type_df = train.loc[train['target'] == car_type]\n",
        "#   car_img = car_type_df.iloc[randint(0,len(car_type_df))]\n",
        "#   image = car_img[\"image_name\"]\n",
        "#   img_name = img_dir + image\n",
        "#   io_image  = io.imread(img_name)\n",
        "#   print(type(io_image))\n",
        "\n",
        "#   edges_1 = cv2.Canny(io_image,10,100, L2gradient= True)\n",
        "\n",
        "#   plt.subplot(121),plt.imshow(edges_1)\n",
        "#   plt.title('Edge Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "#   plt.subplot(122)\n",
        "#   plt.imshow(io_image)\n",
        "#   plt.title('Oriignal Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# plot_edges(\"sedan\")\n",
        "# plot_edges(\"truck\")\n",
        "# plot_edges(\"jeep\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB3dw_BUK1or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_extra_char = input(\"Enter experiment Number ..\")\n",
        "model_extra_char = \"9\"\n",
        "\n",
        "num_epochs = 300;\n",
        "batch_size = 10;\n",
        "learning_rate = 0.001;\n",
        "find_edges = False\n",
        "in_kernel_size = (15,15)\n",
        "hd_kernel_size = (3,3)\n",
        "neuron_count = 32\n",
        "max_neuron_count = 2\n",
        "cnv_count = 10\n",
        "full_count = 5\n",
        "\n",
        "sq_image = False\n",
        "acc_score = 0\n",
        "\n",
        "\n",
        "# model_extra_char = input(\"Enter that extra character to apply to the best model name\")\n",
        "model_save_path = file_dir + \"model_file_experiment_\"  + str(model_extra_char) +\".model\"\n",
        "losses_save_path = file_dir + \"losses/losses_file_experiment_\" + str(model_extra_char) +\".csv\"\n",
        "\n",
        "resize_height = 72\n",
        "resize_width = 30\n",
        "rotation_degree= 10\n",
        "#           transforms.RandomRotation(rotation_degree),\n",
        "if find_edges:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "\n",
        "          transforms.ToTensor()\n",
        "\n",
        "      ])\n",
        "else:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4961, 0.5154, 0.5685), (0.0538, 0.0556, 0.0510))\n",
        "      ])\n",
        "\n",
        "\n",
        "car_type_train_norm = CarTypeDataset(pd_dataframe=train,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform, \n",
        "                                    sq_image = sq_image, \n",
        "                                    find_edges = find_edges)\n",
        "\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(car_type_train_norm,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzPN8EchhjzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "          \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, neuron_count, kernel_size=in_kernel_size, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.MaxPool2d(max_neuron_count))\n",
        "  \n",
        "        self.layer_hd = nn.Sequential(\n",
        "            nn.Conv2d(neuron_count, neuron_count, kernel_size=hd_kernel_size, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(max_neuron_count))\n",
        "\n",
        "        self.fcS = nn.Linear(32, neuron_count)\n",
        "        self.fc_c = nn.Linear(neuron_count, neuron_count)      \n",
        "        self.fcL = nn.Linear(neuron_count, 15)\n",
        "        \n",
        "    def forward(self, x, cnv_count= 1, full_count = 2):\n",
        "        out = self.layer1(x)     #1 \n",
        "        \n",
        "        for i in range(cnv_count-1):\n",
        "          out = self.layer_hd(out) #2\n",
        "        \n",
        "        out = out.view(out.size(0), -1)\n",
        "    \n",
        "        out = self.fcS(out)  #First\n",
        "        for i in range(full_count-2):\n",
        "          out = self.fc_c(out) #1\n",
        "\n",
        "        out = self.fcL(out)  #Last\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uGZHD17hmVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#instance of the Conv Net\n",
        "cnn = CNN();\n",
        "cnn.to(device)\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16kZUe0Axb30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_score(acc_score, cnn, data_transform):\n",
        "  car_type_valid_norm = CarTypeDataset(pd_dataframe=valid,\n",
        "                                      root_dir=img_dir,\n",
        "                                      transform = data_transform,\n",
        "                                       sq_image = sq_image, \n",
        "                                      find_edges = find_edges\n",
        "                                      )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(car_type_valid_norm,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=8)\n",
        "  cnn.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, this_loader in enumerate(valid_loader):\n",
        "      images = Variable(this_loader[\"image\"]).to(device)\n",
        "      outputs = cnn(images, cnv_count, full_count)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += this_loader[\"label\"].size(0)\n",
        "      correct += (predicted == this_loader[\"label\"].to(device)).sum()\n",
        "    \n",
        "  this_acc_score = (100 * correct / total)\n",
        "  if this_acc_score > acc_score:\n",
        "    acc_score = this_acc_score\n",
        "    torch.save(cnn, model_save_path)\n",
        "    print(\"Saved the model to \" + model_save_path)\n",
        "  print('Test Accuracy of the model on the %i test images: %.4f %%' % (len(car_type_valid_norm), (100 * correct / total)) )\n",
        "  return acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGVb6d9-IvXm",
        "colab_type": "code",
        "outputId": "332f935e-d929-4f50-df9a-3aa745960a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Size Data loader\")\n",
        "print(len(dataset_loader))\n",
        "data_loader_len = len(dataset_loader)\n",
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      acc_score =  valid_score(acc_score, cnn, data_transform)\n",
        "      \n",
        "    for i, this_loader in enumerate(dataset_loader):\n",
        "        images = Variable(this_loader[\"image\"]).to(device)\n",
        "        labels = Variable(this_loader[\"label\"]).to(device)\n",
        "        \n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images, cnv_count, full_count)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.data.item());\n",
        "        \n",
        "        with open(losses_save_path, 'wb') as fp:\n",
        "          pickle.dump(losses, fp)\n",
        "        \n",
        "        if (i+1) % int(data_loader_len/3) == 0:\n",
        "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
        "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data.item()))\n",
        "          \n",
        "    "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Data loader\n",
            "350\n",
            "Epoch : 1/300, Iter : 116/349,  Loss: 1.5098\n",
            "Epoch : 1/300, Iter : 232/349,  Loss: 1.6535\n",
            "Epoch : 1/300, Iter : 348/349,  Loss: 1.3006\n",
            "Epoch : 2/300, Iter : 116/349,  Loss: 1.5533\n",
            "Epoch : 2/300, Iter : 232/349,  Loss: 1.3183\n",
            "Epoch : 2/300, Iter : 348/349,  Loss: 1.1295\n",
            "Epoch : 3/300, Iter : 116/349,  Loss: 1.1164\n",
            "Epoch : 3/300, Iter : 232/349,  Loss: 1.7923\n",
            "Epoch : 3/300, Iter : 348/349,  Loss: 1.3827\n",
            "Epoch : 4/300, Iter : 116/349,  Loss: 1.2241\n",
            "Epoch : 4/300, Iter : 232/349,  Loss: 1.0410\n",
            "Epoch : 4/300, Iter : 348/349,  Loss: 0.9468\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 26.0000 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : 5/300, Iter : 116/349,  Loss: 1.3281\n",
            "Epoch : 5/300, Iter : 232/349,  Loss: 1.2835\n",
            "Epoch : 5/300, Iter : 348/349,  Loss: 1.4751\n",
            "Epoch : 6/300, Iter : 116/349,  Loss: 1.3595\n",
            "Epoch : 6/300, Iter : 232/349,  Loss: 1.0905\n",
            "Epoch : 6/300, Iter : 348/349,  Loss: 1.5038\n",
            "Epoch : 7/300, Iter : 116/349,  Loss: 1.1433\n",
            "Epoch : 7/300, Iter : 232/349,  Loss: 1.1772\n",
            "Epoch : 7/300, Iter : 348/349,  Loss: 1.3226\n",
            "Epoch : 8/300, Iter : 116/349,  Loss: 1.2981\n",
            "Epoch : 8/300, Iter : 232/349,  Loss: 1.1912\n",
            "Epoch : 8/300, Iter : 348/349,  Loss: 1.3745\n",
            "Epoch : 9/300, Iter : 116/349,  Loss: 0.8953\n",
            "Epoch : 9/300, Iter : 232/349,  Loss: 1.1790\n",
            "Epoch : 9/300, Iter : 348/349,  Loss: 0.9909\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 56.0000 %\n",
            "Epoch : 10/300, Iter : 116/349,  Loss: 1.4286\n",
            "Epoch : 10/300, Iter : 232/349,  Loss: 1.2341\n",
            "Epoch : 10/300, Iter : 348/349,  Loss: 1.2772\n",
            "Epoch : 11/300, Iter : 116/349,  Loss: 1.2073\n",
            "Epoch : 11/300, Iter : 232/349,  Loss: 1.1019\n",
            "Epoch : 11/300, Iter : 348/349,  Loss: 1.1164\n",
            "Epoch : 12/300, Iter : 116/349,  Loss: 1.6894\n",
            "Epoch : 12/300, Iter : 232/349,  Loss: 1.1511\n",
            "Epoch : 12/300, Iter : 348/349,  Loss: 1.0326\n",
            "Epoch : 13/300, Iter : 116/349,  Loss: 0.7443\n",
            "Epoch : 13/300, Iter : 232/349,  Loss: 1.0057\n",
            "Epoch : 13/300, Iter : 348/349,  Loss: 1.0574\n",
            "Epoch : 14/300, Iter : 116/349,  Loss: 1.1034\n",
            "Epoch : 14/300, Iter : 232/349,  Loss: 1.1418\n",
            "Epoch : 14/300, Iter : 348/349,  Loss: 1.1498\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 58.0000 %\n",
            "Epoch : 15/300, Iter : 116/349,  Loss: 1.1877\n",
            "Epoch : 15/300, Iter : 232/349,  Loss: 1.1706\n",
            "Epoch : 15/300, Iter : 348/349,  Loss: 0.8800\n",
            "Epoch : 16/300, Iter : 116/349,  Loss: 0.9672\n",
            "Epoch : 16/300, Iter : 232/349,  Loss: 0.8622\n",
            "Epoch : 16/300, Iter : 348/349,  Loss: 1.2946\n",
            "Epoch : 17/300, Iter : 116/349,  Loss: 1.0871\n",
            "Epoch : 17/300, Iter : 232/349,  Loss: 1.3674\n",
            "Epoch : 17/300, Iter : 348/349,  Loss: 1.1695\n",
            "Epoch : 18/300, Iter : 116/349,  Loss: 0.9445\n",
            "Epoch : 18/300, Iter : 232/349,  Loss: 1.3769\n",
            "Epoch : 18/300, Iter : 348/349,  Loss: 1.0224\n",
            "Epoch : 19/300, Iter : 116/349,  Loss: 1.2476\n",
            "Epoch : 19/300, Iter : 232/349,  Loss: 1.0889\n",
            "Epoch : 19/300, Iter : 348/349,  Loss: 0.9472\n",
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment_9.model\n",
            "Test Accuracy of the model on the 552 test images: 60.0000 %\n",
            "Epoch : 20/300, Iter : 116/349,  Loss: 0.9524\n",
            "Epoch : 20/300, Iter : 232/349,  Loss: 1.0300\n",
            "Epoch : 20/300, Iter : 348/349,  Loss: 1.1066\n",
            "Epoch : 21/300, Iter : 116/349,  Loss: 1.3018\n",
            "Epoch : 21/300, Iter : 232/349,  Loss: 0.9651\n",
            "Epoch : 21/300, Iter : 348/349,  Loss: 1.2654\n",
            "Epoch : 22/300, Iter : 116/349,  Loss: 1.0302\n",
            "Epoch : 22/300, Iter : 232/349,  Loss: 1.1499\n",
            "Epoch : 22/300, Iter : 348/349,  Loss: 1.0361\n",
            "Epoch : 23/300, Iter : 116/349,  Loss: 0.8098\n",
            "Epoch : 23/300, Iter : 232/349,  Loss: 0.8920\n",
            "Epoch : 23/300, Iter : 348/349,  Loss: 1.1570\n",
            "Epoch : 24/300, Iter : 116/349,  Loss: 0.9558\n",
            "Epoch : 24/300, Iter : 232/349,  Loss: 1.0521\n",
            "Epoch : 24/300, Iter : 348/349,  Loss: 1.2533\n",
            "Test Accuracy of the model on the 552 test images: 59.0000 %\n",
            "Epoch : 25/300, Iter : 116/349,  Loss: 1.0742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-cd2b174fe221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mvalid_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DSVlzWTMvgZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_save_path = file_dir + \"model_file_\" + str(find_edges) + \"_1.model\"\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\"_1.model\"\n",
        "torch.save(cnn, model_save_path)\n",
        "print(\"Saved the model to \" + model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUm4UsnDxt_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "car_type_test = CarTypeDataset(pd_dataframe=test,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform,\n",
        "                                     sq_image = sq_image, \n",
        "                                    find_edges = find_edges\n",
        "                                    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(car_type_test,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, this_loader in enumerate(test_loader):\n",
        "    images = Variable(this_loader[\"image\"])\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += this_loader[\"label\"].size(0)\n",
        "    correct += (predicted == this_loader[\"label\"]).sum()\n",
        "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usEoTQQA0j-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "1476d94b-5984-4b47-e177-39771f3e7555"
      },
      "cell_type": "code",
      "source": [
        "print(len(losses))\n",
        "# losses_in_epochs = losses[0::60]\n",
        "losses_in_epochs = losses\n",
        "# plt.xkcd();\n",
        "plt.rcdefaults()\n",
        "plt.figure();\n",
        "plt.title(\"Experiment \" + str(model_extra_char))\n",
        "plt.xlabel('Iterations #');\n",
        "plt.ylabel('Loss');\n",
        "plt.plot(losses_in_epochs);\n",
        "plt.show();"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5LRY6BAREZHT+n9lc667Y+JrlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb5b414ada0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}