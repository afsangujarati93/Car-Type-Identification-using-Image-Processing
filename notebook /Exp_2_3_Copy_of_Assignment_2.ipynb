{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp 2 3 Copy of Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f0ayvowQNK3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Referred Material\n",
        "\n",
        "**-Loading and transforming data **\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "\n",
        "-**Intro to pytorch **\n",
        "\n",
        "https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
        "\n",
        "\n",
        "-**Image preprocessing over view: **\n",
        "\n",
        "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258\n",
        " \n",
        " (*Try this*) https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        " \n",
        " (*Try this*) https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
        " \n",
        " -**List of things to try w.r.t pre-processing**\n",
        " \n",
        "\n",
        "*   Square images + batch size 10  (**Done**)\n",
        "*   Square images + bw + batch size 100 (**Done**)\n",
        "*   Square images + batch size 100  (**Done**)\n",
        "*   Random flips and rotation  (**Done**)\n",
        "*   Five crop images + batch size 100  (**Done**)\n",
        "*   Other transformation techniques  (**Done**)\n",
        "*   Without normalization  (**Done**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m29L6L_EYtQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Mounting the google drive for loading Dataset sand saving other files"
      ]
    },
    {
      "metadata": {
        "id": "kiT0P1Zh0T4O",
        "colab_type": "code",
        "outputId": "60dce6ca-03b8-42a2-926c-2e0bb9c3a024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJz_lmGZDF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Installing and loading necessary modules"
      ]
    },
    {
      "metadata": {
        "id": "L5xPhzElgxSe",
        "colab_type": "code",
        "outputId": "f4770240-38fb-4d04-86ee-c0db4eeeda11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random;\n",
        "import math;\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from IPython.display import clear_output, display\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 36.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wf4vVlA6IgOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c917596-a5df-4d28-8ca3-a3534bec9abf"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMN54-l0Y2Zt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading Dataset to pandas dataframe and splitting it into train, test and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "jpn74UIA1LG-",
        "colab_type": "code",
        "outputId": "a005742f-06fe-4a93-fb4b-8cad87218b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/train_cars.csv', 'r') as f:\n",
        "#   print(f.read())  \n",
        "\n",
        "file_dir = \"/content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/\"\n",
        "img_dir = file_dir + \"train/\"\n",
        "sq_img_dir = file_dir + \"train_sq/\"\n",
        "file_name = file_dir + \"train_cars.csv\"\n",
        "sep_datasets = file_dir + \"sep datasets/\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_entire_dataset = pd.read_csv(file_name)\n",
        "\n",
        "print(df_entire_dataset.columns)\n",
        "unique_car_type = df_entire_dataset.target.unique()\n",
        "\n",
        "print(unique_car_type)\n",
        "\n",
        "unique_car_type_dict = {}\n",
        "df_entire_dataset[\"num_target\"] = df_entire_dataset[\"target\"]\n",
        "for index, per_car_type in enumerate(unique_car_type):\n",
        "  df_entire_dataset[\"num_target\"] = df_entire_dataset[\"num_target\"].replace(per_car_type, index)\n",
        "\n",
        "# print(df_entire_dataset)\n",
        "train_valid, test = train_test_split(df_entire_dataset, test_size=0.05, random_state =10, stratify=df_entire_dataset[\"num_target\"])\n",
        "train, valid = train_test_split(train_valid, test_size=0.05, random_state=10, stratify=train_valid[\"num_target\"])\n",
        "\n",
        "train.reset_index(inplace = True, drop=True)\n",
        "valid.reset_index(inplace = True, drop=True)\n",
        "test.reset_index(inplace = True, drop=True)\n",
        "\n",
        "train_data_file = sep_datasets + \"train_dataset.csv\"\n",
        "train.to_csv(train_data_file)\n",
        "valid_data_file = sep_datasets + \"valid_dataset.csv\"\n",
        "valid.to_csv(valid_data_file)\n",
        "test_data_file = sep_datasets + \"test_dataset.csv\"\n",
        "test.to_csv(test_data_file)\n",
        "\n",
        "\n",
        "print(df_entire_dataset.groupby(\"target\").size())\n",
        "# print(train.groupby(\"target\").size())\n",
        "# print(valid.groupby(\"target\").size())\n",
        "# print(test.groupby(\"target\").size())\n",
        "print(train.size)\n",
        "print(valid.size)\n",
        "print(test.size)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['image_name', 'target'], dtype='object')\n",
            "['sedan' 'truck' 'dedicated agricultural vehicle' 'jeep' 'crane truck'\n",
            " 'prime mover' 'cement mixer' 'hatchback' 'minivan' 'pickup' 'van'\n",
            " 'light truck' 'bus' 'tanker' 'minibus']\n",
            "target\n",
            "bus                                 53\n",
            "cement mixer                        17\n",
            "crane truck                         16\n",
            "dedicated agricultural vehicle       5\n",
            "hatchback                         3080\n",
            "jeep                               865\n",
            "light truck                        164\n",
            "minibus                             25\n",
            "minivan                            586\n",
            "pickup                             435\n",
            "prime mover                         44\n",
            "sedan                             5783\n",
            "tanker                               3\n",
            "truck                              179\n",
            "van                                362\n",
            "dtype: int64\n",
            "31452\n",
            "1656\n",
            "1743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKm-1x3KZLsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Class to load and transform the dataset"
      ]
    },
    {
      "metadata": {
        "id": "LRWlulvT6gB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#referred from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "class CarTypeDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, pd_dataframe, root_dir, transform=None, sq_image = False, image_channel = \"RGB\", find_edges = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pd_dataframe (dataframe): Pandas dataframe with the respectve data\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.cartype_frame = pd_dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.sq_image = sq_image\n",
        "        self.image_channel = image_channel\n",
        "        self.find_edges = find_edges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cartype_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.root_dir + self.cartype_frame.iloc[idx, 0]\n",
        "        # read the image which returns numerical transformation of image plot using plt.imshow\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        actual_image = image \n",
        "        \n",
        "        if self.find_edges: \n",
        "          image = cv2.Canny(image,10,100, L2gradient= True)\n",
        "          \n",
        "        \n",
        "        pil_image = Image.fromarray(image)\n",
        "        \n",
        "        if self.sq_image: \n",
        "          pil_image = CarTypeDataset.make_square(pil_image)\n",
        "        \n",
        "#         if self.image_channel:\n",
        "        pil_image = pil_image.convert(self.image_channel)\n",
        "\n",
        "        image = pil_image\n",
        "        num_car_type = self.cartype_frame.iloc[idx, 2]\n",
        "        car_type = self.cartype_frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': num_car_type}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def make_square(im, min_size=80, fill_color=(0, 0, 0, 0)):\n",
        "        x, y = im.size\n",
        "        min_size = x if x > y else y \n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        val_x = int((size - x) / 2)\n",
        "        val_y = int((size - y) / 2)\n",
        "\n",
        "        new_im.paste(im, (val_x, val_y))\n",
        "        return new_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_dCHX5hXP-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Calculating Mean and Standard Deviation across all the train images data\n",
        "\n",
        "(Outputs are commented below the print statements)"
      ]
    },
    {
      "metadata": {
        "id": "37RiX6XnU9Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# composed = transforms.Compose([\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "\n",
        "# car_type_train = CarTypeDataset(pd_dataframe=train,\n",
        "#                                     root_dir=img_dir,\n",
        "#                                     transform = composed)\n",
        "\n",
        "\n",
        "# tensor_mean_list = []\n",
        "# tensor_std_list = []\n",
        "\n",
        "# for index in range(0,len(car_type_train)):\n",
        "# #   print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "#   this_car_type = car_type_train[index]\n",
        "#   this_mean = this_car_type[\"image\"].mean(1).mean(1)\n",
        "#   this_std = this_car_type[\"image\"].std(1).std(1)\n",
        "#   if index % 1000 == 0:\n",
        "#     print(str(index) + \" of \" + str(len(car_type_train)))\n",
        "    \n",
        "#     print(this_mean)\n",
        "#     print(this_std)\n",
        "#   tensor_mean_list.append(this_mean)\n",
        "#   tensor_std_list.append(this_std)\n",
        "  \n",
        "# tensor_mean_tuple = tuple(tensor_mean_list)\n",
        "# tensor_std_tuple = tuple(tensor_std_list)\n",
        "\n",
        "# # print(tensor_mean_tuple)\n",
        "\n",
        "# image_means = torch.stack(tensor_mean_tuple)\n",
        "# print(image_means.mean(0))\n",
        "# # tensor([0.4961, 0.5154, 0.5685])\n",
        "\n",
        "# image_std = torch.stack(tensor_std_tuple)\n",
        "# print(image_std.mean(0))\n",
        "# # tensor([0.0538, 0.0556, 0.0510])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSqClVOB3MBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Edge Dectection Sample Code\n",
        "(The sample outputs are included in the report)"
      ]
    },
    {
      "metadata": {
        "id": "B3yhsGxR3JIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# from random import * \n",
        "\n",
        "# def plot_edges(car_type):\n",
        "\n",
        "#   car_type_df = train.loc[train['target'] == car_type]\n",
        "#   car_img = car_type_df.iloc[randint(0,len(car_type_df))]\n",
        "#   image = car_img[\"image_name\"]\n",
        "#   img_name = img_dir + image\n",
        "#   io_image  = io.imread(img_name)\n",
        "#   print(type(io_image))\n",
        "\n",
        "#   edges_1 = cv2.Canny(io_image,10,100, L2gradient= True)\n",
        "\n",
        "#   plt.subplot(121),plt.imshow(edges_1)\n",
        "#   plt.title('Edge Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "#   plt.subplot(122)\n",
        "#   plt.imshow(io_image)\n",
        "#   plt.title('Oriignal Image ' + car_type), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "#   plt.show()\n",
        "  \n",
        "  \n",
        "# plot_edges(\"sedan\")\n",
        "# plot_edges(\"truck\")\n",
        "# plot_edges(\"jeep\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB3dw_BUK1or",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 300;\n",
        "batch_size = 10;\n",
        "learning_rate = 0.001;\n",
        "find_edges = True\n",
        "kernel_size = (3,3)\n",
        "neuron_count = 32\n",
        "\n",
        "sq_image = False\n",
        "acc_score = 0\n",
        "model_extra_char = \"3\"\n",
        "# model_extra_char = input(\"Enter that extra character to apply to the best model name\")\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(model_extra_char) +\".model\"\n",
        "\n",
        "resize_height = 72\n",
        "resize_width = 30\n",
        "rotation_degree= 10\n",
        "\n",
        "if find_edges:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor()\n",
        "\n",
        "      ])\n",
        "else:\n",
        "  data_transform = transforms.Compose([\n",
        "          transforms.Resize((resize_height,resize_width)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomRotation(rotation_degree),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4961, 0.5154, 0.5685), (0.0538, 0.0556, 0.0510))\n",
        "      ])\n",
        "\n",
        "\n",
        "car_type_train_norm = CarTypeDataset(pd_dataframe=train,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform, \n",
        "                                    sq_image = sq_image, \n",
        "                                    find_edges = find_edges)\n",
        "\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(car_type_train_norm,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzPN8EchhjzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "          \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.MaxPool2d(2))\n",
        "  \n",
        "        self.layer_hd = nn.Sequential(\n",
        "            nn.Conv2d(neuron_count, neuron_count, kernel_size=kernel_size, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(neuron_count),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.fcS = nn.Linear(256, neuron_count)\n",
        "        self.fc_c = nn.Linear(neuron_count, neuron_count)      \n",
        "        self.fcL = nn.Linear(neuron_count, 15)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)     #1 \n",
        "        out = self.layer_hd(out) #2\n",
        "        out = self.layer_hd(out) #3\n",
        "        out = self.layer_hd(out) #4\n",
        "        out = self.layer_hd(out) #5\n",
        "        \n",
        "\n",
        "        \n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fcS(out)  #First\n",
        "        out = self.fc_c(out) #1\n",
        "        out = self.fcL(out)  #Last\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uGZHD17hmVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#instance of the Conv Net\n",
        "cnn = CNN();\n",
        "cnn.to(device)\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16kZUe0Axb30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_score(acc_score, cnn, data_transform):\n",
        "  car_type_valid_norm = CarTypeDataset(pd_dataframe=valid,\n",
        "                                      root_dir=img_dir,\n",
        "                                      transform = data_transform,\n",
        "                                       sq_image = sq_image, \n",
        "                                      find_edges = find_edges\n",
        "                                      )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(car_type_valid_norm,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=8)\n",
        "  cnn.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, this_loader in enumerate(valid_loader):\n",
        "      images = Variable(this_loader[\"image\"].to(device))\n",
        "\n",
        "      outputs = cnn(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += this_loader[\"label\"].size(0)\n",
        "      correct += (predicted == this_loader[\"label\"].to(device)).sum()\n",
        "    \n",
        "  this_acc_score = (100 * correct / total)\n",
        "  if this_acc_score > acc_score:\n",
        "    acc_score = this_acc_score\n",
        "    torch.save(cnn, model_save_path)\n",
        "    print(\"Saved the model to \" + model_save_path)\n",
        "  print('Test Accuracy of the model on the %i test images: %.4f %%' % (len(car_type_valid_norm), (100 * correct / total)) )\n",
        "  return acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGVb6d9-IvXm",
        "colab_type": "code",
        "outputId": "ee1c8c18-cf07-4c05-b332-9e48860606f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3241
        }
      },
      "cell_type": "code",
      "source": [
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      acc_score =  valid_score(acc_score, cnn, data_transform)\n",
        "      \n",
        "    for i, this_loader in enumerate(dataset_loader):\n",
        "        images = Variable(this_loader[\"image\"].to(device))\n",
        "        labels = Variable(this_loader[\"label\"].to(device))\n",
        "        \n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.data.item());\n",
        "        \n",
        "        if (i+1) % 500 == 0:\n",
        "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
        "                   %(epoch+1, num_epochs, i+1, len(train)//batch_size, loss.data.item()))\n",
        "          \n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1/300, Iter : 500/1048,  Loss: 1.2007\n",
            "Epoch : 1/300, Iter : 1000/1048,  Loss: 1.9162\n",
            "Epoch : 2/300, Iter : 500/1048,  Loss: 1.4217\n",
            "Epoch : 2/300, Iter : 1000/1048,  Loss: 0.8819\n",
            "Epoch : 3/300, Iter : 500/1048,  Loss: 1.0905\n",
            "Epoch : 3/300, Iter : 1000/1048,  Loss: 1.3923\n",
            "Epoch : 4/300, Iter : 500/1048,  Loss: 1.2991\n",
            "Epoch : 4/300, Iter : 1000/1048,  Loss: 1.0989\n",
            "Test Accuracy of the model on the 552 test images: 52.0000 %\n",
            "Epoch : 5/300, Iter : 500/1048,  Loss: 1.2670\n",
            "Epoch : 5/300, Iter : 1000/1048,  Loss: 0.6356\n",
            "Epoch : 6/300, Iter : 500/1048,  Loss: 1.0096\n",
            "Epoch : 6/300, Iter : 1000/1048,  Loss: 0.2827\n",
            "Epoch : 7/300, Iter : 500/1048,  Loss: 1.5787\n",
            "Epoch : 7/300, Iter : 1000/1048,  Loss: 0.9277\n",
            "Epoch : 8/300, Iter : 500/1048,  Loss: 0.8100\n",
            "Epoch : 8/300, Iter : 1000/1048,  Loss: 0.5781\n",
            "Epoch : 9/300, Iter : 500/1048,  Loss: 0.8614\n",
            "Epoch : 9/300, Iter : 1000/1048,  Loss: 0.8492\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 10/300, Iter : 500/1048,  Loss: 0.3842\n",
            "Epoch : 10/300, Iter : 1000/1048,  Loss: 0.4775\n",
            "Epoch : 11/300, Iter : 500/1048,  Loss: 1.3641\n",
            "Epoch : 11/300, Iter : 1000/1048,  Loss: 0.7776\n",
            "Epoch : 12/300, Iter : 500/1048,  Loss: 1.0299\n",
            "Epoch : 12/300, Iter : 1000/1048,  Loss: 1.4748\n",
            "Epoch : 13/300, Iter : 500/1048,  Loss: 0.8207\n",
            "Epoch : 13/300, Iter : 1000/1048,  Loss: 0.4803\n",
            "Epoch : 14/300, Iter : 500/1048,  Loss: 1.0660\n",
            "Epoch : 14/300, Iter : 1000/1048,  Loss: 0.5681\n",
            "Test Accuracy of the model on the 552 test images: 64.0000 %\n",
            "Epoch : 15/300, Iter : 500/1048,  Loss: 1.2389\n",
            "Epoch : 15/300, Iter : 1000/1048,  Loss: 0.4903\n",
            "Epoch : 16/300, Iter : 500/1048,  Loss: 0.6087\n",
            "Epoch : 16/300, Iter : 1000/1048,  Loss: 0.3751\n",
            "Epoch : 17/300, Iter : 500/1048,  Loss: 1.2675\n",
            "Epoch : 17/300, Iter : 1000/1048,  Loss: 0.5901\n",
            "Epoch : 18/300, Iter : 500/1048,  Loss: 0.8965\n",
            "Epoch : 18/300, Iter : 1000/1048,  Loss: 0.8492\n",
            "Epoch : 19/300, Iter : 500/1048,  Loss: 1.0006\n",
            "Epoch : 19/300, Iter : 1000/1048,  Loss: 0.5716\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 20/300, Iter : 500/1048,  Loss: 0.8951\n",
            "Epoch : 20/300, Iter : 1000/1048,  Loss: 1.2350\n",
            "Epoch : 21/300, Iter : 500/1048,  Loss: 0.6504\n",
            "Epoch : 21/300, Iter : 1000/1048,  Loss: 0.7097\n",
            "Epoch : 22/300, Iter : 500/1048,  Loss: 0.6874\n",
            "Epoch : 22/300, Iter : 1000/1048,  Loss: 0.5738\n",
            "Epoch : 23/300, Iter : 500/1048,  Loss: 1.3504\n",
            "Epoch : 23/300, Iter : 1000/1048,  Loss: 0.7293\n",
            "Epoch : 24/300, Iter : 500/1048,  Loss: 1.2720\n",
            "Epoch : 24/300, Iter : 1000/1048,  Loss: 0.6681\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 25/300, Iter : 500/1048,  Loss: 1.1459\n",
            "Epoch : 25/300, Iter : 1000/1048,  Loss: 1.2994\n",
            "Epoch : 26/300, Iter : 500/1048,  Loss: 1.4749\n",
            "Epoch : 26/300, Iter : 1000/1048,  Loss: 1.1538\n",
            "Epoch : 27/300, Iter : 500/1048,  Loss: 1.3814\n",
            "Epoch : 27/300, Iter : 1000/1048,  Loss: 1.2499\n",
            "Epoch : 28/300, Iter : 500/1048,  Loss: 1.0698\n",
            "Epoch : 28/300, Iter : 1000/1048,  Loss: 1.6253\n",
            "Epoch : 29/300, Iter : 500/1048,  Loss: 0.5360\n",
            "Epoch : 29/300, Iter : 1000/1048,  Loss: 0.8753\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 30/300, Iter : 500/1048,  Loss: 0.7428\n",
            "Epoch : 30/300, Iter : 1000/1048,  Loss: 0.6874\n",
            "Epoch : 31/300, Iter : 500/1048,  Loss: 0.7428\n",
            "Epoch : 31/300, Iter : 1000/1048,  Loss: 1.1319\n",
            "Epoch : 32/300, Iter : 500/1048,  Loss: 0.7278\n",
            "Epoch : 32/300, Iter : 1000/1048,  Loss: 0.6922\n",
            "Epoch : 33/300, Iter : 500/1048,  Loss: 1.2497\n",
            "Epoch : 33/300, Iter : 1000/1048,  Loss: 0.7368\n",
            "Epoch : 34/300, Iter : 500/1048,  Loss: 0.7442\n",
            "Epoch : 34/300, Iter : 1000/1048,  Loss: 0.5868\n",
            "Test Accuracy of the model on the 552 test images: 67.0000 %\n",
            "Epoch : 35/300, Iter : 500/1048,  Loss: 0.6131\n",
            "Epoch : 35/300, Iter : 1000/1048,  Loss: 1.0187\n",
            "Epoch : 36/300, Iter : 500/1048,  Loss: 0.6977\n",
            "Epoch : 36/300, Iter : 1000/1048,  Loss: 0.8058\n",
            "Epoch : 37/300, Iter : 500/1048,  Loss: 0.7854\n",
            "Epoch : 37/300, Iter : 1000/1048,  Loss: 1.0977\n",
            "Epoch : 38/300, Iter : 500/1048,  Loss: 0.8186\n",
            "Epoch : 38/300, Iter : 1000/1048,  Loss: 0.4416\n",
            "Epoch : 39/300, Iter : 500/1048,  Loss: 0.4490\n",
            "Epoch : 39/300, Iter : 1000/1048,  Loss: 0.5398\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 40/300, Iter : 500/1048,  Loss: 1.1780\n",
            "Epoch : 40/300, Iter : 1000/1048,  Loss: 0.6384\n",
            "Epoch : 41/300, Iter : 500/1048,  Loss: 0.2488\n",
            "Epoch : 41/300, Iter : 1000/1048,  Loss: 0.4043\n",
            "Epoch : 42/300, Iter : 500/1048,  Loss: 0.6811\n",
            "Epoch : 42/300, Iter : 1000/1048,  Loss: 0.7376\n",
            "Epoch : 43/300, Iter : 500/1048,  Loss: 0.5675\n",
            "Epoch : 43/300, Iter : 1000/1048,  Loss: 0.9114\n",
            "Epoch : 44/300, Iter : 500/1048,  Loss: 0.4561\n",
            "Epoch : 44/300, Iter : 1000/1048,  Loss: 0.6456\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 45/300, Iter : 500/1048,  Loss: 0.9250\n",
            "Epoch : 45/300, Iter : 1000/1048,  Loss: 1.1276\n",
            "Epoch : 46/300, Iter : 500/1048,  Loss: 0.9345\n",
            "Epoch : 46/300, Iter : 1000/1048,  Loss: 1.5851\n",
            "Epoch : 47/300, Iter : 500/1048,  Loss: 1.0755\n",
            "Epoch : 47/300, Iter : 1000/1048,  Loss: 1.3411\n",
            "Epoch : 48/300, Iter : 500/1048,  Loss: 1.2940\n",
            "Epoch : 48/300, Iter : 1000/1048,  Loss: 0.8997\n",
            "Epoch : 49/300, Iter : 500/1048,  Loss: 1.1407\n",
            "Epoch : 49/300, Iter : 1000/1048,  Loss: 0.3915\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 50/300, Iter : 500/1048,  Loss: 0.7518\n",
            "Epoch : 50/300, Iter : 1000/1048,  Loss: 0.5679\n",
            "Epoch : 51/300, Iter : 500/1048,  Loss: 0.6626\n",
            "Epoch : 51/300, Iter : 1000/1048,  Loss: 0.7250\n",
            "Epoch : 52/300, Iter : 500/1048,  Loss: 1.1190\n",
            "Epoch : 52/300, Iter : 1000/1048,  Loss: 1.0581\n",
            "Epoch : 53/300, Iter : 500/1048,  Loss: 0.2231\n",
            "Epoch : 53/300, Iter : 1000/1048,  Loss: 0.5132\n",
            "Epoch : 54/300, Iter : 500/1048,  Loss: 0.6409\n",
            "Epoch : 54/300, Iter : 1000/1048,  Loss: 0.8086\n",
            "Test Accuracy of the model on the 552 test images: 65.0000 %\n",
            "Epoch : 55/300, Iter : 500/1048,  Loss: 0.3732\n",
            "Epoch : 55/300, Iter : 1000/1048,  Loss: 1.2466\n",
            "Epoch : 56/300, Iter : 500/1048,  Loss: 1.3743\n",
            "Epoch : 56/300, Iter : 1000/1048,  Loss: 0.7596\n",
            "Epoch : 57/300, Iter : 500/1048,  Loss: 1.3956\n",
            "Epoch : 57/300, Iter : 1000/1048,  Loss: 0.6623\n",
            "Epoch : 58/300, Iter : 500/1048,  Loss: 0.6550\n",
            "Epoch : 58/300, Iter : 1000/1048,  Loss: 0.8525\n",
            "Epoch : 59/300, Iter : 500/1048,  Loss: 1.4124\n",
            "Epoch : 59/300, Iter : 1000/1048,  Loss: 0.4089\n",
            "Test Accuracy of the model on the 552 test images: 66.0000 %\n",
            "Epoch : 60/300, Iter : 500/1048,  Loss: 0.9268\n",
            "Epoch : 60/300, Iter : 1000/1048,  Loss: 1.5183\n",
            "Epoch : 61/300, Iter : 500/1048,  Loss: 1.0776\n",
            "Epoch : 61/300, Iter : 1000/1048,  Loss: 0.9707\n",
            "Epoch : 62/300, Iter : 500/1048,  Loss: 0.7746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c2fe57a3644f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mvalid_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DSVlzWTMvgZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f4847a71-acc6-4a48-cec3-a6de467d31b7"
      },
      "cell_type": "code",
      "source": [
        "# model_save_path = file_dir + \"model_file_\" + str(find_edges) + \"_1.model\"\n",
        "model_save_path = file_dir + \"model_file_experiment\"  + str(2) +\"_1.model\"\n",
        "torch.save(cnn, model_save_path)\n",
        "print(\"Saved the model to \" + model_save_path)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved the model to /content/gdrive/My Drive/Dal Masters/CSCI 6515 - ML for Big Data/Assignment 2/Data/train_corrected/model_file_experiment2_1.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zUm4UsnDxt_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "car_type_test = CarTypeDataset(pd_dataframe=test,\n",
        "                                    root_dir=img_dir,\n",
        "                                    transform = data_transform,\n",
        "                                     sq_image = sq_image, \n",
        "                                    find_edges = find_edges\n",
        "                                    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(car_type_test,\n",
        "                                             batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, this_loader in enumerate(test_loader):\n",
        "    images = Variable(this_loader[\"image\"])\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += this_loader[\"label\"].size(0)\n",
        "    correct += (predicted == this_loader[\"label\"]).sum()\n",
        "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usEoTQQA0j-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "9416e0ef-bb71-4bb7-b5ad-fbf8d83bbf02"
      },
      "cell_type": "code",
      "source": [
        "print(len(losses))\n",
        "# losses_in_epochs = losses[0::60]\n",
        "losses_in_epochs = losses\n",
        "# plt.xkcd();\n",
        "plt.rcdefaults()\n",
        "plt.figure();\n",
        "plt.title(\"Experiment \" + str(2))\n",
        "plt.xlabel('Iterations #');\n",
        "plt.ylabel('Loss');\n",
        "plt.plot(losses_in_epochs);\n",
        "plt.show();"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7a80301240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}